I0426 13:32:54.389369  7834 caffe.cpp:218] Using GPUs 0
I0426 13:32:54.407387  7834 caffe.cpp:223] GPU 0: GeForce GTX 980
I0426 13:32:54.738965  7834 solver.cpp:44] Initializing solver from parameters: 
test_iter: 132
test_interval: 1000
base_lr: 0.001
display: 100
max_iter: 50000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.05
stepsize: 20000
snapshot: 1000
snapshot_prefix: "/home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/"
solver_mode: GPU
device_id: 0
net: "/home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I0426 13:32:54.783641  7834 solver.cpp:87] Creating training net from net file: /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/train_val.prototxt
I0426 13:32:54.784006  7834 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0426 13:32:54.784116  7834 net.cpp:51] Initializing net from parameters: 
name: "YanNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 45
    mean_file: "/home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/mean.binaryproto"
  }
  data_param {
    source: "/home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/img_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0426 13:32:54.784193  7834 layer_factory.hpp:77] Creating layer data
I0426 13:32:54.785112  7834 db_lmdb.cpp:35] Opened lmdb /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/img_train_lmdb
I0426 13:32:54.785140  7834 net.cpp:84] Creating Layer data
I0426 13:32:54.785146  7834 net.cpp:380] data -> data
I0426 13:32:54.785174  7834 net.cpp:380] data -> label
I0426 13:32:54.785185  7834 data_transformer.cpp:25] Loading mean file from: /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/mean.binaryproto
I0426 13:32:54.786308  7834 data_layer.cpp:45] output data size: 256,3,45,45
I0426 13:32:54.795040  7834 net.cpp:122] Setting up data
I0426 13:32:54.795073  7834 net.cpp:129] Top shape: 256 3 45 45 (1555200)
I0426 13:32:54.795078  7834 net.cpp:129] Top shape: 256 (256)
I0426 13:32:54.795079  7834 net.cpp:137] Memory required for data: 6221824
I0426 13:32:54.795086  7834 layer_factory.hpp:77] Creating layer conv1
I0426 13:32:54.795104  7834 net.cpp:84] Creating Layer conv1
I0426 13:32:54.795107  7834 net.cpp:406] conv1 <- data
I0426 13:32:54.795120  7834 net.cpp:380] conv1 -> conv1
I0426 13:32:54.797019  7834 net.cpp:122] Setting up conv1
I0426 13:32:54.797040  7834 net.cpp:129] Top shape: 256 64 45 45 (33177600)
I0426 13:32:54.797042  7834 net.cpp:137] Memory required for data: 138932224
I0426 13:32:54.797052  7834 layer_factory.hpp:77] Creating layer relu1
I0426 13:32:54.797060  7834 net.cpp:84] Creating Layer relu1
I0426 13:32:54.797061  7834 net.cpp:406] relu1 <- conv1
I0426 13:32:54.797065  7834 net.cpp:367] relu1 -> conv1 (in-place)
I0426 13:32:54.797072  7834 net.cpp:122] Setting up relu1
I0426 13:32:54.797075  7834 net.cpp:129] Top shape: 256 64 45 45 (33177600)
I0426 13:32:54.797078  7834 net.cpp:137] Memory required for data: 271642624
I0426 13:32:54.797081  7834 layer_factory.hpp:77] Creating layer pool1
I0426 13:32:54.797089  7834 net.cpp:84] Creating Layer pool1
I0426 13:32:54.797094  7834 net.cpp:406] pool1 <- conv1
I0426 13:32:54.797108  7834 net.cpp:380] pool1 -> pool1
I0426 13:32:54.797165  7834 net.cpp:122] Setting up pool1
I0426 13:32:54.797173  7834 net.cpp:129] Top shape: 256 64 22 22 (7929856)
I0426 13:32:54.797188  7834 net.cpp:137] Memory required for data: 303362048
I0426 13:32:54.797190  7834 layer_factory.hpp:77] Creating layer norm1
I0426 13:32:54.797199  7834 net.cpp:84] Creating Layer norm1
I0426 13:32:54.797202  7834 net.cpp:406] norm1 <- pool1
I0426 13:32:54.797207  7834 net.cpp:380] norm1 -> norm1
I0426 13:32:54.797441  7834 net.cpp:122] Setting up norm1
I0426 13:32:54.797461  7834 net.cpp:129] Top shape: 256 64 22 22 (7929856)
I0426 13:32:54.797466  7834 net.cpp:137] Memory required for data: 335081472
I0426 13:32:54.797468  7834 layer_factory.hpp:77] Creating layer conv2
I0426 13:32:54.797479  7834 net.cpp:84] Creating Layer conv2
I0426 13:32:54.797482  7834 net.cpp:406] conv2 <- norm1
I0426 13:32:54.797488  7834 net.cpp:380] conv2 -> conv2
I0426 13:32:54.800591  7834 net.cpp:122] Setting up conv2
I0426 13:32:54.800616  7834 net.cpp:129] Top shape: 256 128 22 22 (15859712)
I0426 13:32:54.800618  7834 net.cpp:137] Memory required for data: 398520320
I0426 13:32:54.800626  7834 layer_factory.hpp:77] Creating layer relu2
I0426 13:32:54.800633  7834 net.cpp:84] Creating Layer relu2
I0426 13:32:54.800647  7834 net.cpp:406] relu2 <- conv2
I0426 13:32:54.800650  7834 net.cpp:367] relu2 -> conv2 (in-place)
I0426 13:32:54.800655  7834 net.cpp:122] Setting up relu2
I0426 13:32:54.800658  7834 net.cpp:129] Top shape: 256 128 22 22 (15859712)
I0426 13:32:54.800660  7834 net.cpp:137] Memory required for data: 461959168
I0426 13:32:54.800662  7834 layer_factory.hpp:77] Creating layer pool2
I0426 13:32:54.800668  7834 net.cpp:84] Creating Layer pool2
I0426 13:32:54.800670  7834 net.cpp:406] pool2 <- conv2
I0426 13:32:54.800686  7834 net.cpp:380] pool2 -> pool2
I0426 13:32:54.800726  7834 net.cpp:122] Setting up pool2
I0426 13:32:54.800730  7834 net.cpp:129] Top shape: 256 128 11 11 (3964928)
I0426 13:32:54.800741  7834 net.cpp:137] Memory required for data: 477818880
I0426 13:32:54.800743  7834 layer_factory.hpp:77] Creating layer norm2
I0426 13:32:54.800748  7834 net.cpp:84] Creating Layer norm2
I0426 13:32:54.800761  7834 net.cpp:406] norm2 <- pool2
I0426 13:32:54.800765  7834 net.cpp:380] norm2 -> norm2
I0426 13:32:54.800853  7834 net.cpp:122] Setting up norm2
I0426 13:32:54.800856  7834 net.cpp:129] Top shape: 256 128 11 11 (3964928)
I0426 13:32:54.800858  7834 net.cpp:137] Memory required for data: 493678592
I0426 13:32:54.800870  7834 layer_factory.hpp:77] Creating layer conv3
I0426 13:32:54.800879  7834 net.cpp:84] Creating Layer conv3
I0426 13:32:54.800880  7834 net.cpp:406] conv3 <- norm2
I0426 13:32:54.800884  7834 net.cpp:380] conv3 -> conv3
I0426 13:32:54.805680  7834 net.cpp:122] Setting up conv3
I0426 13:32:54.805701  7834 net.cpp:129] Top shape: 256 128 11 11 (3964928)
I0426 13:32:54.805703  7834 net.cpp:137] Memory required for data: 509538304
I0426 13:32:54.805709  7834 layer_factory.hpp:77] Creating layer relu3
I0426 13:32:54.805714  7834 net.cpp:84] Creating Layer relu3
I0426 13:32:54.805716  7834 net.cpp:406] relu3 <- conv3
I0426 13:32:54.805730  7834 net.cpp:367] relu3 -> conv3 (in-place)
I0426 13:32:54.805734  7834 net.cpp:122] Setting up relu3
I0426 13:32:54.805737  7834 net.cpp:129] Top shape: 256 128 11 11 (3964928)
I0426 13:32:54.805739  7834 net.cpp:137] Memory required for data: 525398016
I0426 13:32:54.805742  7834 layer_factory.hpp:77] Creating layer pool3
I0426 13:32:54.805747  7834 net.cpp:84] Creating Layer pool3
I0426 13:32:54.805748  7834 net.cpp:406] pool3 <- conv3
I0426 13:32:54.805752  7834 net.cpp:380] pool3 -> pool3
I0426 13:32:54.805774  7834 net.cpp:122] Setting up pool3
I0426 13:32:54.805778  7834 net.cpp:129] Top shape: 256 128 5 5 (819200)
I0426 13:32:54.805789  7834 net.cpp:137] Memory required for data: 528674816
I0426 13:32:54.805791  7834 layer_factory.hpp:77] Creating layer ip1
I0426 13:32:54.805797  7834 net.cpp:84] Creating Layer ip1
I0426 13:32:54.805799  7834 net.cpp:406] ip1 <- pool3
I0426 13:32:54.805802  7834 net.cpp:380] ip1 -> ip1
I0426 13:32:54.844780  7834 net.cpp:122] Setting up ip1
I0426 13:32:54.844799  7834 net.cpp:129] Top shape: 256 1024 (262144)
I0426 13:32:54.844802  7834 net.cpp:137] Memory required for data: 529723392
I0426 13:32:54.844808  7834 layer_factory.hpp:77] Creating layer relu4
I0426 13:32:54.844826  7834 net.cpp:84] Creating Layer relu4
I0426 13:32:54.844828  7834 net.cpp:406] relu4 <- ip1
I0426 13:32:54.844835  7834 net.cpp:367] relu4 -> ip1 (in-place)
I0426 13:32:54.844841  7834 net.cpp:122] Setting up relu4
I0426 13:32:54.844843  7834 net.cpp:129] Top shape: 256 1024 (262144)
I0426 13:32:54.844844  7834 net.cpp:137] Memory required for data: 530771968
I0426 13:32:54.844846  7834 layer_factory.hpp:77] Creating layer drop1
I0426 13:32:54.844856  7834 net.cpp:84] Creating Layer drop1
I0426 13:32:54.844858  7834 net.cpp:406] drop1 <- ip1
I0426 13:32:54.844861  7834 net.cpp:367] drop1 -> ip1 (in-place)
I0426 13:32:54.844874  7834 net.cpp:122] Setting up drop1
I0426 13:32:54.844878  7834 net.cpp:129] Top shape: 256 1024 (262144)
I0426 13:32:54.844880  7834 net.cpp:137] Memory required for data: 531820544
I0426 13:32:54.844882  7834 layer_factory.hpp:77] Creating layer ip2
I0426 13:32:54.844888  7834 net.cpp:84] Creating Layer ip2
I0426 13:32:54.844890  7834 net.cpp:406] ip2 <- ip1
I0426 13:32:54.844893  7834 net.cpp:380] ip2 -> ip2
I0426 13:32:54.844959  7834 net.cpp:122] Setting up ip2
I0426 13:32:54.844964  7834 net.cpp:129] Top shape: 256 1 (256)
I0426 13:32:54.844965  7834 net.cpp:137] Memory required for data: 531821568
I0426 13:32:54.844983  7834 layer_factory.hpp:77] Creating layer loss
I0426 13:32:54.844988  7834 net.cpp:84] Creating Layer loss
I0426 13:32:54.844991  7834 net.cpp:406] loss <- ip2
I0426 13:32:54.845005  7834 net.cpp:406] loss <- label
I0426 13:32:54.845010  7834 net.cpp:380] loss -> loss
I0426 13:32:54.845178  7834 net.cpp:122] Setting up loss
I0426 13:32:54.845187  7834 net.cpp:129] Top shape: (1)
I0426 13:32:54.845190  7834 net.cpp:132]     with loss weight 1
I0426 13:32:54.845216  7834 net.cpp:137] Memory required for data: 531821572
I0426 13:32:54.845217  7834 net.cpp:198] loss needs backward computation.
I0426 13:32:54.845221  7834 net.cpp:198] ip2 needs backward computation.
I0426 13:32:54.845221  7834 net.cpp:198] drop1 needs backward computation.
I0426 13:32:54.845223  7834 net.cpp:198] relu4 needs backward computation.
I0426 13:32:54.845226  7834 net.cpp:198] ip1 needs backward computation.
I0426 13:32:54.845227  7834 net.cpp:198] pool3 needs backward computation.
I0426 13:32:54.845229  7834 net.cpp:198] relu3 needs backward computation.
I0426 13:32:54.845232  7834 net.cpp:198] conv3 needs backward computation.
I0426 13:32:54.845233  7834 net.cpp:198] norm2 needs backward computation.
I0426 13:32:54.845235  7834 net.cpp:198] pool2 needs backward computation.
I0426 13:32:54.845237  7834 net.cpp:198] relu2 needs backward computation.
I0426 13:32:54.845239  7834 net.cpp:198] conv2 needs backward computation.
I0426 13:32:54.845242  7834 net.cpp:198] norm1 needs backward computation.
I0426 13:32:54.845243  7834 net.cpp:198] pool1 needs backward computation.
I0426 13:32:54.845245  7834 net.cpp:198] relu1 needs backward computation.
I0426 13:32:54.845247  7834 net.cpp:198] conv1 needs backward computation.
I0426 13:32:54.845249  7834 net.cpp:200] data does not need backward computation.
I0426 13:32:54.845252  7834 net.cpp:242] This network produces output loss
I0426 13:32:54.845259  7834 net.cpp:255] Network initialization done.
I0426 13:32:54.845590  7834 solver.cpp:172] Creating test net (#0) specified by net file: /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/train_val.prototxt
I0426 13:32:54.845613  7834 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0426 13:32:54.845710  7834 net.cpp:51] Initializing net from parameters: 
name: "YanNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 45
    mean_file: "/home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/mean.binaryproto"
  }
  data_param {
    source: "/home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/img_test_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 3
    alpha: 5e-05
    beta: 0.75
    norm_region: WITHIN_CHANNEL
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
  }
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0426 13:32:54.845769  7834 layer_factory.hpp:77] Creating layer data
I0426 13:32:54.845821  7834 db_lmdb.cpp:35] Opened lmdb /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/img_test_lmdb
I0426 13:32:54.845837  7834 net.cpp:84] Creating Layer data
I0426 13:32:54.845840  7834 net.cpp:380] data -> data
I0426 13:32:54.845845  7834 net.cpp:380] data -> label
I0426 13:32:54.845850  7834 data_transformer.cpp:25] Loading mean file from: /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/mean.binaryproto
I0426 13:32:54.845989  7834 data_layer.cpp:45] output data size: 50,3,45,45
I0426 13:32:54.848662  7834 net.cpp:122] Setting up data
I0426 13:32:54.848685  7834 net.cpp:129] Top shape: 50 3 45 45 (303750)
I0426 13:32:54.848690  7834 net.cpp:129] Top shape: 50 (50)
I0426 13:32:54.848691  7834 net.cpp:137] Memory required for data: 1215200
I0426 13:32:54.848695  7834 layer_factory.hpp:77] Creating layer conv1
I0426 13:32:54.848701  7834 net.cpp:84] Creating Layer conv1
I0426 13:32:54.848704  7834 net.cpp:406] conv1 <- data
I0426 13:32:54.848709  7834 net.cpp:380] conv1 -> conv1
I0426 13:32:54.848991  7834 net.cpp:122] Setting up conv1
I0426 13:32:54.849010  7834 net.cpp:129] Top shape: 50 64 45 45 (6480000)
I0426 13:32:54.849014  7834 net.cpp:137] Memory required for data: 27135200
I0426 13:32:54.849020  7834 layer_factory.hpp:77] Creating layer relu1
I0426 13:32:54.849025  7834 net.cpp:84] Creating Layer relu1
I0426 13:32:54.849026  7834 net.cpp:406] relu1 <- conv1
I0426 13:32:54.849030  7834 net.cpp:367] relu1 -> conv1 (in-place)
I0426 13:32:54.849035  7834 net.cpp:122] Setting up relu1
I0426 13:32:54.849037  7834 net.cpp:129] Top shape: 50 64 45 45 (6480000)
I0426 13:32:54.849040  7834 net.cpp:137] Memory required for data: 53055200
I0426 13:32:54.849040  7834 layer_factory.hpp:77] Creating layer pool1
I0426 13:32:54.849045  7834 net.cpp:84] Creating Layer pool1
I0426 13:32:54.849046  7834 net.cpp:406] pool1 <- conv1
I0426 13:32:54.849050  7834 net.cpp:380] pool1 -> pool1
I0426 13:32:54.849082  7834 net.cpp:122] Setting up pool1
I0426 13:32:54.849086  7834 net.cpp:129] Top shape: 50 64 22 22 (1548800)
I0426 13:32:54.849088  7834 net.cpp:137] Memory required for data: 59250400
I0426 13:32:54.849090  7834 layer_factory.hpp:77] Creating layer norm1
I0426 13:32:54.849105  7834 net.cpp:84] Creating Layer norm1
I0426 13:32:54.849107  7834 net.cpp:406] norm1 <- pool1
I0426 13:32:54.849110  7834 net.cpp:380] norm1 -> norm1
I0426 13:32:54.849174  7834 net.cpp:122] Setting up norm1
I0426 13:32:54.849179  7834 net.cpp:129] Top shape: 50 64 22 22 (1548800)
I0426 13:32:54.849198  7834 net.cpp:137] Memory required for data: 65445600
I0426 13:32:54.849200  7834 layer_factory.hpp:77] Creating layer conv2
I0426 13:32:54.849206  7834 net.cpp:84] Creating Layer conv2
I0426 13:32:54.849208  7834 net.cpp:406] conv2 <- norm1
I0426 13:32:54.849212  7834 net.cpp:380] conv2 -> conv2
I0426 13:32:54.851755  7834 net.cpp:122] Setting up conv2
I0426 13:32:54.851763  7834 net.cpp:129] Top shape: 50 128 22 22 (3097600)
I0426 13:32:54.851776  7834 net.cpp:137] Memory required for data: 77836000
I0426 13:32:54.851781  7834 layer_factory.hpp:77] Creating layer relu2
I0426 13:32:54.851786  7834 net.cpp:84] Creating Layer relu2
I0426 13:32:54.851788  7834 net.cpp:406] relu2 <- conv2
I0426 13:32:54.851791  7834 net.cpp:367] relu2 -> conv2 (in-place)
I0426 13:32:54.851795  7834 net.cpp:122] Setting up relu2
I0426 13:32:54.851799  7834 net.cpp:129] Top shape: 50 128 22 22 (3097600)
I0426 13:32:54.851800  7834 net.cpp:137] Memory required for data: 90226400
I0426 13:32:54.851802  7834 layer_factory.hpp:77] Creating layer pool2
I0426 13:32:54.851805  7834 net.cpp:84] Creating Layer pool2
I0426 13:32:54.851807  7834 net.cpp:406] pool2 <- conv2
I0426 13:32:54.851810  7834 net.cpp:380] pool2 -> pool2
I0426 13:32:54.851832  7834 net.cpp:122] Setting up pool2
I0426 13:32:54.851845  7834 net.cpp:129] Top shape: 50 128 11 11 (774400)
I0426 13:32:54.851847  7834 net.cpp:137] Memory required for data: 93324000
I0426 13:32:54.851848  7834 layer_factory.hpp:77] Creating layer norm2
I0426 13:32:54.851864  7834 net.cpp:84] Creating Layer norm2
I0426 13:32:54.851866  7834 net.cpp:406] norm2 <- pool2
I0426 13:32:54.851871  7834 net.cpp:380] norm2 -> norm2
I0426 13:32:54.851955  7834 net.cpp:122] Setting up norm2
I0426 13:32:54.851961  7834 net.cpp:129] Top shape: 50 128 11 11 (774400)
I0426 13:32:54.851974  7834 net.cpp:137] Memory required for data: 96421600
I0426 13:32:54.851975  7834 layer_factory.hpp:77] Creating layer conv3
I0426 13:32:54.851984  7834 net.cpp:84] Creating Layer conv3
I0426 13:32:54.851985  7834 net.cpp:406] conv3 <- norm2
I0426 13:32:54.851989  7834 net.cpp:380] conv3 -> conv3
I0426 13:32:54.856743  7834 net.cpp:122] Setting up conv3
I0426 13:32:54.856752  7834 net.cpp:129] Top shape: 50 128 11 11 (774400)
I0426 13:32:54.856755  7834 net.cpp:137] Memory required for data: 99519200
I0426 13:32:54.856760  7834 layer_factory.hpp:77] Creating layer relu3
I0426 13:32:54.856765  7834 net.cpp:84] Creating Layer relu3
I0426 13:32:54.856766  7834 net.cpp:406] relu3 <- conv3
I0426 13:32:54.856770  7834 net.cpp:367] relu3 -> conv3 (in-place)
I0426 13:32:54.856773  7834 net.cpp:122] Setting up relu3
I0426 13:32:54.856775  7834 net.cpp:129] Top shape: 50 128 11 11 (774400)
I0426 13:32:54.856777  7834 net.cpp:137] Memory required for data: 102616800
I0426 13:32:54.856779  7834 layer_factory.hpp:77] Creating layer pool3
I0426 13:32:54.856783  7834 net.cpp:84] Creating Layer pool3
I0426 13:32:54.856786  7834 net.cpp:406] pool3 <- conv3
I0426 13:32:54.856787  7834 net.cpp:380] pool3 -> pool3
I0426 13:32:54.856809  7834 net.cpp:122] Setting up pool3
I0426 13:32:54.856814  7834 net.cpp:129] Top shape: 50 128 5 5 (160000)
I0426 13:32:54.856817  7834 net.cpp:137] Memory required for data: 103256800
I0426 13:32:54.856817  7834 layer_factory.hpp:77] Creating layer ip1
I0426 13:32:54.856822  7834 net.cpp:84] Creating Layer ip1
I0426 13:32:54.856823  7834 net.cpp:406] ip1 <- pool3
I0426 13:32:54.856844  7834 net.cpp:380] ip1 -> ip1
I0426 13:32:54.895118  7834 net.cpp:122] Setting up ip1
I0426 13:32:54.895138  7834 net.cpp:129] Top shape: 50 1024 (51200)
I0426 13:32:54.895140  7834 net.cpp:137] Memory required for data: 103461600
I0426 13:32:54.895146  7834 layer_factory.hpp:77] Creating layer relu4
I0426 13:32:54.895153  7834 net.cpp:84] Creating Layer relu4
I0426 13:32:54.895156  7834 net.cpp:406] relu4 <- ip1
I0426 13:32:54.895160  7834 net.cpp:367] relu4 -> ip1 (in-place)
I0426 13:32:54.895176  7834 net.cpp:122] Setting up relu4
I0426 13:32:54.895179  7834 net.cpp:129] Top shape: 50 1024 (51200)
I0426 13:32:54.895192  7834 net.cpp:137] Memory required for data: 103666400
I0426 13:32:54.895195  7834 layer_factory.hpp:77] Creating layer drop1
I0426 13:32:54.895200  7834 net.cpp:84] Creating Layer drop1
I0426 13:32:54.895201  7834 net.cpp:406] drop1 <- ip1
I0426 13:32:54.895205  7834 net.cpp:367] drop1 -> ip1 (in-place)
I0426 13:32:54.895223  7834 net.cpp:122] Setting up drop1
I0426 13:32:54.895227  7834 net.cpp:129] Top shape: 50 1024 (51200)
I0426 13:32:54.895229  7834 net.cpp:137] Memory required for data: 103871200
I0426 13:32:54.895231  7834 layer_factory.hpp:77] Creating layer ip2
I0426 13:32:54.895236  7834 net.cpp:84] Creating Layer ip2
I0426 13:32:54.895237  7834 net.cpp:406] ip2 <- ip1
I0426 13:32:54.895241  7834 net.cpp:380] ip2 -> ip2
I0426 13:32:54.895310  7834 net.cpp:122] Setting up ip2
I0426 13:32:54.895314  7834 net.cpp:129] Top shape: 50 1 (50)
I0426 13:32:54.895316  7834 net.cpp:137] Memory required for data: 103871400
I0426 13:32:54.895323  7834 layer_factory.hpp:77] Creating layer loss
I0426 13:32:54.895329  7834 net.cpp:84] Creating Layer loss
I0426 13:32:54.895331  7834 net.cpp:406] loss <- ip2
I0426 13:32:54.895334  7834 net.cpp:406] loss <- label
I0426 13:32:54.895346  7834 net.cpp:380] loss -> loss
I0426 13:32:54.895370  7834 net.cpp:122] Setting up loss
I0426 13:32:54.895373  7834 net.cpp:129] Top shape: (1)
I0426 13:32:54.895375  7834 net.cpp:132]     with loss weight 1
I0426 13:32:54.895382  7834 net.cpp:137] Memory required for data: 103871404
I0426 13:32:54.895385  7834 net.cpp:198] loss needs backward computation.
I0426 13:32:54.895386  7834 net.cpp:198] ip2 needs backward computation.
I0426 13:32:54.895388  7834 net.cpp:198] drop1 needs backward computation.
I0426 13:32:54.895390  7834 net.cpp:198] relu4 needs backward computation.
I0426 13:32:54.895391  7834 net.cpp:198] ip1 needs backward computation.
I0426 13:32:54.895393  7834 net.cpp:198] pool3 needs backward computation.
I0426 13:32:54.895396  7834 net.cpp:198] relu3 needs backward computation.
I0426 13:32:54.895397  7834 net.cpp:198] conv3 needs backward computation.
I0426 13:32:54.895401  7834 net.cpp:198] norm2 needs backward computation.
I0426 13:32:54.895402  7834 net.cpp:198] pool2 needs backward computation.
I0426 13:32:54.895404  7834 net.cpp:198] relu2 needs backward computation.
I0426 13:32:54.895406  7834 net.cpp:198] conv2 needs backward computation.
I0426 13:32:54.895407  7834 net.cpp:198] norm1 needs backward computation.
I0426 13:32:54.895409  7834 net.cpp:198] pool1 needs backward computation.
I0426 13:32:54.895411  7834 net.cpp:198] relu1 needs backward computation.
I0426 13:32:54.895413  7834 net.cpp:198] conv1 needs backward computation.
I0426 13:32:54.895416  7834 net.cpp:200] data does not need backward computation.
I0426 13:32:54.895417  7834 net.cpp:242] This network produces output loss
I0426 13:32:54.895426  7834 net.cpp:255] Network initialization done.
I0426 13:32:54.895481  7834 solver.cpp:56] Solver scaffolding done.
I0426 13:32:54.895720  7834 caffe.cpp:248] Starting Optimization
I0426 13:32:54.895725  7834 solver.cpp:272] Solving YanNet
I0426 13:32:54.895726  7834 solver.cpp:273] Learning Rate Policy: step
I0426 13:32:54.896570  7834 solver.cpp:330] Iteration 0, Testing net (#0)
I0426 13:32:57.540961  7834 solver.cpp:397]     Test net output #0: loss = 23.6931 (* 1 = 23.6931 loss)
I0426 13:32:57.827287  7834 solver.cpp:218] Iteration 0 (0 iter/s, 2.93153s/100 iters), loss = 22.0078
I0426 13:32:57.827316  7834 solver.cpp:237]     Train net output #0: loss = 22.0078 (* 1 = 22.0078 loss)
I0426 13:32:57.827340  7834 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0426 13:33:25.633311  7834 solver.cpp:218] Iteration 100 (3.59634 iter/s, 27.806s/100 iters), loss = 4.81171
I0426 13:33:25.633411  7834 solver.cpp:237]     Train net output #0: loss = 4.81171 (* 1 = 4.81171 loss)
I0426 13:33:25.633419  7834 sgd_solver.cpp:105] Iteration 100, lr = 0.001
I0426 13:33:53.463315  7834 solver.cpp:218] Iteration 200 (3.59325 iter/s, 27.8299s/100 iters), loss = 4.22501
I0426 13:33:53.463343  7834 solver.cpp:237]     Train net output #0: loss = 4.22501 (* 1 = 4.22501 loss)
I0426 13:33:53.463349  7834 sgd_solver.cpp:105] Iteration 200, lr = 0.001
I0426 13:34:21.309950  7834 solver.cpp:218] Iteration 300 (3.5911 iter/s, 27.8466s/100 iters), loss = 2.97543
I0426 13:34:21.310060  7834 solver.cpp:237]     Train net output #0: loss = 2.97543 (* 1 = 2.97543 loss)
I0426 13:34:21.310066  7834 sgd_solver.cpp:105] Iteration 300, lr = 0.001
I0426 13:34:49.164503  7834 solver.cpp:218] Iteration 400 (3.59009 iter/s, 27.8545s/100 iters), loss = 3.21166
I0426 13:34:49.164531  7834 solver.cpp:237]     Train net output #0: loss = 3.21166 (* 1 = 3.21166 loss)
I0426 13:34:49.164536  7834 sgd_solver.cpp:105] Iteration 400, lr = 0.001
I0426 13:35:17.020421  7834 solver.cpp:218] Iteration 500 (3.5899 iter/s, 27.8559s/100 iters), loss = 2.9249
I0426 13:35:17.020476  7834 solver.cpp:237]     Train net output #0: loss = 2.9249 (* 1 = 2.9249 loss)
I0426 13:35:17.020483  7834 sgd_solver.cpp:105] Iteration 500, lr = 0.001
I0426 13:35:44.877194  7834 solver.cpp:218] Iteration 600 (3.5898 iter/s, 27.8567s/100 iters), loss = 3.4522
I0426 13:35:44.877223  7834 solver.cpp:237]     Train net output #0: loss = 3.4522 (* 1 = 3.4522 loss)
I0426 13:35:44.877228  7834 sgd_solver.cpp:105] Iteration 600, lr = 0.001
I0426 13:36:12.748785  7834 solver.cpp:218] Iteration 700 (3.58789 iter/s, 27.8716s/100 iters), loss = 3.17629
I0426 13:36:12.748893  7834 solver.cpp:237]     Train net output #0: loss = 3.17629 (* 1 = 3.17629 loss)
I0426 13:36:12.748899  7834 sgd_solver.cpp:105] Iteration 700, lr = 0.001
I0426 13:36:40.632948  7834 solver.cpp:218] Iteration 800 (3.58628 iter/s, 27.8841s/100 iters), loss = 2.52754
I0426 13:36:40.632978  7834 solver.cpp:237]     Train net output #0: loss = 2.52754 (* 1 = 2.52754 loss)
I0426 13:36:40.632984  7834 sgd_solver.cpp:105] Iteration 800, lr = 0.001
I0426 13:37:08.493520  7834 solver.cpp:218] Iteration 900 (3.5893 iter/s, 27.8606s/100 iters), loss = 2.90938
I0426 13:37:08.493667  7834 solver.cpp:237]     Train net output #0: loss = 2.90938 (* 1 = 2.90938 loss)
I0426 13:37:08.493675  7834 sgd_solver.cpp:105] Iteration 900, lr = 0.001
I0426 13:37:36.060326  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_1000.caffemodel
I0426 13:37:36.114523  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_1000.solverstate
I0426 13:37:36.129323  7834 solver.cpp:330] Iteration 1000, Testing net (#0)
I0426 13:37:38.770069  7834 solver.cpp:397]     Test net output #0: loss = 2.13094 (* 1 = 2.13094 loss)
I0426 13:37:39.046955  7834 solver.cpp:218] Iteration 1000 (3.27297 iter/s, 30.5533s/100 iters), loss = 3.21942
I0426 13:37:39.046983  7834 solver.cpp:237]     Train net output #0: loss = 3.21942 (* 1 = 3.21942 loss)
I0426 13:37:39.046988  7834 sgd_solver.cpp:105] Iteration 1000, lr = 0.001
I0426 13:38:06.900692  7834 solver.cpp:218] Iteration 1100 (3.59018 iter/s, 27.8537s/100 iters), loss = 2.34426
I0426 13:38:06.900722  7834 solver.cpp:237]     Train net output #0: loss = 2.34426 (* 1 = 2.34426 loss)
I0426 13:38:06.900727  7834 sgd_solver.cpp:105] Iteration 1100, lr = 0.001
I0426 13:38:34.754871  7834 solver.cpp:218] Iteration 1200 (3.59013 iter/s, 27.8542s/100 iters), loss = 2.74044
I0426 13:38:34.754956  7834 solver.cpp:237]     Train net output #0: loss = 2.74044 (* 1 = 2.74044 loss)
I0426 13:38:34.754964  7834 sgd_solver.cpp:105] Iteration 1200, lr = 0.001
I0426 13:39:02.613438  7834 solver.cpp:218] Iteration 1300 (3.58957 iter/s, 27.8585s/100 iters), loss = 2.09384
I0426 13:39:02.613476  7834 solver.cpp:237]     Train net output #0: loss = 2.09384 (* 1 = 2.09384 loss)
I0426 13:39:02.613481  7834 sgd_solver.cpp:105] Iteration 1300, lr = 0.001
I0426 13:39:30.469288  7834 solver.cpp:218] Iteration 1400 (3.58991 iter/s, 27.8558s/100 iters), loss = 2.12748
I0426 13:39:30.469401  7834 solver.cpp:237]     Train net output #0: loss = 2.12748 (* 1 = 2.12748 loss)
I0426 13:39:30.469408  7834 sgd_solver.cpp:105] Iteration 1400, lr = 0.001
I0426 13:39:58.328805  7834 solver.cpp:218] Iteration 1500 (3.58945 iter/s, 27.8594s/100 iters), loss = 2.09747
I0426 13:39:58.328835  7834 solver.cpp:237]     Train net output #0: loss = 2.09747 (* 1 = 2.09747 loss)
I0426 13:39:58.328840  7834 sgd_solver.cpp:105] Iteration 1500, lr = 0.001
I0426 13:40:26.185727  7834 solver.cpp:218] Iteration 1600 (3.58977 iter/s, 27.8569s/100 iters), loss = 2.24443
I0426 13:40:26.185799  7834 solver.cpp:237]     Train net output #0: loss = 2.24443 (* 1 = 2.24443 loss)
I0426 13:40:26.185806  7834 sgd_solver.cpp:105] Iteration 1600, lr = 0.001
I0426 13:40:54.041456  7834 solver.cpp:218] Iteration 1700 (3.58993 iter/s, 27.8557s/100 iters), loss = 1.81099
I0426 13:40:54.041486  7834 solver.cpp:237]     Train net output #0: loss = 1.81099 (* 1 = 1.81099 loss)
I0426 13:40:54.041491  7834 sgd_solver.cpp:105] Iteration 1700, lr = 0.001
I0426 13:41:21.897300  7834 solver.cpp:218] Iteration 1800 (3.58991 iter/s, 27.8558s/100 iters), loss = 2.09562
I0426 13:41:21.897397  7834 solver.cpp:237]     Train net output #0: loss = 2.09562 (* 1 = 2.09562 loss)
I0426 13:41:21.897405  7834 sgd_solver.cpp:105] Iteration 1800, lr = 0.001
I0426 13:41:49.752037  7834 solver.cpp:218] Iteration 1900 (3.59006 iter/s, 27.8547s/100 iters), loss = 1.93038
I0426 13:41:49.752064  7834 solver.cpp:237]     Train net output #0: loss = 1.93038 (* 1 = 1.93038 loss)
I0426 13:41:49.752070  7834 sgd_solver.cpp:105] Iteration 1900, lr = 0.001
I0426 13:42:17.314362  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_2000.caffemodel
I0426 13:42:17.367365  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_2000.solverstate
I0426 13:42:17.382592  7834 solver.cpp:330] Iteration 2000, Testing net (#0)
I0426 13:42:20.021939  7834 solver.cpp:397]     Test net output #0: loss = 1.82289 (* 1 = 1.82289 loss)
I0426 13:42:20.298741  7834 solver.cpp:218] Iteration 2000 (3.27368 iter/s, 30.5467s/100 iters), loss = 2.44896
I0426 13:42:20.298770  7834 solver.cpp:237]     Train net output #0: loss = 2.44896 (* 1 = 2.44896 loss)
I0426 13:42:20.298776  7834 sgd_solver.cpp:105] Iteration 2000, lr = 0.001
I0426 13:42:48.151155  7834 solver.cpp:218] Iteration 2100 (3.59035 iter/s, 27.8524s/100 iters), loss = 2.68404
I0426 13:42:48.151252  7834 solver.cpp:237]     Train net output #0: loss = 2.68404 (* 1 = 2.68404 loss)
I0426 13:42:48.151258  7834 sgd_solver.cpp:105] Iteration 2100, lr = 0.001
I0426 13:43:16.003415  7834 solver.cpp:218] Iteration 2200 (3.59038 iter/s, 27.8522s/100 iters), loss = 2.58414
I0426 13:43:16.003443  7834 solver.cpp:237]     Train net output #0: loss = 2.58414 (* 1 = 2.58414 loss)
I0426 13:43:16.003448  7834 sgd_solver.cpp:105] Iteration 2200, lr = 0.001
I0426 13:43:43.862241  7834 solver.cpp:218] Iteration 2300 (3.58953 iter/s, 27.8588s/100 iters), loss = 1.93818
I0426 13:43:43.862350  7834 solver.cpp:237]     Train net output #0: loss = 1.93818 (* 1 = 1.93818 loss)
I0426 13:43:43.862357  7834 sgd_solver.cpp:105] Iteration 2300, lr = 0.001
I0426 13:44:11.722640  7834 solver.cpp:218] Iteration 2400 (3.58933 iter/s, 27.8603s/100 iters), loss = 1.73353
I0426 13:44:11.722667  7834 solver.cpp:237]     Train net output #0: loss = 1.73353 (* 1 = 1.73353 loss)
I0426 13:44:11.722673  7834 sgd_solver.cpp:105] Iteration 2400, lr = 0.001
I0426 13:44:39.581478  7834 solver.cpp:218] Iteration 2500 (3.58953 iter/s, 27.8588s/100 iters), loss = 1.74518
I0426 13:44:39.581557  7834 solver.cpp:237]     Train net output #0: loss = 1.74518 (* 1 = 1.74518 loss)
I0426 13:44:39.581573  7834 sgd_solver.cpp:105] Iteration 2500, lr = 0.001
I0426 13:45:07.444509  7834 solver.cpp:218] Iteration 2600 (3.58899 iter/s, 27.863s/100 iters), loss = 1.60228
I0426 13:45:07.444540  7834 solver.cpp:237]     Train net output #0: loss = 1.60228 (* 1 = 1.60228 loss)
I0426 13:45:07.444545  7834 sgd_solver.cpp:105] Iteration 2600, lr = 0.001
I0426 13:45:23.613106  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:45:35.317454  7834 solver.cpp:218] Iteration 2700 (3.58771 iter/s, 27.8729s/100 iters), loss = 2.55547
I0426 13:45:35.317482  7834 solver.cpp:237]     Train net output #0: loss = 2.55547 (* 1 = 2.55547 loss)
I0426 13:45:35.317488  7834 sgd_solver.cpp:105] Iteration 2700, lr = 0.001
I0426 13:46:03.181354  7834 solver.cpp:218] Iteration 2800 (3.58888 iter/s, 27.8639s/100 iters), loss = 2.12209
I0426 13:46:03.181495  7834 solver.cpp:237]     Train net output #0: loss = 2.12209 (* 1 = 2.12209 loss)
I0426 13:46:03.181502  7834 sgd_solver.cpp:105] Iteration 2800, lr = 0.001
I0426 13:46:31.040860  7834 solver.cpp:218] Iteration 2900 (3.58946 iter/s, 27.8594s/100 iters), loss = 1.95484
I0426 13:46:31.040890  7834 solver.cpp:237]     Train net output #0: loss = 1.95484 (* 1 = 1.95484 loss)
I0426 13:46:31.040896  7834 sgd_solver.cpp:105] Iteration 2900, lr = 0.001
I0426 13:46:58.607302  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_3000.caffemodel
I0426 13:46:58.660542  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_3000.solverstate
I0426 13:46:58.675067  7834 solver.cpp:330] Iteration 3000, Testing net (#0)
I0426 13:47:01.315742  7834 solver.cpp:397]     Test net output #0: loss = 1.5064 (* 1 = 1.5064 loss)
I0426 13:47:01.592361  7834 solver.cpp:218] Iteration 3000 (3.27316 iter/s, 30.5515s/100 iters), loss = 1.86514
I0426 13:47:01.592388  7834 solver.cpp:237]     Train net output #0: loss = 1.86514 (* 1 = 1.86514 loss)
I0426 13:47:01.592394  7834 sgd_solver.cpp:105] Iteration 3000, lr = 0.001
I0426 13:47:29.451561  7834 solver.cpp:218] Iteration 3100 (3.58948 iter/s, 27.8592s/100 iters), loss = 1.79028
I0426 13:47:29.451704  7834 solver.cpp:237]     Train net output #0: loss = 1.79028 (* 1 = 1.79028 loss)
I0426 13:47:29.451711  7834 sgd_solver.cpp:105] Iteration 3100, lr = 0.001
I0426 13:47:57.312600  7834 solver.cpp:218] Iteration 3200 (3.58926 iter/s, 27.8609s/100 iters), loss = 1.64278
I0426 13:47:57.312635  7834 solver.cpp:237]     Train net output #0: loss = 1.64278 (* 1 = 1.64278 loss)
I0426 13:47:57.312644  7834 sgd_solver.cpp:105] Iteration 3200, lr = 0.001
I0426 13:48:25.176439  7834 solver.cpp:218] Iteration 3300 (3.58888 iter/s, 27.8638s/100 iters), loss = 1.9833
I0426 13:48:25.176520  7834 solver.cpp:237]     Train net output #0: loss = 1.9833 (* 1 = 1.9833 loss)
I0426 13:48:25.176537  7834 sgd_solver.cpp:105] Iteration 3300, lr = 0.001
I0426 13:48:53.038756  7834 solver.cpp:218] Iteration 3400 (3.58909 iter/s, 27.8622s/100 iters), loss = 1.75874
I0426 13:48:53.038796  7834 solver.cpp:237]     Train net output #0: loss = 1.75874 (* 1 = 1.75874 loss)
I0426 13:48:53.038801  7834 sgd_solver.cpp:105] Iteration 3400, lr = 0.001
I0426 13:49:20.900055  7834 solver.cpp:218] Iteration 3500 (3.58921 iter/s, 27.8613s/100 iters), loss = 1.67486
I0426 13:49:20.900188  7834 solver.cpp:237]     Train net output #0: loss = 1.67486 (* 1 = 1.67486 loss)
I0426 13:49:20.900195  7834 sgd_solver.cpp:105] Iteration 3500, lr = 0.001
I0426 13:49:48.756479  7834 solver.cpp:218] Iteration 3600 (3.58985 iter/s, 27.8563s/100 iters), loss = 1.72977
I0426 13:49:48.756507  7834 solver.cpp:237]     Train net output #0: loss = 1.72977 (* 1 = 1.72977 loss)
I0426 13:49:48.756512  7834 sgd_solver.cpp:105] Iteration 3600, lr = 0.001
I0426 13:50:16.611855  7834 solver.cpp:218] Iteration 3700 (3.58997 iter/s, 27.8554s/100 iters), loss = 2.0187
I0426 13:50:16.611989  7834 solver.cpp:237]     Train net output #0: loss = 2.0187 (* 1 = 2.0187 loss)
I0426 13:50:16.611995  7834 sgd_solver.cpp:105] Iteration 3700, lr = 0.001
I0426 13:50:44.478572  7834 solver.cpp:218] Iteration 3800 (3.58853 iter/s, 27.8666s/100 iters), loss = 1.82263
I0426 13:50:44.478601  7834 solver.cpp:237]     Train net output #0: loss = 1.82263 (* 1 = 1.82263 loss)
I0426 13:50:44.478607  7834 sgd_solver.cpp:105] Iteration 3800, lr = 0.001
I0426 13:51:12.424914  7834 solver.cpp:218] Iteration 3900 (3.57829 iter/s, 27.9463s/100 iters), loss = 1.55946
I0426 13:51:12.425036  7834 solver.cpp:237]     Train net output #0: loss = 1.55946 (* 1 = 1.55946 loss)
I0426 13:51:12.425043  7834 sgd_solver.cpp:105] Iteration 3900, lr = 0.001
I0426 13:51:39.990947  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_4000.caffemodel
I0426 13:51:40.044407  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_4000.solverstate
I0426 13:51:40.059088  7834 solver.cpp:330] Iteration 4000, Testing net (#0)
I0426 13:51:42.699962  7834 solver.cpp:397]     Test net output #0: loss = 2.41536 (* 1 = 2.41536 loss)
I0426 13:51:42.976737  7834 solver.cpp:218] Iteration 4000 (3.27314 iter/s, 30.5517s/100 iters), loss = 1.8309
I0426 13:51:42.976764  7834 solver.cpp:237]     Train net output #0: loss = 1.8309 (* 1 = 1.8309 loss)
I0426 13:51:42.976770  7834 sgd_solver.cpp:105] Iteration 4000, lr = 0.001
I0426 13:52:10.835083  7834 solver.cpp:218] Iteration 4100 (3.58959 iter/s, 27.8583s/100 iters), loss = 1.85754
I0426 13:52:10.835111  7834 solver.cpp:237]     Train net output #0: loss = 1.85754 (* 1 = 1.85754 loss)
I0426 13:52:10.835117  7834 sgd_solver.cpp:105] Iteration 4100, lr = 0.001
I0426 13:52:38.697573  7834 solver.cpp:218] Iteration 4200 (3.58906 iter/s, 27.8625s/100 iters), loss = 1.36235
I0426 13:52:38.697726  7834 solver.cpp:237]     Train net output #0: loss = 1.36235 (* 1 = 1.36235 loss)
I0426 13:52:38.697733  7834 sgd_solver.cpp:105] Iteration 4200, lr = 0.001
I0426 13:53:06.553524  7834 solver.cpp:218] Iteration 4300 (3.58991 iter/s, 27.8558s/100 iters), loss = 1.68223
I0426 13:53:06.553552  7834 solver.cpp:237]     Train net output #0: loss = 1.68223 (* 1 = 1.68223 loss)
I0426 13:53:06.553558  7834 sgd_solver.cpp:105] Iteration 4300, lr = 0.001
I0426 13:53:34.416033  7834 solver.cpp:218] Iteration 4400 (3.58905 iter/s, 27.8625s/100 iters), loss = 1.37805
I0426 13:53:34.416180  7834 solver.cpp:237]     Train net output #0: loss = 1.37805 (* 1 = 1.37805 loss)
I0426 13:53:34.416188  7834 sgd_solver.cpp:105] Iteration 4400, lr = 0.001
I0426 13:54:02.277294  7834 solver.cpp:218] Iteration 4500 (3.58923 iter/s, 27.8611s/100 iters), loss = 1.46952
I0426 13:54:02.277323  7834 solver.cpp:237]     Train net output #0: loss = 1.46952 (* 1 = 1.46952 loss)
I0426 13:54:02.277329  7834 sgd_solver.cpp:105] Iteration 4500, lr = 0.001
I0426 13:54:30.137753  7834 solver.cpp:218] Iteration 4600 (3.58932 iter/s, 27.8604s/100 iters), loss = 1.61342
I0426 13:54:30.137810  7834 solver.cpp:237]     Train net output #0: loss = 1.61342 (* 1 = 1.61342 loss)
I0426 13:54:30.137817  7834 sgd_solver.cpp:105] Iteration 4600, lr = 0.001
I0426 13:54:58.013401  7834 solver.cpp:218] Iteration 4700 (3.58737 iter/s, 27.8756s/100 iters), loss = 1.77634
I0426 13:54:58.013430  7834 solver.cpp:237]     Train net output #0: loss = 1.77634 (* 1 = 1.77634 loss)
I0426 13:54:58.013437  7834 sgd_solver.cpp:105] Iteration 4700, lr = 0.001
I0426 13:55:25.879647  7834 solver.cpp:218] Iteration 4800 (3.58857 iter/s, 27.8662s/100 iters), loss = 2.03193
I0426 13:55:25.879762  7834 solver.cpp:237]     Train net output #0: loss = 2.03193 (* 1 = 2.03193 loss)
I0426 13:55:25.879768  7834 sgd_solver.cpp:105] Iteration 4800, lr = 0.001
I0426 13:55:53.744463  7834 solver.cpp:218] Iteration 4900 (3.58877 iter/s, 27.8647s/100 iters), loss = 1.72151
I0426 13:55:53.744493  7834 solver.cpp:237]     Train net output #0: loss = 1.72151 (* 1 = 1.72151 loss)
I0426 13:55:53.744498  7834 sgd_solver.cpp:105] Iteration 4900, lr = 0.001
I0426 13:56:21.309159  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_5000.caffemodel
I0426 13:56:21.362502  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_5000.solverstate
I0426 13:56:21.376983  7834 solver.cpp:330] Iteration 5000, Testing net (#0)
I0426 13:56:24.016469  7834 solver.cpp:397]     Test net output #0: loss = 1.67002 (* 1 = 1.67002 loss)
I0426 13:56:24.293136  7834 solver.cpp:218] Iteration 5000 (3.27347 iter/s, 30.5487s/100 iters), loss = 1.55754
I0426 13:56:24.293164  7834 solver.cpp:237]     Train net output #0: loss = 1.55754 (* 1 = 1.55754 loss)
I0426 13:56:24.293169  7834 sgd_solver.cpp:105] Iteration 5000, lr = 0.001
I0426 13:56:52.197062  7834 solver.cpp:218] Iteration 5100 (3.58373 iter/s, 27.9039s/100 iters), loss = 1.79308
I0426 13:56:52.197162  7834 solver.cpp:237]     Train net output #0: loss = 1.79308 (* 1 = 1.79308 loss)
I0426 13:56:52.197170  7834 sgd_solver.cpp:105] Iteration 5100, lr = 0.001
I0426 13:57:20.306403  7834 solver.cpp:218] Iteration 5200 (3.55755 iter/s, 28.1093s/100 iters), loss = 1.98271
I0426 13:57:20.306432  7834 solver.cpp:237]     Train net output #0: loss = 1.98271 (* 1 = 1.98271 loss)
I0426 13:57:20.306438  7834 sgd_solver.cpp:105] Iteration 5200, lr = 0.001
I0426 13:57:48.298908  7834 solver.cpp:218] Iteration 5300 (3.57239 iter/s, 27.9925s/100 iters), loss = 2.27644
I0426 13:57:48.299011  7834 solver.cpp:237]     Train net output #0: loss = 2.27644 (* 1 = 2.27644 loss)
I0426 13:57:48.299019  7834 sgd_solver.cpp:105] Iteration 5300, lr = 0.001
I0426 13:57:53.881206  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 13:58:16.235656  7834 solver.cpp:218] Iteration 5400 (3.57953 iter/s, 27.9367s/100 iters), loss = 1.76096
I0426 13:58:16.235687  7834 solver.cpp:237]     Train net output #0: loss = 1.76096 (* 1 = 1.76096 loss)
I0426 13:58:16.235692  7834 sgd_solver.cpp:105] Iteration 5400, lr = 0.001
I0426 13:58:44.276664  7834 solver.cpp:218] Iteration 5500 (3.56621 iter/s, 28.041s/100 iters), loss = 1.91875
I0426 13:58:44.276758  7834 solver.cpp:237]     Train net output #0: loss = 1.91875 (* 1 = 1.91875 loss)
I0426 13:58:44.276765  7834 sgd_solver.cpp:105] Iteration 5500, lr = 0.001
I0426 13:59:12.528872  7834 solver.cpp:218] Iteration 5600 (3.53955 iter/s, 28.2521s/100 iters), loss = 1.66124
I0426 13:59:12.528900  7834 solver.cpp:237]     Train net output #0: loss = 1.66124 (* 1 = 1.66124 loss)
I0426 13:59:12.528908  7834 sgd_solver.cpp:105] Iteration 5600, lr = 0.001
I0426 13:59:40.533777  7834 solver.cpp:218] Iteration 5700 (3.5708 iter/s, 28.0049s/100 iters), loss = 1.59755
I0426 13:59:40.533852  7834 solver.cpp:237]     Train net output #0: loss = 1.59755 (* 1 = 1.59755 loss)
I0426 13:59:40.533861  7834 sgd_solver.cpp:105] Iteration 5700, lr = 0.001
I0426 14:00:08.517848  7834 solver.cpp:218] Iteration 5800 (3.57347 iter/s, 27.984s/100 iters), loss = 2.06595
I0426 14:00:08.517879  7834 solver.cpp:237]     Train net output #0: loss = 2.06595 (* 1 = 2.06595 loss)
I0426 14:00:08.517885  7834 sgd_solver.cpp:105] Iteration 5800, lr = 0.001
I0426 14:00:36.492197  7834 solver.cpp:218] Iteration 5900 (3.5747 iter/s, 27.9743s/100 iters), loss = 1.78963
I0426 14:00:36.492316  7834 solver.cpp:237]     Train net output #0: loss = 1.78963 (* 1 = 1.78963 loss)
I0426 14:00:36.492322  7834 sgd_solver.cpp:105] Iteration 5900, lr = 0.001
I0426 14:01:04.054558  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_6000.caffemodel
I0426 14:01:04.108697  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_6000.solverstate
I0426 14:01:04.123739  7834 solver.cpp:330] Iteration 6000, Testing net (#0)
I0426 14:01:06.759901  7834 solver.cpp:397]     Test net output #0: loss = 1.50019 (* 1 = 1.50019 loss)
I0426 14:01:07.035949  7834 solver.cpp:218] Iteration 6000 (3.274 iter/s, 30.5437s/100 iters), loss = 1.45342
I0426 14:01:07.035976  7834 solver.cpp:237]     Train net output #0: loss = 1.45342 (* 1 = 1.45342 loss)
I0426 14:01:07.035982  7834 sgd_solver.cpp:105] Iteration 6000, lr = 0.001
I0426 14:01:34.892294  7834 solver.cpp:218] Iteration 6100 (3.58985 iter/s, 27.8563s/100 iters), loss = 1.3395
I0426 14:01:34.892323  7834 solver.cpp:237]     Train net output #0: loss = 1.3395 (* 1 = 1.3395 loss)
I0426 14:01:34.892329  7834 sgd_solver.cpp:105] Iteration 6100, lr = 0.001
I0426 14:02:02.751219  7834 solver.cpp:218] Iteration 6200 (3.58952 iter/s, 27.8589s/100 iters), loss = 1.38324
I0426 14:02:02.751358  7834 solver.cpp:237]     Train net output #0: loss = 1.38324 (* 1 = 1.38324 loss)
I0426 14:02:02.751368  7834 sgd_solver.cpp:105] Iteration 6200, lr = 0.001
I0426 14:02:30.605846  7834 solver.cpp:218] Iteration 6300 (3.59008 iter/s, 27.8545s/100 iters), loss = 1.43007
I0426 14:02:30.605876  7834 solver.cpp:237]     Train net output #0: loss = 1.43007 (* 1 = 1.43007 loss)
I0426 14:02:30.605882  7834 sgd_solver.cpp:105] Iteration 6300, lr = 0.001
I0426 14:02:58.467183  7834 solver.cpp:218] Iteration 6400 (3.5892 iter/s, 27.8613s/100 iters), loss = 1.46265
I0426 14:02:58.467304  7834 solver.cpp:237]     Train net output #0: loss = 1.46265 (* 1 = 1.46265 loss)
I0426 14:02:58.467314  7834 sgd_solver.cpp:105] Iteration 6400, lr = 0.001
I0426 14:03:26.325218  7834 solver.cpp:218] Iteration 6500 (3.58964 iter/s, 27.8579s/100 iters), loss = 1.63413
I0426 14:03:26.325249  7834 solver.cpp:237]     Train net output #0: loss = 1.63413 (* 1 = 1.63413 loss)
I0426 14:03:26.325256  7834 sgd_solver.cpp:105] Iteration 6500, lr = 0.001
I0426 14:03:54.184782  7834 solver.cpp:218] Iteration 6600 (3.58943 iter/s, 27.8596s/100 iters), loss = 1.89855
I0426 14:03:54.184864  7834 solver.cpp:237]     Train net output #0: loss = 1.89855 (* 1 = 1.89855 loss)
I0426 14:03:54.184880  7834 sgd_solver.cpp:105] Iteration 6600, lr = 0.001
I0426 14:04:22.041115  7834 solver.cpp:218] Iteration 6700 (3.58986 iter/s, 27.8563s/100 iters), loss = 1.43509
I0426 14:04:22.041143  7834 solver.cpp:237]     Train net output #0: loss = 1.43509 (* 1 = 1.43509 loss)
I0426 14:04:22.041149  7834 sgd_solver.cpp:105] Iteration 6700, lr = 0.001
I0426 14:04:49.892546  7834 solver.cpp:218] Iteration 6800 (3.59048 iter/s, 27.8514s/100 iters), loss = 1.57242
I0426 14:04:49.892604  7834 solver.cpp:237]     Train net output #0: loss = 1.57242 (* 1 = 1.57242 loss)
I0426 14:04:49.892611  7834 sgd_solver.cpp:105] Iteration 6800, lr = 0.001
I0426 14:05:17.743278  7834 solver.cpp:218] Iteration 6900 (3.59057 iter/s, 27.8507s/100 iters), loss = 1.19713
I0426 14:05:17.743305  7834 solver.cpp:237]     Train net output #0: loss = 1.19713 (* 1 = 1.19713 loss)
I0426 14:05:17.743311  7834 sgd_solver.cpp:105] Iteration 6900, lr = 0.001
I0426 14:05:45.305367  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_7000.caffemodel
I0426 14:05:45.358793  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_7000.solverstate
I0426 14:05:45.373673  7834 solver.cpp:330] Iteration 7000, Testing net (#0)
I0426 14:05:48.011569  7834 solver.cpp:397]     Test net output #0: loss = 1.70347 (* 1 = 1.70347 loss)
I0426 14:05:48.287575  7834 solver.cpp:218] Iteration 7000 (3.27393 iter/s, 30.5443s/100 iters), loss = 1.85058
I0426 14:05:48.287602  7834 solver.cpp:237]     Train net output #0: loss = 1.85058 (* 1 = 1.85058 loss)
I0426 14:05:48.287607  7834 sgd_solver.cpp:105] Iteration 7000, lr = 0.001
I0426 14:06:16.141182  7834 solver.cpp:218] Iteration 7100 (3.5902 iter/s, 27.8536s/100 iters), loss = 2.11345
I0426 14:06:16.141227  7834 solver.cpp:237]     Train net output #0: loss = 2.11345 (* 1 = 2.11345 loss)
I0426 14:06:16.141232  7834 sgd_solver.cpp:105] Iteration 7100, lr = 0.001
I0426 14:06:43.995729  7834 solver.cpp:218] Iteration 7200 (3.59008 iter/s, 27.8545s/100 iters), loss = 1.79544
I0426 14:06:43.995759  7834 solver.cpp:237]     Train net output #0: loss = 1.79544 (* 1 = 1.79544 loss)
I0426 14:06:43.995764  7834 sgd_solver.cpp:105] Iteration 7200, lr = 0.001
I0426 14:07:11.848695  7834 solver.cpp:218] Iteration 7300 (3.59028 iter/s, 27.853s/100 iters), loss = 1.61548
I0426 14:07:11.848765  7834 solver.cpp:237]     Train net output #0: loss = 1.61548 (* 1 = 1.61548 loss)
I0426 14:07:11.848773  7834 sgd_solver.cpp:105] Iteration 7300, lr = 0.001
I0426 14:07:39.701364  7834 solver.cpp:218] Iteration 7400 (3.59033 iter/s, 27.8526s/100 iters), loss = 1.60718
I0426 14:07:39.701403  7834 solver.cpp:237]     Train net output #0: loss = 1.60718 (* 1 = 1.60718 loss)
I0426 14:07:39.701409  7834 sgd_solver.cpp:105] Iteration 7400, lr = 0.001
I0426 14:08:07.552830  7834 solver.cpp:218] Iteration 7500 (3.59048 iter/s, 27.8514s/100 iters), loss = 1.56667
I0426 14:08:07.552914  7834 solver.cpp:237]     Train net output #0: loss = 1.56667 (* 1 = 1.56667 loss)
I0426 14:08:07.552930  7834 sgd_solver.cpp:105] Iteration 7500, lr = 0.001
I0426 14:08:35.399186  7834 solver.cpp:218] Iteration 7600 (3.59114 iter/s, 27.8463s/100 iters), loss = 1.55732
I0426 14:08:35.399214  7834 solver.cpp:237]     Train net output #0: loss = 1.55732 (* 1 = 1.55732 loss)
I0426 14:08:35.399220  7834 sgd_solver.cpp:105] Iteration 7600, lr = 0.001
I0426 14:09:03.250427  7834 solver.cpp:218] Iteration 7700 (3.59051 iter/s, 27.8512s/100 iters), loss = 1.31507
I0426 14:09:03.250511  7834 solver.cpp:237]     Train net output #0: loss = 1.31507 (* 1 = 1.31507 loss)
I0426 14:09:03.250527  7834 sgd_solver.cpp:105] Iteration 7700, lr = 0.001
I0426 14:09:31.102315  7834 solver.cpp:218] Iteration 7800 (3.59043 iter/s, 27.8518s/100 iters), loss = 1.58155
I0426 14:09:31.102344  7834 solver.cpp:237]     Train net output #0: loss = 1.58155 (* 1 = 1.58155 loss)
I0426 14:09:31.102349  7834 sgd_solver.cpp:105] Iteration 7800, lr = 0.001
I0426 14:09:58.953660  7834 solver.cpp:218] Iteration 7900 (3.59049 iter/s, 27.8513s/100 iters), loss = 2.21502
I0426 14:09:58.953740  7834 solver.cpp:237]     Train net output #0: loss = 2.21502 (* 1 = 2.21502 loss)
I0426 14:09:58.953757  7834 sgd_solver.cpp:105] Iteration 7900, lr = 0.001
I0426 14:10:21.915973  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:10:26.639300  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_8000.caffemodel
I0426 14:10:26.692651  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_8000.solverstate
I0426 14:10:26.707892  7834 solver.cpp:330] Iteration 8000, Testing net (#0)
I0426 14:10:29.346698  7834 solver.cpp:397]     Test net output #0: loss = 1.7275 (* 1 = 1.7275 loss)
I0426 14:10:29.622625  7834 solver.cpp:218] Iteration 8000 (3.26063 iter/s, 30.6689s/100 iters), loss = 1.46984
I0426 14:10:29.622655  7834 solver.cpp:237]     Train net output #0: loss = 1.46984 (* 1 = 1.46984 loss)
I0426 14:10:29.622661  7834 sgd_solver.cpp:105] Iteration 8000, lr = 0.001
I0426 14:10:57.891090  7834 solver.cpp:218] Iteration 8100 (3.53751 iter/s, 28.2685s/100 iters), loss = 1.7475
I0426 14:10:57.891134  7834 solver.cpp:237]     Train net output #0: loss = 1.7475 (* 1 = 1.7475 loss)
I0426 14:10:57.891141  7834 sgd_solver.cpp:105] Iteration 8100, lr = 0.001
I0426 14:11:26.762272  7834 solver.cpp:218] Iteration 8200 (3.46367 iter/s, 28.8711s/100 iters), loss = 1.53862
I0426 14:11:26.762372  7834 solver.cpp:237]     Train net output #0: loss = 1.53862 (* 1 = 1.53862 loss)
I0426 14:11:26.762388  7834 sgd_solver.cpp:105] Iteration 8200, lr = 0.001
I0426 14:11:55.220252  7834 solver.cpp:218] Iteration 8300 (3.51396 iter/s, 28.4579s/100 iters), loss = 1.38726
I0426 14:11:55.220280  7834 solver.cpp:237]     Train net output #0: loss = 1.38726 (* 1 = 1.38726 loss)
I0426 14:11:55.220285  7834 sgd_solver.cpp:105] Iteration 8300, lr = 0.001
I0426 14:12:23.382670  7834 solver.cpp:218] Iteration 8400 (3.55083 iter/s, 28.1624s/100 iters), loss = 1.71231
I0426 14:12:23.382793  7834 solver.cpp:237]     Train net output #0: loss = 1.71231 (* 1 = 1.71231 loss)
I0426 14:12:23.382800  7834 sgd_solver.cpp:105] Iteration 8400, lr = 0.001
I0426 14:12:51.394708  7834 solver.cpp:218] Iteration 8500 (3.56991 iter/s, 28.0119s/100 iters), loss = 1.89135
I0426 14:12:51.394737  7834 solver.cpp:237]     Train net output #0: loss = 1.89135 (* 1 = 1.89135 loss)
I0426 14:12:51.394742  7834 sgd_solver.cpp:105] Iteration 8500, lr = 0.001
I0426 14:13:19.418613  7834 solver.cpp:218] Iteration 8600 (3.56838 iter/s, 28.0239s/100 iters), loss = 1.5375
I0426 14:13:19.419154  7834 solver.cpp:237]     Train net output #0: loss = 1.5375 (* 1 = 1.5375 loss)
I0426 14:13:19.419173  7834 sgd_solver.cpp:105] Iteration 8600, lr = 0.001
I0426 14:13:47.694442  7834 solver.cpp:218] Iteration 8700 (3.53666 iter/s, 28.2753s/100 iters), loss = 1.68483
I0426 14:13:47.694470  7834 solver.cpp:237]     Train net output #0: loss = 1.68483 (* 1 = 1.68483 loss)
I0426 14:13:47.694476  7834 sgd_solver.cpp:105] Iteration 8700, lr = 0.001
I0426 14:14:15.636976  7834 solver.cpp:218] Iteration 8800 (3.57877 iter/s, 27.9425s/100 iters), loss = 1.38538
I0426 14:14:15.637086  7834 solver.cpp:237]     Train net output #0: loss = 1.38538 (* 1 = 1.38538 loss)
I0426 14:14:15.637104  7834 sgd_solver.cpp:105] Iteration 8800, lr = 0.001
I0426 14:14:43.683377  7834 solver.cpp:218] Iteration 8900 (3.56553 iter/s, 28.0463s/100 iters), loss = 1.64287
I0426 14:14:43.683404  7834 solver.cpp:237]     Train net output #0: loss = 1.64287 (* 1 = 1.64287 loss)
I0426 14:14:43.683410  7834 sgd_solver.cpp:105] Iteration 8900, lr = 0.001
I0426 14:15:11.273694  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_9000.caffemodel
I0426 14:15:11.327271  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_9000.solverstate
I0426 14:15:11.341820  7834 solver.cpp:330] Iteration 9000, Testing net (#0)
I0426 14:15:13.980038  7834 solver.cpp:397]     Test net output #0: loss = 2.06735 (* 1 = 2.06735 loss)
I0426 14:15:14.255836  7834 solver.cpp:218] Iteration 9000 (3.27092 iter/s, 30.5725s/100 iters), loss = 2.21535
I0426 14:15:14.255864  7834 solver.cpp:237]     Train net output #0: loss = 2.21535 (* 1 = 2.21535 loss)
I0426 14:15:14.255870  7834 sgd_solver.cpp:105] Iteration 9000, lr = 0.001
I0426 14:15:42.104230  7834 solver.cpp:218] Iteration 9100 (3.59087 iter/s, 27.8484s/100 iters), loss = 1.77236
I0426 14:15:42.104373  7834 solver.cpp:237]     Train net output #0: loss = 1.77236 (* 1 = 1.77236 loss)
I0426 14:15:42.104382  7834 sgd_solver.cpp:105] Iteration 9100, lr = 0.001
I0426 14:16:09.959492  7834 solver.cpp:218] Iteration 9200 (3.59 iter/s, 27.8552s/100 iters), loss = 1.61568
I0426 14:16:09.959532  7834 solver.cpp:237]     Train net output #0: loss = 1.61568 (* 1 = 1.61568 loss)
I0426 14:16:09.959553  7834 sgd_solver.cpp:105] Iteration 9200, lr = 0.001
I0426 14:16:37.982110  7834 solver.cpp:218] Iteration 9300 (3.56855 iter/s, 28.0226s/100 iters), loss = 1.41972
I0426 14:16:37.982252  7834 solver.cpp:237]     Train net output #0: loss = 1.41972 (* 1 = 1.41972 loss)
I0426 14:16:37.982260  7834 sgd_solver.cpp:105] Iteration 9300, lr = 0.001
I0426 14:17:05.936286  7834 solver.cpp:218] Iteration 9400 (3.5773 iter/s, 27.9541s/100 iters), loss = 1.6111
I0426 14:17:05.936316  7834 solver.cpp:237]     Train net output #0: loss = 1.6111 (* 1 = 1.6111 loss)
I0426 14:17:05.936321  7834 sgd_solver.cpp:105] Iteration 9400, lr = 0.001
I0426 14:17:33.891584  7834 solver.cpp:218] Iteration 9500 (3.57714 iter/s, 27.9553s/100 iters), loss = 1.60783
I0426 14:17:33.891674  7834 solver.cpp:237]     Train net output #0: loss = 1.60783 (* 1 = 1.60783 loss)
I0426 14:17:33.891680  7834 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I0426 14:18:01.783452  7834 solver.cpp:218] Iteration 9600 (3.58528 iter/s, 27.8918s/100 iters), loss = 1.39334
I0426 14:18:01.783480  7834 solver.cpp:237]     Train net output #0: loss = 1.39334 (* 1 = 1.39334 loss)
I0426 14:18:01.783485  7834 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I0426 14:18:29.636703  7834 solver.cpp:218] Iteration 9700 (3.59025 iter/s, 27.8533s/100 iters), loss = 1.52585
I0426 14:18:29.636829  7834 solver.cpp:237]     Train net output #0: loss = 1.52585 (* 1 = 1.52585 loss)
I0426 14:18:29.636837  7834 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I0426 14:18:57.489985  7834 solver.cpp:218] Iteration 9800 (3.59025 iter/s, 27.8532s/100 iters), loss = 1.88481
I0426 14:18:57.490015  7834 solver.cpp:237]     Train net output #0: loss = 1.88481 (* 1 = 1.88481 loss)
I0426 14:18:57.490020  7834 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I0426 14:19:25.340597  7834 solver.cpp:218] Iteration 9900 (3.59059 iter/s, 27.8506s/100 iters), loss = 1.33031
I0426 14:19:25.340697  7834 solver.cpp:237]     Train net output #0: loss = 1.33031 (* 1 = 1.33031 loss)
I0426 14:19:25.340703  7834 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I0426 14:19:52.900491  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_10000.caffemodel
I0426 14:19:52.953632  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_10000.solverstate
I0426 14:19:52.968443  7834 solver.cpp:330] Iteration 10000, Testing net (#0)
I0426 14:19:55.607107  7834 solver.cpp:397]     Test net output #0: loss = 1.35461 (* 1 = 1.35461 loss)
I0426 14:19:55.883707  7834 solver.cpp:218] Iteration 10000 (3.27407 iter/s, 30.543s/100 iters), loss = 1.48963
I0426 14:19:55.883733  7834 solver.cpp:237]     Train net output #0: loss = 1.48963 (* 1 = 1.48963 loss)
I0426 14:19:55.883738  7834 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I0426 14:20:23.857152  7834 solver.cpp:218] Iteration 10100 (3.57482 iter/s, 27.9734s/100 iters), loss = 1.85422
I0426 14:20:23.857180  7834 solver.cpp:237]     Train net output #0: loss = 1.85422 (* 1 = 1.85422 loss)
I0426 14:20:23.857187  7834 sgd_solver.cpp:105] Iteration 10100, lr = 0.001
I0426 14:20:51.714754  7834 solver.cpp:218] Iteration 10200 (3.58969 iter/s, 27.8576s/100 iters), loss = 1.08562
I0426 14:20:51.714823  7834 solver.cpp:237]     Train net output #0: loss = 1.08562 (* 1 = 1.08562 loss)
I0426 14:20:51.714829  7834 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I0426 14:21:19.570405  7834 solver.cpp:218] Iteration 10300 (3.58994 iter/s, 27.8556s/100 iters), loss = 1.44598
I0426 14:21:19.570457  7834 solver.cpp:237]     Train net output #0: loss = 1.44598 (* 1 = 1.44598 loss)
I0426 14:21:19.570463  7834 sgd_solver.cpp:105] Iteration 10300, lr = 0.001
I0426 14:21:47.426789  7834 solver.cpp:218] Iteration 10400 (3.58984 iter/s, 27.8564s/100 iters), loss = 1.05291
I0426 14:21:47.426846  7834 solver.cpp:237]     Train net output #0: loss = 1.05291 (* 1 = 1.05291 loss)
I0426 14:21:47.426852  7834 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I0426 14:22:15.282263  7834 solver.cpp:218] Iteration 10500 (3.58996 iter/s, 27.8554s/100 iters), loss = 1.11454
I0426 14:22:15.282291  7834 solver.cpp:237]     Train net output #0: loss = 1.11454 (* 1 = 1.11454 loss)
I0426 14:22:15.282296  7834 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I0426 14:22:43.138872  7834 solver.cpp:218] Iteration 10600 (3.58981 iter/s, 27.8566s/100 iters), loss = 1.38347
I0426 14:22:43.138931  7834 solver.cpp:237]     Train net output #0: loss = 1.38347 (* 1 = 1.38347 loss)
I0426 14:22:43.138937  7834 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I0426 14:22:55.677678  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:23:10.996340  7834 solver.cpp:218] Iteration 10700 (3.58971 iter/s, 27.8574s/100 iters), loss = 1.22277
I0426 14:23:10.996367  7834 solver.cpp:237]     Train net output #0: loss = 1.22277 (* 1 = 1.22277 loss)
I0426 14:23:10.996372  7834 sgd_solver.cpp:105] Iteration 10700, lr = 0.001
I0426 14:23:38.852967  7834 solver.cpp:218] Iteration 10800 (3.58981 iter/s, 27.8566s/100 iters), loss = 1.38375
I0426 14:23:38.853049  7834 solver.cpp:237]     Train net output #0: loss = 1.38375 (* 1 = 1.38375 loss)
I0426 14:23:38.853055  7834 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I0426 14:24:06.711897  7834 solver.cpp:218] Iteration 10900 (3.58952 iter/s, 27.8589s/100 iters), loss = 1.50703
I0426 14:24:06.711925  7834 solver.cpp:237]     Train net output #0: loss = 1.50703 (* 1 = 1.50703 loss)
I0426 14:24:06.711931  7834 sgd_solver.cpp:105] Iteration 10900, lr = 0.001
I0426 14:24:34.286831  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_11000.caffemodel
I0426 14:24:34.340101  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_11000.solverstate
I0426 14:24:34.355008  7834 solver.cpp:330] Iteration 11000, Testing net (#0)
I0426 14:24:36.994364  7834 solver.cpp:397]     Test net output #0: loss = 1.3518 (* 1 = 1.3518 loss)
I0426 14:24:37.270017  7834 solver.cpp:218] Iteration 11000 (3.27245 iter/s, 30.5581s/100 iters), loss = 1.61655
I0426 14:24:37.270045  7834 solver.cpp:237]     Train net output #0: loss = 1.61655 (* 1 = 1.61655 loss)
I0426 14:24:37.270051  7834 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I0426 14:25:05.129623  7834 solver.cpp:218] Iteration 11100 (3.58943 iter/s, 27.8596s/100 iters), loss = 1.46926
I0426 14:25:05.129734  7834 solver.cpp:237]     Train net output #0: loss = 1.46926 (* 1 = 1.46926 loss)
I0426 14:25:05.129740  7834 sgd_solver.cpp:105] Iteration 11100, lr = 0.001
I0426 14:25:32.987763  7834 solver.cpp:218] Iteration 11200 (3.58963 iter/s, 27.8581s/100 iters), loss = 1.72649
I0426 14:25:32.987794  7834 solver.cpp:237]     Train net output #0: loss = 1.72649 (* 1 = 1.72649 loss)
I0426 14:25:32.987800  7834 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I0426 14:26:00.842443  7834 solver.cpp:218] Iteration 11300 (3.59006 iter/s, 27.8547s/100 iters), loss = 1.64962
I0426 14:26:00.842541  7834 solver.cpp:237]     Train net output #0: loss = 1.64962 (* 1 = 1.64962 loss)
I0426 14:26:00.842557  7834 sgd_solver.cpp:105] Iteration 11300, lr = 0.001
I0426 14:26:28.697783  7834 solver.cpp:218] Iteration 11400 (3.58999 iter/s, 27.8553s/100 iters), loss = 1.24813
I0426 14:26:28.697813  7834 solver.cpp:237]     Train net output #0: loss = 1.24813 (* 1 = 1.24813 loss)
I0426 14:26:28.697819  7834 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I0426 14:26:56.564733  7834 solver.cpp:218] Iteration 11500 (3.58848 iter/s, 27.8669s/100 iters), loss = 1.73546
I0426 14:26:56.564815  7834 solver.cpp:237]     Train net output #0: loss = 1.73546 (* 1 = 1.73546 loss)
I0426 14:26:56.564831  7834 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I0426 14:27:24.420812  7834 solver.cpp:218] Iteration 11600 (3.58989 iter/s, 27.856s/100 iters), loss = 1.43459
I0426 14:27:24.420843  7834 solver.cpp:237]     Train net output #0: loss = 1.43459 (* 1 = 1.43459 loss)
I0426 14:27:24.420850  7834 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I0426 14:27:52.280227  7834 solver.cpp:218] Iteration 11700 (3.58945 iter/s, 27.8594s/100 iters), loss = 1.33271
I0426 14:27:52.280318  7834 solver.cpp:237]     Train net output #0: loss = 1.33271 (* 1 = 1.33271 loss)
I0426 14:27:52.280324  7834 sgd_solver.cpp:105] Iteration 11700, lr = 0.001
I0426 14:28:20.136181  7834 solver.cpp:218] Iteration 11800 (3.5899 iter/s, 27.8559s/100 iters), loss = 1.30135
I0426 14:28:20.136210  7834 solver.cpp:237]     Train net output #0: loss = 1.30135 (* 1 = 1.30135 loss)
I0426 14:28:20.136217  7834 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I0426 14:28:47.991981  7834 solver.cpp:218] Iteration 11900 (3.58992 iter/s, 27.8558s/100 iters), loss = 1.33756
I0426 14:28:47.992126  7834 solver.cpp:237]     Train net output #0: loss = 1.33756 (* 1 = 1.33756 loss)
I0426 14:28:47.992135  7834 sgd_solver.cpp:105] Iteration 11900, lr = 0.001
I0426 14:29:15.553042  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_12000.caffemodel
I0426 14:29:15.606828  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_12000.solverstate
I0426 14:29:15.621634  7834 solver.cpp:330] Iteration 12000, Testing net (#0)
I0426 14:29:18.259918  7834 solver.cpp:397]     Test net output #0: loss = 1.40004 (* 1 = 1.40004 loss)
I0426 14:29:18.535965  7834 solver.cpp:218] Iteration 12000 (3.27398 iter/s, 30.5439s/100 iters), loss = 1.59497
I0426 14:29:18.535993  7834 solver.cpp:237]     Train net output #0: loss = 1.59497 (* 1 = 1.59497 loss)
I0426 14:29:18.536000  7834 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I0426 14:29:46.395613  7834 solver.cpp:218] Iteration 12100 (3.58942 iter/s, 27.8596s/100 iters), loss = 1.83666
I0426 14:29:46.395642  7834 solver.cpp:237]     Train net output #0: loss = 1.83666 (* 1 = 1.83666 loss)
I0426 14:29:46.395648  7834 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I0426 14:30:14.253073  7834 solver.cpp:218] Iteration 12200 (3.5897 iter/s, 27.8575s/100 iters), loss = 1.76713
I0426 14:30:14.253125  7834 solver.cpp:237]     Train net output #0: loss = 1.76713 (* 1 = 1.76713 loss)
I0426 14:30:14.253132  7834 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I0426 14:30:42.109002  7834 solver.cpp:218] Iteration 12300 (3.5899 iter/s, 27.8559s/100 iters), loss = 1.79072
I0426 14:30:42.109032  7834 solver.cpp:237]     Train net output #0: loss = 1.79072 (* 1 = 1.79072 loss)
I0426 14:30:42.109038  7834 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I0426 14:31:09.966279  7834 solver.cpp:218] Iteration 12400 (3.58973 iter/s, 27.8573s/100 iters), loss = 1.63587
I0426 14:31:09.966408  7834 solver.cpp:237]     Train net output #0: loss = 1.63587 (* 1 = 1.63587 loss)
I0426 14:31:09.966413  7834 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I0426 14:31:37.821549  7834 solver.cpp:218] Iteration 12500 (3.59 iter/s, 27.8552s/100 iters), loss = 1.42808
I0426 14:31:37.821578  7834 solver.cpp:237]     Train net output #0: loss = 1.42808 (* 1 = 1.42808 loss)
I0426 14:31:37.821584  7834 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I0426 14:32:05.676774  7834 solver.cpp:218] Iteration 12600 (3.58999 iter/s, 27.8552s/100 iters), loss = 1.63362
I0426 14:32:05.676910  7834 solver.cpp:237]     Train net output #0: loss = 1.63362 (* 1 = 1.63362 loss)
I0426 14:32:05.676918  7834 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I0426 14:32:33.537740  7834 solver.cpp:218] Iteration 12700 (3.58926 iter/s, 27.8609s/100 iters), loss = 1.54998
I0426 14:32:33.537768  7834 solver.cpp:237]     Train net output #0: loss = 1.54998 (* 1 = 1.54998 loss)
I0426 14:32:33.537775  7834 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I0426 14:33:01.396033  7834 solver.cpp:218] Iteration 12800 (3.5896 iter/s, 27.8583s/100 iters), loss = 1.24763
I0426 14:33:01.396131  7834 solver.cpp:237]     Train net output #0: loss = 1.24763 (* 1 = 1.24763 loss)
I0426 14:33:01.396138  7834 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I0426 14:33:29.255694  7834 solver.cpp:218] Iteration 12900 (3.58943 iter/s, 27.8596s/100 iters), loss = 1.38365
I0426 14:33:29.255724  7834 solver.cpp:237]     Train net output #0: loss = 1.38365 (* 1 = 1.38365 loss)
I0426 14:33:29.255730  7834 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I0426 14:33:56.818110  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_13000.caffemodel
I0426 14:33:56.871999  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_13000.solverstate
I0426 14:33:56.886682  7834 solver.cpp:330] Iteration 13000, Testing net (#0)
I0426 14:33:59.525683  7834 solver.cpp:397]     Test net output #0: loss = 1.25439 (* 1 = 1.25439 loss)
I0426 14:33:59.801555  7834 solver.cpp:218] Iteration 13000 (3.27377 iter/s, 30.5459s/100 iters), loss = 1.72109
I0426 14:33:59.801584  7834 solver.cpp:237]     Train net output #0: loss = 1.72109 (* 1 = 1.72109 loss)
I0426 14:33:59.801590  7834 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I0426 14:34:27.653892  7834 solver.cpp:218] Iteration 13100 (3.59036 iter/s, 27.8523s/100 iters), loss = 1.72112
I0426 14:34:27.654067  7834 solver.cpp:237]     Train net output #0: loss = 1.72112 (* 1 = 1.72112 loss)
I0426 14:34:27.654074  7834 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I0426 14:34:55.504624  7834 solver.cpp:218] Iteration 13200 (3.59059 iter/s, 27.8506s/100 iters), loss = 1.25499
I0426 14:34:55.504664  7834 solver.cpp:237]     Train net output #0: loss = 1.25499 (* 1 = 1.25499 loss)
I0426 14:34:55.504670  7834 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I0426 14:35:23.365329  7834 solver.cpp:218] Iteration 13300 (3.58929 iter/s, 27.8607s/100 iters), loss = 1.76405
I0426 14:35:23.365463  7834 solver.cpp:237]     Train net output #0: loss = 1.76405 (* 1 = 1.76405 loss)
I0426 14:35:23.365469  7834 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I0426 14:35:25.320276  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:35:51.225807  7834 solver.cpp:218] Iteration 13400 (3.58933 iter/s, 27.8604s/100 iters), loss = 1.74386
I0426 14:35:51.225836  7834 solver.cpp:237]     Train net output #0: loss = 1.74386 (* 1 = 1.74386 loss)
I0426 14:35:51.225842  7834 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I0426 14:36:19.078320  7834 solver.cpp:218] Iteration 13500 (3.59034 iter/s, 27.8525s/100 iters), loss = 1.64539
I0426 14:36:19.078466  7834 solver.cpp:237]     Train net output #0: loss = 1.64539 (* 1 = 1.64539 loss)
I0426 14:36:19.078474  7834 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I0426 14:36:46.935190  7834 solver.cpp:218] Iteration 13600 (3.58979 iter/s, 27.8568s/100 iters), loss = 1.53914
I0426 14:36:46.935220  7834 solver.cpp:237]     Train net output #0: loss = 1.53914 (* 1 = 1.53914 loss)
I0426 14:36:46.935225  7834 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I0426 14:37:14.789723  7834 solver.cpp:218] Iteration 13700 (3.59008 iter/s, 27.8545s/100 iters), loss = 1.45692
I0426 14:37:14.789824  7834 solver.cpp:237]     Train net output #0: loss = 1.45692 (* 1 = 1.45692 loss)
I0426 14:37:14.789830  7834 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I0426 14:37:42.644959  7834 solver.cpp:218] Iteration 13800 (3.59 iter/s, 27.8552s/100 iters), loss = 1.21882
I0426 14:37:42.644990  7834 solver.cpp:237]     Train net output #0: loss = 1.21882 (* 1 = 1.21882 loss)
I0426 14:37:42.644996  7834 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I0426 14:38:10.503373  7834 solver.cpp:218] Iteration 13900 (3.58958 iter/s, 27.8584s/100 iters), loss = 1.00962
I0426 14:38:10.503455  7834 solver.cpp:237]     Train net output #0: loss = 1.00962 (* 1 = 1.00962 loss)
I0426 14:38:10.503471  7834 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I0426 14:38:38.066129  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_14000.caffemodel
I0426 14:38:38.119278  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_14000.solverstate
I0426 14:38:38.133791  7834 solver.cpp:330] Iteration 14000, Testing net (#0)
I0426 14:38:40.771765  7834 solver.cpp:397]     Test net output #0: loss = 1.45629 (* 1 = 1.45629 loss)
I0426 14:38:41.047632  7834 solver.cpp:218] Iteration 14000 (3.27394 iter/s, 30.5442s/100 iters), loss = 1.57445
I0426 14:38:41.047659  7834 solver.cpp:237]     Train net output #0: loss = 1.57445 (* 1 = 1.57445 loss)
I0426 14:38:41.047665  7834 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I0426 14:39:08.909515  7834 solver.cpp:218] Iteration 14100 (3.58913 iter/s, 27.8619s/100 iters), loss = 1.17535
I0426 14:39:08.909545  7834 solver.cpp:237]     Train net output #0: loss = 1.17535 (* 1 = 1.17535 loss)
I0426 14:39:08.909551  7834 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I0426 14:39:36.772316  7834 solver.cpp:218] Iteration 14200 (3.58901 iter/s, 27.8628s/100 iters), loss = 1.74443
I0426 14:39:36.772486  7834 solver.cpp:237]     Train net output #0: loss = 1.74443 (* 1 = 1.74443 loss)
I0426 14:39:36.772495  7834 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I0426 14:40:04.633944  7834 solver.cpp:218] Iteration 14300 (3.58918 iter/s, 27.8615s/100 iters), loss = 1.94098
I0426 14:40:04.633972  7834 solver.cpp:237]     Train net output #0: loss = 1.94098 (* 1 = 1.94098 loss)
I0426 14:40:04.633978  7834 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I0426 14:40:32.490496  7834 solver.cpp:218] Iteration 14400 (3.58982 iter/s, 27.8566s/100 iters), loss = 1.74671
I0426 14:40:32.490556  7834 solver.cpp:237]     Train net output #0: loss = 1.74671 (* 1 = 1.74671 loss)
I0426 14:40:32.490562  7834 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I0426 14:41:00.348435  7834 solver.cpp:218] Iteration 14500 (3.58964 iter/s, 27.8579s/100 iters), loss = 1.41311
I0426 14:41:00.348464  7834 solver.cpp:237]     Train net output #0: loss = 1.41311 (* 1 = 1.41311 loss)
I0426 14:41:00.348470  7834 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I0426 14:41:28.207928  7834 solver.cpp:218] Iteration 14600 (3.58944 iter/s, 27.8595s/100 iters), loss = 1.31366
I0426 14:41:28.208003  7834 solver.cpp:237]     Train net output #0: loss = 1.31366 (* 1 = 1.31366 loss)
I0426 14:41:28.208019  7834 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I0426 14:41:56.066694  7834 solver.cpp:218] Iteration 14700 (3.58954 iter/s, 27.8587s/100 iters), loss = 1.45611
I0426 14:41:56.066721  7834 solver.cpp:237]     Train net output #0: loss = 1.45611 (* 1 = 1.45611 loss)
I0426 14:41:56.066727  7834 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I0426 14:42:23.925667  7834 solver.cpp:218] Iteration 14800 (3.58951 iter/s, 27.859s/100 iters), loss = 1.48985
I0426 14:42:23.925746  7834 solver.cpp:237]     Train net output #0: loss = 1.48985 (* 1 = 1.48985 loss)
I0426 14:42:23.925763  7834 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I0426 14:42:51.770777  7834 solver.cpp:218] Iteration 14900 (3.5913 iter/s, 27.8451s/100 iters), loss = 1.21483
I0426 14:42:51.770807  7834 solver.cpp:237]     Train net output #0: loss = 1.21483 (* 1 = 1.21483 loss)
I0426 14:42:51.770813  7834 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I0426 14:43:19.333420  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_15000.caffemodel
I0426 14:43:19.386241  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_15000.solverstate
I0426 14:43:19.400710  7834 solver.cpp:330] Iteration 15000, Testing net (#0)
I0426 14:43:22.039856  7834 solver.cpp:397]     Test net output #0: loss = 1.49348 (* 1 = 1.49348 loss)
I0426 14:43:22.316031  7834 solver.cpp:218] Iteration 15000 (3.27383 iter/s, 30.5453s/100 iters), loss = 1.7038
I0426 14:43:22.316061  7834 solver.cpp:237]     Train net output #0: loss = 1.7038 (* 1 = 1.7038 loss)
I0426 14:43:22.316066  7834 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I0426 14:43:50.172531  7834 solver.cpp:218] Iteration 15100 (3.58983 iter/s, 27.8565s/100 iters), loss = 1.30723
I0426 14:43:50.172629  7834 solver.cpp:237]     Train net output #0: loss = 1.30723 (* 1 = 1.30723 loss)
I0426 14:43:50.172636  7834 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I0426 14:44:18.030038  7834 solver.cpp:218] Iteration 15200 (3.5897 iter/s, 27.8574s/100 iters), loss = 1.38511
I0426 14:44:18.030066  7834 solver.cpp:237]     Train net output #0: loss = 1.38511 (* 1 = 1.38511 loss)
I0426 14:44:18.030071  7834 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I0426 14:44:45.884352  7834 solver.cpp:218] Iteration 15300 (3.59011 iter/s, 27.8543s/100 iters), loss = 1.43901
I0426 14:44:45.884433  7834 solver.cpp:237]     Train net output #0: loss = 1.43901 (* 1 = 1.43901 loss)
I0426 14:44:45.884449  7834 sgd_solver.cpp:105] Iteration 15300, lr = 0.001
I0426 14:45:13.741904  7834 solver.cpp:218] Iteration 15400 (3.5897 iter/s, 27.8575s/100 iters), loss = 1.77975
I0426 14:45:13.741935  7834 solver.cpp:237]     Train net output #0: loss = 1.77975 (* 1 = 1.77975 loss)
I0426 14:45:13.741940  7834 sgd_solver.cpp:105] Iteration 15400, lr = 0.001
I0426 14:45:41.602008  7834 solver.cpp:218] Iteration 15500 (3.58936 iter/s, 27.8601s/100 iters), loss = 1.12302
I0426 14:45:41.602114  7834 solver.cpp:237]     Train net output #0: loss = 1.12302 (* 1 = 1.12302 loss)
I0426 14:45:41.602123  7834 sgd_solver.cpp:105] Iteration 15500, lr = 0.001
I0426 14:46:09.462632  7834 solver.cpp:218] Iteration 15600 (3.5893 iter/s, 27.8606s/100 iters), loss = 1.78535
I0426 14:46:09.462662  7834 solver.cpp:237]     Train net output #0: loss = 1.78535 (* 1 = 1.78535 loss)
I0426 14:46:09.462667  7834 sgd_solver.cpp:105] Iteration 15600, lr = 0.001
I0426 14:46:37.322623  7834 solver.cpp:218] Iteration 15700 (3.58938 iter/s, 27.86s/100 iters), loss = 0.884032
I0426 14:46:37.322731  7834 solver.cpp:237]     Train net output #0: loss = 0.884032 (* 1 = 0.884032 loss)
I0426 14:46:37.322737  7834 sgd_solver.cpp:105] Iteration 15700, lr = 0.001
I0426 14:47:05.182607  7834 solver.cpp:218] Iteration 15800 (3.58939 iter/s, 27.8599s/100 iters), loss = 1.75614
I0426 14:47:05.182637  7834 solver.cpp:237]     Train net output #0: loss = 1.75614 (* 1 = 1.75614 loss)
I0426 14:47:05.182642  7834 sgd_solver.cpp:105] Iteration 15800, lr = 0.001
I0426 14:47:33.038669  7834 solver.cpp:218] Iteration 15900 (3.58988 iter/s, 27.8561s/100 iters), loss = 1.79802
I0426 14:47:33.038816  7834 solver.cpp:237]     Train net output #0: loss = 1.79802 (* 1 = 1.79802 loss)
I0426 14:47:33.038823  7834 sgd_solver.cpp:105] Iteration 15900, lr = 0.001
I0426 14:47:52.268062  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 14:48:00.603610  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_16000.caffemodel
I0426 14:48:00.656513  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_16000.solverstate
I0426 14:48:00.670991  7834 solver.cpp:330] Iteration 16000, Testing net (#0)
I0426 14:48:03.311708  7834 solver.cpp:397]     Test net output #0: loss = 1.54945 (* 1 = 1.54945 loss)
I0426 14:48:03.587731  7834 solver.cpp:218] Iteration 16000 (3.27343 iter/s, 30.549s/100 iters), loss = 1.89497
I0426 14:48:03.587759  7834 solver.cpp:237]     Train net output #0: loss = 1.89497 (* 1 = 1.89497 loss)
I0426 14:48:03.587765  7834 sgd_solver.cpp:105] Iteration 16000, lr = 0.001
I0426 14:48:31.447614  7834 solver.cpp:218] Iteration 16100 (3.58939 iter/s, 27.8599s/100 iters), loss = 1.37167
I0426 14:48:31.447643  7834 solver.cpp:237]     Train net output #0: loss = 1.37167 (* 1 = 1.37167 loss)
I0426 14:48:31.447649  7834 sgd_solver.cpp:105] Iteration 16100, lr = 0.001
I0426 14:48:59.304064  7834 solver.cpp:218] Iteration 16200 (3.58983 iter/s, 27.8565s/100 iters), loss = 1.70272
I0426 14:48:59.304203  7834 solver.cpp:237]     Train net output #0: loss = 1.70272 (* 1 = 1.70272 loss)
I0426 14:48:59.304211  7834 sgd_solver.cpp:105] Iteration 16200, lr = 0.001
I0426 14:49:27.166947  7834 solver.cpp:218] Iteration 16300 (3.58902 iter/s, 27.8628s/100 iters), loss = 1.4641
I0426 14:49:27.166976  7834 solver.cpp:237]     Train net output #0: loss = 1.4641 (* 1 = 1.4641 loss)
I0426 14:49:27.166982  7834 sgd_solver.cpp:105] Iteration 16300, lr = 0.001
I0426 14:49:55.029145  7834 solver.cpp:218] Iteration 16400 (3.58909 iter/s, 27.8622s/100 iters), loss = 1.64203
I0426 14:49:55.029255  7834 solver.cpp:237]     Train net output #0: loss = 1.64203 (* 1 = 1.64203 loss)
I0426 14:49:55.029263  7834 sgd_solver.cpp:105] Iteration 16400, lr = 0.001
I0426 14:50:22.891016  7834 solver.cpp:218] Iteration 16500 (3.58914 iter/s, 27.8618s/100 iters), loss = 1.25283
I0426 14:50:22.891046  7834 solver.cpp:237]     Train net output #0: loss = 1.25283 (* 1 = 1.25283 loss)
I0426 14:50:22.891050  7834 sgd_solver.cpp:105] Iteration 16500, lr = 0.001
I0426 14:50:50.752557  7834 solver.cpp:218] Iteration 16600 (3.58918 iter/s, 27.8616s/100 iters), loss = 1.3115
I0426 14:50:50.752713  7834 solver.cpp:237]     Train net output #0: loss = 1.3115 (* 1 = 1.3115 loss)
I0426 14:50:50.752720  7834 sgd_solver.cpp:105] Iteration 16600, lr = 0.001
I0426 14:51:18.615136  7834 solver.cpp:218] Iteration 16700 (3.58906 iter/s, 27.8625s/100 iters), loss = 1.59516
I0426 14:51:18.615166  7834 solver.cpp:237]     Train net output #0: loss = 1.59516 (* 1 = 1.59516 loss)
I0426 14:51:18.615172  7834 sgd_solver.cpp:105] Iteration 16700, lr = 0.001
I0426 14:51:46.474637  7834 solver.cpp:218] Iteration 16800 (3.58944 iter/s, 27.8595s/100 iters), loss = 1.40395
I0426 14:51:46.474697  7834 solver.cpp:237]     Train net output #0: loss = 1.40395 (* 1 = 1.40395 loss)
I0426 14:51:46.474715  7834 sgd_solver.cpp:105] Iteration 16800, lr = 0.001
I0426 14:52:14.340724  7834 solver.cpp:218] Iteration 16900 (3.58859 iter/s, 27.8661s/100 iters), loss = 1.58307
I0426 14:52:14.340754  7834 solver.cpp:237]     Train net output #0: loss = 1.58307 (* 1 = 1.58307 loss)
I0426 14:52:14.340759  7834 sgd_solver.cpp:105] Iteration 16900, lr = 0.001
I0426 14:52:41.910337  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_17000.caffemodel
I0426 14:52:41.963366  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_17000.solverstate
I0426 14:52:41.978266  7834 solver.cpp:330] Iteration 17000, Testing net (#0)
I0426 14:52:44.616904  7834 solver.cpp:397]     Test net output #0: loss = 1.43919 (* 1 = 1.43919 loss)
I0426 14:52:44.893031  7834 solver.cpp:218] Iteration 17000 (3.27307 iter/s, 30.5523s/100 iters), loss = 1.46784
I0426 14:52:44.893060  7834 solver.cpp:237]     Train net output #0: loss = 1.46784 (* 1 = 1.46784 loss)
I0426 14:52:44.893066  7834 sgd_solver.cpp:105] Iteration 17000, lr = 0.001
I0426 14:53:12.751004  7834 solver.cpp:218] Iteration 17100 (3.58964 iter/s, 27.858s/100 iters), loss = 1.49357
I0426 14:53:12.751070  7834 solver.cpp:237]     Train net output #0: loss = 1.49357 (* 1 = 1.49357 loss)
I0426 14:53:12.751076  7834 sgd_solver.cpp:105] Iteration 17100, lr = 0.001
I0426 14:53:40.611451  7834 solver.cpp:218] Iteration 17200 (3.58932 iter/s, 27.8604s/100 iters), loss = 1.40465
I0426 14:53:40.611479  7834 solver.cpp:237]     Train net output #0: loss = 1.40465 (* 1 = 1.40465 loss)
I0426 14:53:40.611485  7834 sgd_solver.cpp:105] Iteration 17200, lr = 0.001
I0426 14:54:08.471547  7834 solver.cpp:218] Iteration 17300 (3.58936 iter/s, 27.8601s/100 iters), loss = 1.70032
I0426 14:54:08.471645  7834 solver.cpp:237]     Train net output #0: loss = 1.70032 (* 1 = 1.70032 loss)
I0426 14:54:08.471652  7834 sgd_solver.cpp:105] Iteration 17300, lr = 0.001
I0426 14:54:36.321408  7834 solver.cpp:218] Iteration 17400 (3.59069 iter/s, 27.8498s/100 iters), loss = 1.6712
I0426 14:54:36.321437  7834 solver.cpp:237]     Train net output #0: loss = 1.6712 (* 1 = 1.6712 loss)
I0426 14:54:36.321444  7834 sgd_solver.cpp:105] Iteration 17400, lr = 0.001
I0426 14:55:04.193593  7834 solver.cpp:218] Iteration 17500 (3.58781 iter/s, 27.8721s/100 iters), loss = 1.50489
I0426 14:55:04.193687  7834 solver.cpp:237]     Train net output #0: loss = 1.50489 (* 1 = 1.50489 loss)
I0426 14:55:04.193704  7834 sgd_solver.cpp:105] Iteration 17500, lr = 0.001
I0426 14:55:32.053099  7834 solver.cpp:218] Iteration 17600 (3.58945 iter/s, 27.8594s/100 iters), loss = 1.53856
I0426 14:55:32.053128  7834 solver.cpp:237]     Train net output #0: loss = 1.53856 (* 1 = 1.53856 loss)
I0426 14:55:32.053133  7834 sgd_solver.cpp:105] Iteration 17600, lr = 0.001
I0426 14:55:59.915096  7834 solver.cpp:218] Iteration 17700 (3.58912 iter/s, 27.862s/100 iters), loss = 1.18235
I0426 14:55:59.915169  7834 solver.cpp:237]     Train net output #0: loss = 1.18235 (* 1 = 1.18235 loss)
I0426 14:55:59.915185  7834 sgd_solver.cpp:105] Iteration 17700, lr = 0.001
I0426 14:56:27.775354  7834 solver.cpp:218] Iteration 17800 (3.58935 iter/s, 27.8602s/100 iters), loss = 1.48271
I0426 14:56:27.775382  7834 solver.cpp:237]     Train net output #0: loss = 1.48271 (* 1 = 1.48271 loss)
I0426 14:56:27.775388  7834 sgd_solver.cpp:105] Iteration 17800, lr = 0.001
I0426 14:56:55.640318  7834 solver.cpp:218] Iteration 17900 (3.58874 iter/s, 27.8649s/100 iters), loss = 1.4193
I0426 14:56:55.640424  7834 solver.cpp:237]     Train net output #0: loss = 1.4193 (* 1 = 1.4193 loss)
I0426 14:56:55.640439  7834 sgd_solver.cpp:105] Iteration 17900, lr = 0.001
I0426 14:57:23.208675  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_18000.caffemodel
I0426 14:57:23.262529  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_18000.solverstate
I0426 14:57:23.277451  7834 solver.cpp:330] Iteration 18000, Testing net (#0)
I0426 14:57:25.916898  7834 solver.cpp:397]     Test net output #0: loss = 1.34226 (* 1 = 1.34226 loss)
I0426 14:57:26.193092  7834 solver.cpp:218] Iteration 18000 (3.27304 iter/s, 30.5527s/100 iters), loss = 1.23351
I0426 14:57:26.193120  7834 solver.cpp:237]     Train net output #0: loss = 1.23351 (* 1 = 1.23351 loss)
I0426 14:57:26.193125  7834 sgd_solver.cpp:105] Iteration 18000, lr = 0.001
I0426 14:57:54.059752  7834 solver.cpp:218] Iteration 18100 (3.58852 iter/s, 27.8666s/100 iters), loss = 1.44887
I0426 14:57:54.059782  7834 solver.cpp:237]     Train net output #0: loss = 1.44887 (* 1 = 1.44887 loss)
I0426 14:57:54.059787  7834 sgd_solver.cpp:105] Iteration 18100, lr = 0.001
I0426 14:58:21.924099  7834 solver.cpp:218] Iteration 18200 (3.58882 iter/s, 27.8643s/100 iters), loss = 1.41139
I0426 14:58:21.924212  7834 solver.cpp:237]     Train net output #0: loss = 1.41139 (* 1 = 1.41139 loss)
I0426 14:58:21.924221  7834 sgd_solver.cpp:105] Iteration 18200, lr = 0.001
I0426 14:58:49.789158  7834 solver.cpp:218] Iteration 18300 (3.58874 iter/s, 27.8649s/100 iters), loss = 1.73954
I0426 14:58:49.789187  7834 solver.cpp:237]     Train net output #0: loss = 1.73954 (* 1 = 1.73954 loss)
I0426 14:58:49.789192  7834 sgd_solver.cpp:105] Iteration 18300, lr = 0.001
I0426 14:59:17.652179  7834 solver.cpp:218] Iteration 18400 (3.58899 iter/s, 27.863s/100 iters), loss = 1.89705
I0426 14:59:17.652225  7834 solver.cpp:237]     Train net output #0: loss = 1.89705 (* 1 = 1.89705 loss)
I0426 14:59:17.652231  7834 sgd_solver.cpp:105] Iteration 18400, lr = 0.001
I0426 14:59:45.512991  7834 solver.cpp:218] Iteration 18500 (3.58928 iter/s, 27.8608s/100 iters), loss = 1.3645
I0426 14:59:45.513020  7834 solver.cpp:237]     Train net output #0: loss = 1.3645 (* 1 = 1.3645 loss)
I0426 14:59:45.513025  7834 sgd_solver.cpp:105] Iteration 18500, lr = 0.001
I0426 15:00:13.373921  7834 solver.cpp:218] Iteration 18600 (3.58926 iter/s, 27.8609s/100 iters), loss = 1.41876
I0426 15:00:13.374063  7834 solver.cpp:237]     Train net output #0: loss = 1.41876 (* 1 = 1.41876 loss)
I0426 15:00:13.374070  7834 sgd_solver.cpp:105] Iteration 18600, lr = 0.001
I0426 15:00:22.293222  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:00:41.237558  7834 solver.cpp:218] Iteration 18700 (3.58893 iter/s, 27.8635s/100 iters), loss = 1.5557
I0426 15:00:41.237587  7834 solver.cpp:237]     Train net output #0: loss = 1.5557 (* 1 = 1.5557 loss)
I0426 15:00:41.237593  7834 sgd_solver.cpp:105] Iteration 18700, lr = 0.001
I0426 15:01:09.104656  7834 solver.cpp:218] Iteration 18800 (3.58847 iter/s, 27.8671s/100 iters), loss = 1.67323
I0426 15:01:09.104735  7834 solver.cpp:237]     Train net output #0: loss = 1.67323 (* 1 = 1.67323 loss)
I0426 15:01:09.104751  7834 sgd_solver.cpp:105] Iteration 18800, lr = 0.001
I0426 15:01:36.992652  7834 solver.cpp:218] Iteration 18900 (3.58578 iter/s, 27.8879s/100 iters), loss = 1.54859
I0426 15:01:36.992682  7834 solver.cpp:237]     Train net output #0: loss = 1.54859 (* 1 = 1.54859 loss)
I0426 15:01:36.992687  7834 sgd_solver.cpp:105] Iteration 18900, lr = 0.001
I0426 15:02:04.565443  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_19000.caffemodel
I0426 15:02:04.618520  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_19000.solverstate
I0426 15:02:04.633147  7834 solver.cpp:330] Iteration 19000, Testing net (#0)
I0426 15:02:07.273180  7834 solver.cpp:397]     Test net output #0: loss = 1.69892 (* 1 = 1.69892 loss)
I0426 15:02:07.549386  7834 solver.cpp:218] Iteration 19000 (3.2726 iter/s, 30.5567s/100 iters), loss = 0.9829
I0426 15:02:07.549412  7834 solver.cpp:237]     Train net output #0: loss = 0.9829 (* 1 = 0.9829 loss)
I0426 15:02:07.549418  7834 sgd_solver.cpp:105] Iteration 19000, lr = 0.001
I0426 15:02:35.431529  7834 solver.cpp:218] Iteration 19100 (3.58653 iter/s, 27.8821s/100 iters), loss = 1.45792
I0426 15:02:35.431620  7834 solver.cpp:237]     Train net output #0: loss = 1.45792 (* 1 = 1.45792 loss)
I0426 15:02:35.431635  7834 sgd_solver.cpp:105] Iteration 19100, lr = 0.001
I0426 15:03:03.287716  7834 solver.cpp:218] Iteration 19200 (3.58988 iter/s, 27.8561s/100 iters), loss = 1.57104
I0426 15:03:03.287746  7834 solver.cpp:237]     Train net output #0: loss = 1.57104 (* 1 = 1.57104 loss)
I0426 15:03:03.287751  7834 sgd_solver.cpp:105] Iteration 19200, lr = 0.001
I0426 15:03:31.145181  7834 solver.cpp:218] Iteration 19300 (3.58971 iter/s, 27.8574s/100 iters), loss = 1.56928
I0426 15:03:31.145287  7834 solver.cpp:237]     Train net output #0: loss = 1.56928 (* 1 = 1.56928 loss)
I0426 15:03:31.145292  7834 sgd_solver.cpp:105] Iteration 19300, lr = 0.001
I0426 15:03:59.002699  7834 solver.cpp:218] Iteration 19400 (3.58971 iter/s, 27.8574s/100 iters), loss = 1.38913
I0426 15:03:59.002728  7834 solver.cpp:237]     Train net output #0: loss = 1.38913 (* 1 = 1.38913 loss)
I0426 15:03:59.002734  7834 sgd_solver.cpp:105] Iteration 19400, lr = 0.001
I0426 15:04:26.858155  7834 solver.cpp:218] Iteration 19500 (3.58997 iter/s, 27.8554s/100 iters), loss = 1.16683
I0426 15:04:26.858253  7834 solver.cpp:237]     Train net output #0: loss = 1.16683 (* 1 = 1.16683 loss)
I0426 15:04:26.858269  7834 sgd_solver.cpp:105] Iteration 19500, lr = 0.001
I0426 15:04:54.713853  7834 solver.cpp:218] Iteration 19600 (3.58994 iter/s, 27.8556s/100 iters), loss = 1.53882
I0426 15:04:54.713882  7834 solver.cpp:237]     Train net output #0: loss = 1.53882 (* 1 = 1.53882 loss)
I0426 15:04:54.713887  7834 sgd_solver.cpp:105] Iteration 19600, lr = 0.001
I0426 15:05:22.584367  7834 solver.cpp:218] Iteration 19700 (3.58803 iter/s, 27.8705s/100 iters), loss = 1.45392
I0426 15:05:22.584513  7834 solver.cpp:237]     Train net output #0: loss = 1.45392 (* 1 = 1.45392 loss)
I0426 15:05:22.584522  7834 sgd_solver.cpp:105] Iteration 19700, lr = 0.001
I0426 15:05:50.473114  7834 solver.cpp:218] Iteration 19800 (3.58569 iter/s, 27.8886s/100 iters), loss = 1.42593
I0426 15:05:50.473142  7834 solver.cpp:237]     Train net output #0: loss = 1.42593 (* 1 = 1.42593 loss)
I0426 15:05:50.473148  7834 sgd_solver.cpp:105] Iteration 19800, lr = 0.001
I0426 15:06:18.331614  7834 solver.cpp:218] Iteration 19900 (3.58957 iter/s, 27.8585s/100 iters), loss = 1.08577
I0426 15:06:18.331715  7834 solver.cpp:237]     Train net output #0: loss = 1.08577 (* 1 = 1.08577 loss)
I0426 15:06:18.331722  7834 sgd_solver.cpp:105] Iteration 19900, lr = 0.001
I0426 15:06:45.895763  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_20000.caffemodel
I0426 15:06:45.949002  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_20000.solverstate
I0426 15:06:45.963649  7834 solver.cpp:330] Iteration 20000, Testing net (#0)
I0426 15:06:48.602952  7834 solver.cpp:397]     Test net output #0: loss = 1.65421 (* 1 = 1.65421 loss)
I0426 15:06:48.878945  7834 solver.cpp:218] Iteration 20000 (3.27362 iter/s, 30.5472s/100 iters), loss = 1.07781
I0426 15:06:48.878973  7834 solver.cpp:237]     Train net output #0: loss = 1.07781 (* 1 = 1.07781 loss)
I0426 15:06:48.878978  7834 sgd_solver.cpp:105] Iteration 20000, lr = 0.0001
I0426 15:07:16.735859  7834 solver.cpp:218] Iteration 20100 (3.58978 iter/s, 27.8569s/100 iters), loss = 1.12415
I0426 15:07:16.735886  7834 solver.cpp:237]     Train net output #0: loss = 1.12415 (* 1 = 1.12415 loss)
I0426 15:07:16.735893  7834 sgd_solver.cpp:105] Iteration 20100, lr = 0.0001
I0426 15:07:44.595787  7834 solver.cpp:218] Iteration 20200 (3.58939 iter/s, 27.8599s/100 iters), loss = 1.25948
I0426 15:07:44.595907  7834 solver.cpp:237]     Train net output #0: loss = 1.25948 (* 1 = 1.25948 loss)
I0426 15:07:44.595914  7834 sgd_solver.cpp:105] Iteration 20200, lr = 0.0001
I0426 15:08:12.457561  7834 solver.cpp:218] Iteration 20300 (3.58916 iter/s, 27.8617s/100 iters), loss = 1.21622
I0426 15:08:12.457588  7834 solver.cpp:237]     Train net output #0: loss = 1.21622 (* 1 = 1.21622 loss)
I0426 15:08:12.457594  7834 sgd_solver.cpp:105] Iteration 20300, lr = 0.0001
I0426 15:08:40.330178  7834 solver.cpp:218] Iteration 20400 (3.58776 iter/s, 27.8726s/100 iters), loss = 1.05994
I0426 15:08:40.330245  7834 solver.cpp:237]     Train net output #0: loss = 1.05994 (* 1 = 1.05994 loss)
I0426 15:08:40.330252  7834 sgd_solver.cpp:105] Iteration 20400, lr = 0.0001
I0426 15:09:08.224758  7834 solver.cpp:218] Iteration 20500 (3.58493 iter/s, 27.8945s/100 iters), loss = 1.08967
I0426 15:09:08.224786  7834 solver.cpp:237]     Train net output #0: loss = 1.08967 (* 1 = 1.08967 loss)
I0426 15:09:08.224792  7834 sgd_solver.cpp:105] Iteration 20500, lr = 0.0001
I0426 15:09:36.090209  7834 solver.cpp:218] Iteration 20600 (3.58868 iter/s, 27.8654s/100 iters), loss = 0.935188
I0426 15:09:36.090348  7834 solver.cpp:237]     Train net output #0: loss = 0.935188 (* 1 = 0.935188 loss)
I0426 15:09:36.090355  7834 sgd_solver.cpp:105] Iteration 20600, lr = 0.0001
I0426 15:10:03.953290  7834 solver.cpp:218] Iteration 20700 (3.589 iter/s, 27.8629s/100 iters), loss = 1.02615
I0426 15:10:03.953318  7834 solver.cpp:237]     Train net output #0: loss = 1.02615 (* 1 = 1.02615 loss)
I0426 15:10:03.953323  7834 sgd_solver.cpp:105] Iteration 20700, lr = 0.0001
I0426 15:10:31.812669  7834 solver.cpp:218] Iteration 20800 (3.58946 iter/s, 27.8593s/100 iters), loss = 0.949287
I0426 15:10:31.812750  7834 solver.cpp:237]     Train net output #0: loss = 0.949287 (* 1 = 0.949287 loss)
I0426 15:10:31.812767  7834 sgd_solver.cpp:105] Iteration 20800, lr = 0.0001
I0426 15:10:59.676462  7834 solver.cpp:218] Iteration 20900 (3.5889 iter/s, 27.8637s/100 iters), loss = 1.38922
I0426 15:10:59.676491  7834 solver.cpp:237]     Train net output #0: loss = 1.38922 (* 1 = 1.38922 loss)
I0426 15:10:59.676496  7834 sgd_solver.cpp:105] Iteration 20900, lr = 0.0001
I0426 15:11:27.247754  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_21000.caffemodel
I0426 15:11:27.301542  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_21000.solverstate
I0426 15:11:27.316629  7834 solver.cpp:330] Iteration 21000, Testing net (#0)
I0426 15:11:29.955564  7834 solver.cpp:397]     Test net output #0: loss = 1.14349 (* 1 = 1.14349 loss)
I0426 15:11:30.231431  7834 solver.cpp:218] Iteration 21000 (3.27279 iter/s, 30.5549s/100 iters), loss = 0.979362
I0426 15:11:30.231461  7834 solver.cpp:237]     Train net output #0: loss = 0.979362 (* 1 = 0.979362 loss)
I0426 15:11:30.231467  7834 sgd_solver.cpp:105] Iteration 21000, lr = 0.0001
I0426 15:11:58.096349  7834 solver.cpp:218] Iteration 21100 (3.58875 iter/s, 27.8649s/100 iters), loss = 1.02063
I0426 15:11:58.096483  7834 solver.cpp:237]     Train net output #0: loss = 1.02063 (* 1 = 1.02063 loss)
I0426 15:11:58.096490  7834 sgd_solver.cpp:105] Iteration 21100, lr = 0.0001
I0426 15:12:25.958941  7834 solver.cpp:218] Iteration 21200 (3.58906 iter/s, 27.8625s/100 iters), loss = 0.992502
I0426 15:12:25.958971  7834 solver.cpp:237]     Train net output #0: loss = 0.992502 (* 1 = 0.992502 loss)
I0426 15:12:25.958976  7834 sgd_solver.cpp:105] Iteration 21200, lr = 0.0001
I0426 15:12:52.148856  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:12:53.815315  7834 solver.cpp:218] Iteration 21300 (3.58985 iter/s, 27.8563s/100 iters), loss = 1.06096
I0426 15:12:53.815353  7834 solver.cpp:237]     Train net output #0: loss = 1.06096 (* 1 = 1.06096 loss)
I0426 15:12:53.815359  7834 sgd_solver.cpp:105] Iteration 21300, lr = 0.0001
I0426 15:13:21.674329  7834 solver.cpp:218] Iteration 21400 (3.58951 iter/s, 27.859s/100 iters), loss = 1.0161
I0426 15:13:21.674367  7834 solver.cpp:237]     Train net output #0: loss = 1.0161 (* 1 = 1.0161 loss)
I0426 15:13:21.674373  7834 sgd_solver.cpp:105] Iteration 21400, lr = 0.0001
I0426 15:13:49.530781  7834 solver.cpp:218] Iteration 21500 (3.58984 iter/s, 27.8564s/100 iters), loss = 1.15803
I0426 15:13:49.530926  7834 solver.cpp:237]     Train net output #0: loss = 1.15803 (* 1 = 1.15803 loss)
I0426 15:13:49.530932  7834 sgd_solver.cpp:105] Iteration 21500, lr = 0.0001
I0426 15:14:17.394242  7834 solver.cpp:218] Iteration 21600 (3.58895 iter/s, 27.8633s/100 iters), loss = 0.92969
I0426 15:14:17.394269  7834 solver.cpp:237]     Train net output #0: loss = 0.92969 (* 1 = 0.92969 loss)
I0426 15:14:17.394275  7834 sgd_solver.cpp:105] Iteration 21600, lr = 0.0001
I0426 15:14:45.257421  7834 solver.cpp:218] Iteration 21700 (3.58897 iter/s, 27.8632s/100 iters), loss = 0.791696
I0426 15:14:45.257526  7834 solver.cpp:237]     Train net output #0: loss = 0.791696 (* 1 = 0.791696 loss)
I0426 15:14:45.257534  7834 sgd_solver.cpp:105] Iteration 21700, lr = 0.0001
I0426 15:15:13.122625  7834 solver.cpp:218] Iteration 21800 (3.58872 iter/s, 27.8651s/100 iters), loss = 0.72059
I0426 15:15:13.122654  7834 solver.cpp:237]     Train net output #0: loss = 0.72059 (* 1 = 0.72059 loss)
I0426 15:15:13.122660  7834 sgd_solver.cpp:105] Iteration 21800, lr = 0.0001
I0426 15:15:40.983134  7834 solver.cpp:218] Iteration 21900 (3.58931 iter/s, 27.8605s/100 iters), loss = 1.1313
I0426 15:15:40.983242  7834 solver.cpp:237]     Train net output #0: loss = 1.1313 (* 1 = 1.1313 loss)
I0426 15:15:40.983248  7834 sgd_solver.cpp:105] Iteration 21900, lr = 0.0001
I0426 15:16:08.549679  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_22000.caffemodel
I0426 15:16:08.603138  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_22000.solverstate
I0426 15:16:08.617805  7834 solver.cpp:330] Iteration 22000, Testing net (#0)
I0426 15:16:11.257450  7834 solver.cpp:397]     Test net output #0: loss = 1.24181 (* 1 = 1.24181 loss)
I0426 15:16:11.533530  7834 solver.cpp:218] Iteration 22000 (3.27329 iter/s, 30.5503s/100 iters), loss = 0.935612
I0426 15:16:11.533557  7834 solver.cpp:237]     Train net output #0: loss = 0.935612 (* 1 = 0.935612 loss)
I0426 15:16:11.533563  7834 sgd_solver.cpp:105] Iteration 22000, lr = 0.0001
I0426 15:16:39.400921  7834 solver.cpp:218] Iteration 22100 (3.58843 iter/s, 27.8674s/100 iters), loss = 0.737862
I0426 15:16:39.400956  7834 solver.cpp:237]     Train net output #0: loss = 0.737862 (* 1 = 0.737862 loss)
I0426 15:16:39.400964  7834 sgd_solver.cpp:105] Iteration 22100, lr = 0.0001
I0426 15:17:07.264436  7834 solver.cpp:218] Iteration 22200 (3.58893 iter/s, 27.8635s/100 iters), loss = 0.932048
I0426 15:17:07.264518  7834 solver.cpp:237]     Train net output #0: loss = 0.932048 (* 1 = 0.932048 loss)
I0426 15:17:07.264533  7834 sgd_solver.cpp:105] Iteration 22200, lr = 0.0001
I0426 15:17:35.128849  7834 solver.cpp:218] Iteration 22300 (3.58882 iter/s, 27.8643s/100 iters), loss = 0.895257
I0426 15:17:35.128878  7834 solver.cpp:237]     Train net output #0: loss = 0.895257 (* 1 = 0.895257 loss)
I0426 15:17:35.128885  7834 sgd_solver.cpp:105] Iteration 22300, lr = 0.0001
I0426 15:18:02.992211  7834 solver.cpp:218] Iteration 22400 (3.58895 iter/s, 27.8633s/100 iters), loss = 0.912469
I0426 15:18:02.992390  7834 solver.cpp:237]     Train net output #0: loss = 0.912469 (* 1 = 0.912469 loss)
I0426 15:18:02.992398  7834 sgd_solver.cpp:105] Iteration 22400, lr = 0.0001
I0426 15:18:30.853873  7834 solver.cpp:218] Iteration 22500 (3.58918 iter/s, 27.8615s/100 iters), loss = 0.889608
I0426 15:18:30.853902  7834 solver.cpp:237]     Train net output #0: loss = 0.889608 (* 1 = 0.889608 loss)
I0426 15:18:30.853909  7834 sgd_solver.cpp:105] Iteration 22500, lr = 0.0001
I0426 15:18:58.723536  7834 solver.cpp:218] Iteration 22600 (3.58813 iter/s, 27.8696s/100 iters), loss = 1.27274
I0426 15:18:58.723639  7834 solver.cpp:237]     Train net output #0: loss = 1.27274 (* 1 = 1.27274 loss)
I0426 15:18:58.723645  7834 sgd_solver.cpp:105] Iteration 22600, lr = 0.0001
I0426 15:19:26.585213  7834 solver.cpp:218] Iteration 22700 (3.58917 iter/s, 27.8616s/100 iters), loss = 1.25001
I0426 15:19:26.585242  7834 solver.cpp:237]     Train net output #0: loss = 1.25001 (* 1 = 1.25001 loss)
I0426 15:19:26.585247  7834 sgd_solver.cpp:105] Iteration 22700, lr = 0.0001
I0426 15:19:54.444903  7834 solver.cpp:218] Iteration 22800 (3.58942 iter/s, 27.8597s/100 iters), loss = 0.990195
I0426 15:19:54.445020  7834 solver.cpp:237]     Train net output #0: loss = 0.990195 (* 1 = 0.990195 loss)
I0426 15:19:54.445027  7834 sgd_solver.cpp:105] Iteration 22800, lr = 0.0001
I0426 15:20:22.309980  7834 solver.cpp:218] Iteration 22900 (3.58874 iter/s, 27.865s/100 iters), loss = 0.87708
I0426 15:20:22.310009  7834 solver.cpp:237]     Train net output #0: loss = 0.87708 (* 1 = 0.87708 loss)
I0426 15:20:22.310014  7834 sgd_solver.cpp:105] Iteration 22900, lr = 0.0001
I0426 15:20:49.880384  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_23000.caffemodel
I0426 15:20:49.933806  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_23000.solverstate
I0426 15:20:49.949152  7834 solver.cpp:330] Iteration 23000, Testing net (#0)
I0426 15:20:52.589510  7834 solver.cpp:397]     Test net output #0: loss = 1.33071 (* 1 = 1.33071 loss)
I0426 15:20:52.865782  7834 solver.cpp:218] Iteration 23000 (3.2727 iter/s, 30.5558s/100 iters), loss = 1.16688
I0426 15:20:52.865808  7834 solver.cpp:237]     Train net output #0: loss = 1.16688 (* 1 = 1.16688 loss)
I0426 15:20:52.865814  7834 sgd_solver.cpp:105] Iteration 23000, lr = 0.0001
I0426 15:21:20.727320  7834 solver.cpp:218] Iteration 23100 (3.58918 iter/s, 27.8615s/100 iters), loss = 0.901351
I0426 15:21:20.727424  7834 solver.cpp:237]     Train net output #0: loss = 0.901351 (* 1 = 0.901351 loss)
I0426 15:21:20.727430  7834 sgd_solver.cpp:105] Iteration 23100, lr = 0.0001
I0426 15:21:48.588505  7834 solver.cpp:218] Iteration 23200 (3.58923 iter/s, 27.8611s/100 iters), loss = 0.924719
I0426 15:21:48.588536  7834 solver.cpp:237]     Train net output #0: loss = 0.924719 (* 1 = 0.924719 loss)
I0426 15:21:48.588541  7834 sgd_solver.cpp:105] Iteration 23200, lr = 0.0001
I0426 15:22:16.454044  7834 solver.cpp:218] Iteration 23300 (3.58867 iter/s, 27.8655s/100 iters), loss = 0.925009
I0426 15:22:16.454124  7834 solver.cpp:237]     Train net output #0: loss = 0.925009 (* 1 = 0.925009 loss)
I0426 15:22:16.454140  7834 sgd_solver.cpp:105] Iteration 23300, lr = 0.0001
I0426 15:22:44.318912  7834 solver.cpp:218] Iteration 23400 (3.58876 iter/s, 27.8648s/100 iters), loss = 1.11106
I0426 15:22:44.318939  7834 solver.cpp:237]     Train net output #0: loss = 1.11106 (* 1 = 1.11106 loss)
I0426 15:22:44.318944  7834 sgd_solver.cpp:105] Iteration 23400, lr = 0.0001
I0426 15:23:12.183210  7834 solver.cpp:218] Iteration 23500 (3.58882 iter/s, 27.8643s/100 iters), loss = 0.872959
I0426 15:23:12.183334  7834 solver.cpp:237]     Train net output #0: loss = 0.872959 (* 1 = 0.872959 loss)
I0426 15:23:12.183341  7834 sgd_solver.cpp:105] Iteration 23500, lr = 0.0001
I0426 15:23:40.043296  7834 solver.cpp:218] Iteration 23600 (3.58938 iter/s, 27.86s/100 iters), loss = 0.942471
I0426 15:23:40.043325  7834 solver.cpp:237]     Train net output #0: loss = 0.942471 (* 1 = 0.942471 loss)
I0426 15:23:40.043330  7834 sgd_solver.cpp:105] Iteration 23600, lr = 0.0001
I0426 15:24:07.905761  7834 solver.cpp:218] Iteration 23700 (3.58906 iter/s, 27.8624s/100 iters), loss = 0.807596
I0426 15:24:07.905860  7834 solver.cpp:237]     Train net output #0: loss = 0.807596 (* 1 = 0.807596 loss)
I0426 15:24:07.905866  7834 sgd_solver.cpp:105] Iteration 23700, lr = 0.0001
I0426 15:24:35.779713  7834 solver.cpp:218] Iteration 23800 (3.58759 iter/s, 27.8739s/100 iters), loss = 0.915291
I0426 15:24:35.779742  7834 solver.cpp:237]     Train net output #0: loss = 0.915291 (* 1 = 0.915291 loss)
I0426 15:24:35.779747  7834 sgd_solver.cpp:105] Iteration 23800, lr = 0.0001
I0426 15:25:03.681401  7834 solver.cpp:218] Iteration 23900 (3.58402 iter/s, 27.9017s/100 iters), loss = 0.945203
I0426 15:25:03.681553  7834 solver.cpp:237]     Train net output #0: loss = 0.945203 (* 1 = 0.945203 loss)
I0426 15:25:03.681561  7834 sgd_solver.cpp:105] Iteration 23900, lr = 0.0001
I0426 15:25:19.306972  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:25:31.261703  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_24000.caffemodel
I0426 15:25:31.314601  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_24000.solverstate
I0426 15:25:31.329156  7834 solver.cpp:330] Iteration 24000, Testing net (#0)
I0426 15:25:33.135947  7841 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:25:33.974453  7834 solver.cpp:397]     Test net output #0: loss = 1.21108 (* 1 = 1.21108 loss)
I0426 15:25:34.250679  7834 solver.cpp:218] Iteration 24000 (3.27127 iter/s, 30.5691s/100 iters), loss = 0.903106
I0426 15:25:34.250705  7834 solver.cpp:237]     Train net output #0: loss = 0.903106 (* 1 = 0.903106 loss)
I0426 15:25:34.250710  7834 sgd_solver.cpp:105] Iteration 24000, lr = 0.0001
I0426 15:26:02.137315  7834 solver.cpp:218] Iteration 24100 (3.58595 iter/s, 27.8866s/100 iters), loss = 1.26441
I0426 15:26:02.137346  7834 solver.cpp:237]     Train net output #0: loss = 1.26441 (* 1 = 1.26441 loss)
I0426 15:26:02.137351  7834 sgd_solver.cpp:105] Iteration 24100, lr = 0.0001
I0426 15:26:30.027626  7834 solver.cpp:218] Iteration 24200 (3.58548 iter/s, 27.8903s/100 iters), loss = 1.1528
I0426 15:26:30.027694  7834 solver.cpp:237]     Train net output #0: loss = 1.1528 (* 1 = 1.1528 loss)
I0426 15:26:30.027700  7834 sgd_solver.cpp:105] Iteration 24200, lr = 0.0001
I0426 15:26:57.901399  7834 solver.cpp:218] Iteration 24300 (3.58761 iter/s, 27.8737s/100 iters), loss = 1.05287
I0426 15:26:57.901428  7834 solver.cpp:237]     Train net output #0: loss = 1.05287 (* 1 = 1.05287 loss)
I0426 15:26:57.901434  7834 sgd_solver.cpp:105] Iteration 24300, lr = 0.0001
I0426 15:27:25.764019  7834 solver.cpp:218] Iteration 24400 (3.58904 iter/s, 27.8626s/100 iters), loss = 1.35783
I0426 15:27:25.764111  7834 solver.cpp:237]     Train net output #0: loss = 1.35783 (* 1 = 1.35783 loss)
I0426 15:27:25.764117  7834 sgd_solver.cpp:105] Iteration 24400, lr = 0.0001
I0426 15:27:53.626929  7834 solver.cpp:218] Iteration 24500 (3.58901 iter/s, 27.8628s/100 iters), loss = 0.988966
I0426 15:27:53.626957  7834 solver.cpp:237]     Train net output #0: loss = 0.988966 (* 1 = 0.988966 loss)
I0426 15:27:53.626963  7834 sgd_solver.cpp:105] Iteration 24500, lr = 0.0001
I0426 15:28:21.492576  7834 solver.cpp:218] Iteration 24600 (3.58865 iter/s, 27.8656s/100 iters), loss = 0.854086
I0426 15:28:21.492674  7834 solver.cpp:237]     Train net output #0: loss = 0.854086 (* 1 = 0.854086 loss)
I0426 15:28:21.492691  7834 sgd_solver.cpp:105] Iteration 24600, lr = 0.0001
I0426 15:28:49.359002  7834 solver.cpp:218] Iteration 24700 (3.58856 iter/s, 27.8663s/100 iters), loss = 1.18142
I0426 15:28:49.359031  7834 solver.cpp:237]     Train net output #0: loss = 1.18142 (* 1 = 1.18142 loss)
I0426 15:28:49.359036  7834 sgd_solver.cpp:105] Iteration 24700, lr = 0.0001
I0426 15:29:17.226500  7834 solver.cpp:218] Iteration 24800 (3.58841 iter/s, 27.8675s/100 iters), loss = 0.891218
I0426 15:29:17.226630  7834 solver.cpp:237]     Train net output #0: loss = 0.891218 (* 1 = 0.891218 loss)
I0426 15:29:17.226646  7834 sgd_solver.cpp:105] Iteration 24800, lr = 0.0001
I0426 15:29:45.090468  7834 solver.cpp:218] Iteration 24900 (3.58888 iter/s, 27.8638s/100 iters), loss = 0.897464
I0426 15:29:45.090498  7834 solver.cpp:237]     Train net output #0: loss = 0.897464 (* 1 = 0.897464 loss)
I0426 15:29:45.090503  7834 sgd_solver.cpp:105] Iteration 24900, lr = 0.0001
I0426 15:30:12.660387  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_25000.caffemodel
I0426 15:30:12.713243  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_25000.solverstate
I0426 15:30:12.727769  7834 solver.cpp:330] Iteration 25000, Testing net (#0)
I0426 15:30:15.367118  7834 solver.cpp:397]     Test net output #0: loss = 1.27174 (* 1 = 1.27174 loss)
I0426 15:30:15.643092  7834 solver.cpp:218] Iteration 25000 (3.27305 iter/s, 30.5526s/100 iters), loss = 0.798572
I0426 15:30:15.643119  7834 solver.cpp:237]     Train net output #0: loss = 0.798572 (* 1 = 0.798572 loss)
I0426 15:30:15.643126  7834 sgd_solver.cpp:105] Iteration 25000, lr = 0.0001
I0426 15:30:43.504858  7834 solver.cpp:218] Iteration 25100 (3.58916 iter/s, 27.8617s/100 iters), loss = 0.648717
I0426 15:30:43.504986  7834 solver.cpp:237]     Train net output #0: loss = 0.648717 (* 1 = 0.648717 loss)
I0426 15:30:43.504992  7834 sgd_solver.cpp:105] Iteration 25100, lr = 0.0001
I0426 15:31:11.366307  7834 solver.cpp:218] Iteration 25200 (3.58921 iter/s, 27.8613s/100 iters), loss = 0.592909
I0426 15:31:11.366348  7834 solver.cpp:237]     Train net output #0: loss = 0.592909 (* 1 = 0.592909 loss)
I0426 15:31:11.366353  7834 sgd_solver.cpp:105] Iteration 25200, lr = 0.0001
I0426 15:31:39.227887  7834 solver.cpp:218] Iteration 25300 (3.58918 iter/s, 27.8615s/100 iters), loss = 0.79289
I0426 15:31:39.227974  7834 solver.cpp:237]     Train net output #0: loss = 0.79289 (* 1 = 0.79289 loss)
I0426 15:31:39.227989  7834 sgd_solver.cpp:105] Iteration 25300, lr = 0.0001
I0426 15:32:07.090937  7834 solver.cpp:218] Iteration 25400 (3.589 iter/s, 27.8629s/100 iters), loss = 0.939958
I0426 15:32:07.090968  7834 solver.cpp:237]     Train net output #0: loss = 0.939958 (* 1 = 0.939958 loss)
I0426 15:32:07.090973  7834 sgd_solver.cpp:105] Iteration 25400, lr = 0.0001
I0426 15:32:34.949815  7834 solver.cpp:218] Iteration 25500 (3.58953 iter/s, 27.8588s/100 iters), loss = 0.866426
I0426 15:32:34.949921  7834 solver.cpp:237]     Train net output #0: loss = 0.866426 (* 1 = 0.866426 loss)
I0426 15:32:34.949928  7834 sgd_solver.cpp:105] Iteration 25500, lr = 0.0001
I0426 15:33:02.813283  7834 solver.cpp:218] Iteration 25600 (3.58895 iter/s, 27.8633s/100 iters), loss = 0.922291
I0426 15:33:02.813313  7834 solver.cpp:237]     Train net output #0: loss = 0.922291 (* 1 = 0.922291 loss)
I0426 15:33:02.813318  7834 sgd_solver.cpp:105] Iteration 25600, lr = 0.0001
I0426 15:33:30.675607  7834 solver.cpp:218] Iteration 25700 (3.58908 iter/s, 27.8623s/100 iters), loss = 0.843929
I0426 15:33:30.675762  7834 solver.cpp:237]     Train net output #0: loss = 0.843929 (* 1 = 0.843929 loss)
I0426 15:33:30.675770  7834 sgd_solver.cpp:105] Iteration 25700, lr = 0.0001
I0426 15:33:58.534842  7834 solver.cpp:218] Iteration 25800 (3.5895 iter/s, 27.8591s/100 iters), loss = 0.827679
I0426 15:33:58.534871  7834 solver.cpp:237]     Train net output #0: loss = 0.827679 (* 1 = 0.827679 loss)
I0426 15:33:58.534876  7834 sgd_solver.cpp:105] Iteration 25800, lr = 0.0001
I0426 15:34:26.410162  7834 solver.cpp:218] Iteration 25900 (3.58741 iter/s, 27.8753s/100 iters), loss = 0.976438
I0426 15:34:26.410306  7834 solver.cpp:237]     Train net output #0: loss = 0.976438 (* 1 = 0.976438 loss)
I0426 15:34:26.410315  7834 sgd_solver.cpp:105] Iteration 25900, lr = 0.0001
I0426 15:34:54.001405  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_26000.caffemodel
I0426 15:34:54.054451  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_26000.solverstate
I0426 15:34:54.068917  7834 solver.cpp:330] Iteration 26000, Testing net (#0)
I0426 15:34:56.708058  7834 solver.cpp:397]     Test net output #0: loss = 1.31539 (* 1 = 1.31539 loss)
I0426 15:34:56.984294  7834 solver.cpp:218] Iteration 26000 (3.27076 iter/s, 30.574s/100 iters), loss = 0.849678
I0426 15:34:56.984321  7834 solver.cpp:237]     Train net output #0: loss = 0.849678 (* 1 = 0.849678 loss)
I0426 15:34:56.984328  7834 sgd_solver.cpp:105] Iteration 26000, lr = 0.0001
I0426 15:35:24.845551  7834 solver.cpp:218] Iteration 26100 (3.58922 iter/s, 27.8612s/100 iters), loss = 0.930322
I0426 15:35:24.845582  7834 solver.cpp:237]     Train net output #0: loss = 0.930322 (* 1 = 0.930322 loss)
I0426 15:35:24.845587  7834 sgd_solver.cpp:105] Iteration 26100, lr = 0.0001
I0426 15:35:52.704712  7834 solver.cpp:218] Iteration 26200 (3.58949 iter/s, 27.8591s/100 iters), loss = 0.953836
I0426 15:35:52.704810  7834 solver.cpp:237]     Train net output #0: loss = 0.953836 (* 1 = 0.953836 loss)
I0426 15:35:52.704826  7834 sgd_solver.cpp:105] Iteration 26200, lr = 0.0001
I0426 15:36:20.565709  7834 solver.cpp:218] Iteration 26300 (3.58926 iter/s, 27.8609s/100 iters), loss = 0.962126
I0426 15:36:20.565737  7834 solver.cpp:237]     Train net output #0: loss = 0.962126 (* 1 = 0.962126 loss)
I0426 15:36:20.565743  7834 sgd_solver.cpp:105] Iteration 26300, lr = 0.0001
I0426 15:36:48.423373  7834 solver.cpp:218] Iteration 26400 (3.58968 iter/s, 27.8576s/100 iters), loss = 1.01972
I0426 15:36:48.423519  7834 solver.cpp:237]     Train net output #0: loss = 1.01972 (* 1 = 1.01972 loss)
I0426 15:36:48.423527  7834 sgd_solver.cpp:105] Iteration 26400, lr = 0.0001
I0426 15:37:16.283115  7834 solver.cpp:218] Iteration 26500 (3.58943 iter/s, 27.8596s/100 iters), loss = 0.887535
I0426 15:37:16.283145  7834 solver.cpp:237]     Train net output #0: loss = 0.887535 (* 1 = 0.887535 loss)
I0426 15:37:16.283151  7834 sgd_solver.cpp:105] Iteration 26500, lr = 0.0001
I0426 15:37:44.144368  7834 solver.cpp:218] Iteration 26600 (3.58922 iter/s, 27.8612s/100 iters), loss = 0.966564
I0426 15:37:44.144467  7834 solver.cpp:237]     Train net output #0: loss = 0.966564 (* 1 = 0.966564 loss)
I0426 15:37:44.144474  7834 sgd_solver.cpp:105] Iteration 26600, lr = 0.0001
I0426 15:37:49.441207  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:38:12.036162  7834 solver.cpp:218] Iteration 26700 (3.5853 iter/s, 27.8917s/100 iters), loss = 1.04023
I0426 15:38:12.036195  7834 solver.cpp:237]     Train net output #0: loss = 1.04023 (* 1 = 1.04023 loss)
I0426 15:38:12.036201  7834 sgd_solver.cpp:105] Iteration 26700, lr = 0.0001
I0426 15:38:39.912027  7834 solver.cpp:218] Iteration 26800 (3.58734 iter/s, 27.8758s/100 iters), loss = 1.15063
I0426 15:38:39.912122  7834 solver.cpp:237]     Train net output #0: loss = 1.15063 (* 1 = 1.15063 loss)
I0426 15:38:39.912137  7834 sgd_solver.cpp:105] Iteration 26800, lr = 0.0001
I0426 15:39:07.779530  7834 solver.cpp:218] Iteration 26900 (3.58843 iter/s, 27.8674s/100 iters), loss = 0.869535
I0426 15:39:07.779559  7834 solver.cpp:237]     Train net output #0: loss = 0.869535 (* 1 = 0.869535 loss)
I0426 15:39:07.779566  7834 sgd_solver.cpp:105] Iteration 26900, lr = 0.0001
I0426 15:39:35.348425  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_27000.caffemodel
I0426 15:39:35.401259  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_27000.solverstate
I0426 15:39:35.416043  7834 solver.cpp:330] Iteration 27000, Testing net (#0)
I0426 15:39:38.054299  7834 solver.cpp:397]     Test net output #0: loss = 1.34619 (* 1 = 1.34619 loss)
I0426 15:39:38.330467  7834 solver.cpp:218] Iteration 27000 (3.27323 iter/s, 30.5509s/100 iters), loss = 1.00667
I0426 15:39:38.330494  7834 solver.cpp:237]     Train net output #0: loss = 1.00667 (* 1 = 1.00667 loss)
I0426 15:39:38.330500  7834 sgd_solver.cpp:105] Iteration 27000, lr = 0.0001
I0426 15:40:06.188390  7834 solver.cpp:218] Iteration 27100 (3.58965 iter/s, 27.8579s/100 iters), loss = 1.00025
I0426 15:40:06.188524  7834 solver.cpp:237]     Train net output #0: loss = 1.00025 (* 1 = 1.00025 loss)
I0426 15:40:06.188530  7834 sgd_solver.cpp:105] Iteration 27100, lr = 0.0001
I0426 15:40:34.046155  7834 solver.cpp:218] Iteration 27200 (3.58968 iter/s, 27.8576s/100 iters), loss = 0.864997
I0426 15:40:34.046185  7834 solver.cpp:237]     Train net output #0: loss = 0.864997 (* 1 = 0.864997 loss)
I0426 15:40:34.046190  7834 sgd_solver.cpp:105] Iteration 27200, lr = 0.0001
I0426 15:41:01.901991  7834 solver.cpp:218] Iteration 27300 (3.58992 iter/s, 27.8558s/100 iters), loss = 0.742478
I0426 15:41:01.902135  7834 solver.cpp:237]     Train net output #0: loss = 0.742478 (* 1 = 0.742478 loss)
I0426 15:41:01.902143  7834 sgd_solver.cpp:105] Iteration 27300, lr = 0.0001
I0426 15:41:29.776469  7834 solver.cpp:218] Iteration 27400 (3.58753 iter/s, 27.8743s/100 iters), loss = 0.771383
I0426 15:41:29.776500  7834 solver.cpp:237]     Train net output #0: loss = 0.771383 (* 1 = 0.771383 loss)
I0426 15:41:29.776506  7834 sgd_solver.cpp:105] Iteration 27400, lr = 0.0001
I0426 15:41:57.639843  7834 solver.cpp:218] Iteration 27500 (3.58895 iter/s, 27.8633s/100 iters), loss = 0.675212
I0426 15:41:57.639950  7834 solver.cpp:237]     Train net output #0: loss = 0.675212 (* 1 = 0.675212 loss)
I0426 15:41:57.639955  7834 sgd_solver.cpp:105] Iteration 27500, lr = 0.0001
I0426 15:42:25.499497  7834 solver.cpp:218] Iteration 27600 (3.58944 iter/s, 27.8595s/100 iters), loss = 1.10853
I0426 15:42:25.499524  7834 solver.cpp:237]     Train net output #0: loss = 1.10853 (* 1 = 1.10853 loss)
I0426 15:42:25.499531  7834 sgd_solver.cpp:105] Iteration 27600, lr = 0.0001
I0426 15:42:53.359812  7834 solver.cpp:218] Iteration 27700 (3.58934 iter/s, 27.8603s/100 iters), loss = 0.568287
I0426 15:42:53.359921  7834 solver.cpp:237]     Train net output #0: loss = 0.568287 (* 1 = 0.568287 loss)
I0426 15:42:53.359928  7834 sgd_solver.cpp:105] Iteration 27700, lr = 0.0001
I0426 15:43:21.242451  7834 solver.cpp:218] Iteration 27800 (3.58648 iter/s, 27.8825s/100 iters), loss = 0.979028
I0426 15:43:21.242483  7834 solver.cpp:237]     Train net output #0: loss = 0.979028 (* 1 = 0.979028 loss)
I0426 15:43:21.242489  7834 sgd_solver.cpp:105] Iteration 27800, lr = 0.0001
I0426 15:43:49.122082  7834 solver.cpp:218] Iteration 27900 (3.58686 iter/s, 27.8796s/100 iters), loss = 0.85823
I0426 15:43:49.122179  7834 solver.cpp:237]     Train net output #0: loss = 0.85823 (* 1 = 0.85823 loss)
I0426 15:43:49.122195  7834 sgd_solver.cpp:105] Iteration 27900, lr = 0.0001
I0426 15:44:16.709966  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_28000.caffemodel
I0426 15:44:16.763183  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_28000.solverstate
I0426 15:44:16.777739  7834 solver.cpp:330] Iteration 28000, Testing net (#0)
I0426 15:44:19.423784  7834 solver.cpp:397]     Test net output #0: loss = 1.28012 (* 1 = 1.28012 loss)
I0426 15:44:19.700947  7834 solver.cpp:218] Iteration 28000 (3.27025 iter/s, 30.5787s/100 iters), loss = 0.606716
I0426 15:44:19.700994  7834 solver.cpp:237]     Train net output #0: loss = 0.606716 (* 1 = 0.606716 loss)
I0426 15:44:19.701000  7834 sgd_solver.cpp:105] Iteration 28000, lr = 0.0001
I0426 15:44:47.594714  7834 solver.cpp:218] Iteration 28100 (3.58504 iter/s, 27.8937s/100 iters), loss = 0.777368
I0426 15:44:47.594745  7834 solver.cpp:237]     Train net output #0: loss = 0.777368 (* 1 = 0.777368 loss)
I0426 15:44:47.594751  7834 sgd_solver.cpp:105] Iteration 28100, lr = 0.0001
I0426 15:45:15.462527  7834 solver.cpp:218] Iteration 28200 (3.58838 iter/s, 27.8678s/100 iters), loss = 1.05429
I0426 15:45:15.462702  7834 solver.cpp:237]     Train net output #0: loss = 1.05429 (* 1 = 1.05429 loss)
I0426 15:45:15.462709  7834 sgd_solver.cpp:105] Iteration 28200, lr = 0.0001
I0426 15:45:43.324981  7834 solver.cpp:218] Iteration 28300 (3.58908 iter/s, 27.8623s/100 iters), loss = 1.08819
I0426 15:45:43.325011  7834 solver.cpp:237]     Train net output #0: loss = 1.08819 (* 1 = 1.08819 loss)
I0426 15:45:43.325016  7834 sgd_solver.cpp:105] Iteration 28300, lr = 0.0001
I0426 15:46:11.185461  7834 solver.cpp:218] Iteration 28400 (3.58932 iter/s, 27.8604s/100 iters), loss = 1.06503
I0426 15:46:11.185597  7834 solver.cpp:237]     Train net output #0: loss = 1.06503 (* 1 = 1.06503 loss)
I0426 15:46:11.185605  7834 sgd_solver.cpp:105] Iteration 28400, lr = 0.0001
I0426 15:46:39.049756  7834 solver.cpp:218] Iteration 28500 (3.58884 iter/s, 27.8641s/100 iters), loss = 1.07704
I0426 15:46:39.049784  7834 solver.cpp:237]     Train net output #0: loss = 1.07704 (* 1 = 1.07704 loss)
I0426 15:46:39.049789  7834 sgd_solver.cpp:105] Iteration 28500, lr = 0.0001
I0426 15:47:06.913180  7834 solver.cpp:218] Iteration 28600 (3.58894 iter/s, 27.8634s/100 iters), loss = 0.826384
I0426 15:47:06.913249  7834 solver.cpp:237]     Train net output #0: loss = 0.826384 (* 1 = 0.826384 loss)
I0426 15:47:06.913264  7834 sgd_solver.cpp:105] Iteration 28600, lr = 0.0001
I0426 15:47:34.777604  7834 solver.cpp:218] Iteration 28700 (3.58882 iter/s, 27.8643s/100 iters), loss = 1.00772
I0426 15:47:34.777633  7834 solver.cpp:237]     Train net output #0: loss = 1.00772 (* 1 = 1.00772 loss)
I0426 15:47:34.777638  7834 sgd_solver.cpp:105] Iteration 28700, lr = 0.0001
I0426 15:48:02.635942  7834 solver.cpp:218] Iteration 28800 (3.5896 iter/s, 27.8583s/100 iters), loss = 0.747201
I0426 15:48:02.636088  7834 solver.cpp:237]     Train net output #0: loss = 0.747201 (* 1 = 0.747201 loss)
I0426 15:48:02.636096  7834 sgd_solver.cpp:105] Iteration 28800, lr = 0.0001
I0426 15:48:30.520756  7834 solver.cpp:218] Iteration 28900 (3.5862 iter/s, 27.8846s/100 iters), loss = 1.07691
I0426 15:48:30.520787  7834 solver.cpp:237]     Train net output #0: loss = 1.07691 (* 1 = 1.07691 loss)
I0426 15:48:30.520793  7834 sgd_solver.cpp:105] Iteration 28900, lr = 0.0001
I0426 15:48:58.108937  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_29000.caffemodel
I0426 15:48:58.161782  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_29000.solverstate
I0426 15:48:58.176592  7834 solver.cpp:330] Iteration 29000, Testing net (#0)
I0426 15:49:00.817498  7834 solver.cpp:397]     Test net output #0: loss = 1.33676 (* 1 = 1.33676 loss)
I0426 15:49:01.093447  7834 solver.cpp:218] Iteration 29000 (3.2709 iter/s, 30.5726s/100 iters), loss = 0.8931
I0426 15:49:01.093475  7834 solver.cpp:237]     Train net output #0: loss = 0.8931 (* 1 = 0.8931 loss)
I0426 15:49:01.093482  7834 sgd_solver.cpp:105] Iteration 29000, lr = 0.0001
I0426 15:49:28.959453  7834 solver.cpp:218] Iteration 29100 (3.58861 iter/s, 27.866s/100 iters), loss = 0.943077
I0426 15:49:28.959568  7834 solver.cpp:237]     Train net output #0: loss = 0.943077 (* 1 = 0.943077 loss)
I0426 15:49:28.959583  7834 sgd_solver.cpp:105] Iteration 29100, lr = 0.0001
I0426 15:49:56.841164  7834 solver.cpp:218] Iteration 29200 (3.5866 iter/s, 27.8816s/100 iters), loss = 0.683073
I0426 15:49:56.841195  7834 solver.cpp:237]     Train net output #0: loss = 0.683073 (* 1 = 0.683073 loss)
I0426 15:49:56.841202  7834 sgd_solver.cpp:105] Iteration 29200, lr = 0.0001
I0426 15:50:19.422185  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 15:50:24.718137  7834 solver.cpp:218] Iteration 29300 (3.5872 iter/s, 27.8769s/100 iters), loss = 0.949347
I0426 15:50:24.718165  7834 solver.cpp:237]     Train net output #0: loss = 0.949347 (* 1 = 0.949347 loss)
I0426 15:50:24.718171  7834 sgd_solver.cpp:105] Iteration 29300, lr = 0.0001
I0426 15:50:52.601307  7834 solver.cpp:218] Iteration 29400 (3.5864 iter/s, 27.8831s/100 iters), loss = 0.759492
I0426 15:50:52.601382  7834 solver.cpp:237]     Train net output #0: loss = 0.759492 (* 1 = 0.759492 loss)
I0426 15:50:52.601388  7834 sgd_solver.cpp:105] Iteration 29400, lr = 0.0001
I0426 15:51:20.497117  7834 solver.cpp:218] Iteration 29500 (3.58478 iter/s, 27.8957s/100 iters), loss = 0.763751
I0426 15:51:20.497146  7834 solver.cpp:237]     Train net output #0: loss = 0.763751 (* 1 = 0.763751 loss)
I0426 15:51:20.497153  7834 sgd_solver.cpp:105] Iteration 29500, lr = 0.0001
I0426 15:51:48.356670  7834 solver.cpp:218] Iteration 29600 (3.58944 iter/s, 27.8595s/100 iters), loss = 0.873746
I0426 15:51:48.356765  7834 solver.cpp:237]     Train net output #0: loss = 0.873746 (* 1 = 0.873746 loss)
I0426 15:51:48.356781  7834 sgd_solver.cpp:105] Iteration 29600, lr = 0.0001
I0426 15:52:16.229988  7834 solver.cpp:218] Iteration 29700 (3.58768 iter/s, 27.8732s/100 iters), loss = 0.909082
I0426 15:52:16.230016  7834 solver.cpp:237]     Train net output #0: loss = 0.909082 (* 1 = 0.909082 loss)
I0426 15:52:16.230022  7834 sgd_solver.cpp:105] Iteration 29700, lr = 0.0001
I0426 15:52:44.116436  7834 solver.cpp:218] Iteration 29800 (3.58598 iter/s, 27.8864s/100 iters), loss = 0.85798
I0426 15:52:44.116513  7834 solver.cpp:237]     Train net output #0: loss = 0.85798 (* 1 = 0.85798 loss)
I0426 15:52:44.116529  7834 sgd_solver.cpp:105] Iteration 29800, lr = 0.0001
I0426 15:53:11.973584  7834 solver.cpp:218] Iteration 29900 (3.58976 iter/s, 27.857s/100 iters), loss = 0.68283
I0426 15:53:11.973614  7834 solver.cpp:237]     Train net output #0: loss = 0.68283 (* 1 = 0.68283 loss)
I0426 15:53:11.973620  7834 sgd_solver.cpp:105] Iteration 29900, lr = 0.0001
I0426 15:53:39.539389  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_30000.caffemodel
I0426 15:53:39.592344  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_30000.solverstate
I0426 15:53:39.607007  7834 solver.cpp:330] Iteration 30000, Testing net (#0)
I0426 15:53:42.245106  7834 solver.cpp:397]     Test net output #0: loss = 1.34297 (* 1 = 1.34297 loss)
I0426 15:53:42.521162  7834 solver.cpp:218] Iteration 30000 (3.27359 iter/s, 30.5475s/100 iters), loss = 0.909459
I0426 15:53:42.521189  7834 solver.cpp:237]     Train net output #0: loss = 0.909459 (* 1 = 0.909459 loss)
I0426 15:53:42.521195  7834 sgd_solver.cpp:105] Iteration 30000, lr = 0.0001
I0426 15:54:10.380668  7834 solver.cpp:218] Iteration 30100 (3.58945 iter/s, 27.8595s/100 iters), loss = 0.683716
I0426 15:54:10.380825  7834 solver.cpp:237]     Train net output #0: loss = 0.683716 (* 1 = 0.683716 loss)
I0426 15:54:10.380831  7834 sgd_solver.cpp:105] Iteration 30100, lr = 0.0001
I0426 15:54:38.244709  7834 solver.cpp:218] Iteration 30200 (3.58888 iter/s, 27.8639s/100 iters), loss = 0.718843
I0426 15:54:38.244740  7834 solver.cpp:237]     Train net output #0: loss = 0.718843 (* 1 = 0.718843 loss)
I0426 15:54:38.244745  7834 sgd_solver.cpp:105] Iteration 30200, lr = 0.0001
I0426 15:55:06.106052  7834 solver.cpp:218] Iteration 30300 (3.58921 iter/s, 27.8613s/100 iters), loss = 0.694701
I0426 15:55:06.106192  7834 solver.cpp:237]     Train net output #0: loss = 0.694701 (* 1 = 0.694701 loss)
I0426 15:55:06.106200  7834 sgd_solver.cpp:105] Iteration 30300, lr = 0.0001
I0426 15:55:33.967533  7834 solver.cpp:218] Iteration 30400 (3.58921 iter/s, 27.8613s/100 iters), loss = 0.713762
I0426 15:55:33.967563  7834 solver.cpp:237]     Train net output #0: loss = 0.713762 (* 1 = 0.713762 loss)
I0426 15:55:33.967568  7834 sgd_solver.cpp:105] Iteration 30400, lr = 0.0001
I0426 15:56:01.832202  7834 solver.cpp:218] Iteration 30500 (3.58878 iter/s, 27.8646s/100 iters), loss = 0.961272
I0426 15:56:01.832324  7834 solver.cpp:237]     Train net output #0: loss = 0.961272 (* 1 = 0.961272 loss)
I0426 15:56:01.832330  7834 sgd_solver.cpp:105] Iteration 30500, lr = 0.0001
I0426 15:56:29.695412  7834 solver.cpp:218] Iteration 30600 (3.58898 iter/s, 27.8631s/100 iters), loss = 0.821138
I0426 15:56:29.695456  7834 solver.cpp:237]     Train net output #0: loss = 0.821138 (* 1 = 0.821138 loss)
I0426 15:56:29.695462  7834 sgd_solver.cpp:105] Iteration 30600, lr = 0.0001
I0426 15:56:57.555799  7834 solver.cpp:218] Iteration 30700 (3.58933 iter/s, 27.8603s/100 iters), loss = 0.787392
I0426 15:56:57.555951  7834 solver.cpp:237]     Train net output #0: loss = 0.787392 (* 1 = 0.787392 loss)
I0426 15:56:57.555958  7834 sgd_solver.cpp:105] Iteration 30700, lr = 0.0001
I0426 15:57:25.422757  7834 solver.cpp:218] Iteration 30800 (3.5885 iter/s, 27.8668s/100 iters), loss = 0.863967
I0426 15:57:25.422787  7834 solver.cpp:237]     Train net output #0: loss = 0.863967 (* 1 = 0.863967 loss)
I0426 15:57:25.422793  7834 sgd_solver.cpp:105] Iteration 30800, lr = 0.0001
I0426 15:57:53.286337  7834 solver.cpp:218] Iteration 30900 (3.58892 iter/s, 27.8635s/100 iters), loss = 0.992899
I0426 15:57:53.286435  7834 solver.cpp:237]     Train net output #0: loss = 0.992899 (* 1 = 0.992899 loss)
I0426 15:57:53.286442  7834 sgd_solver.cpp:105] Iteration 30900, lr = 0.0001
I0426 15:58:20.858762  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_31000.caffemodel
I0426 15:58:20.911270  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_31000.solverstate
I0426 15:58:20.925804  7834 solver.cpp:330] Iteration 31000, Testing net (#0)
I0426 15:58:23.564098  7834 solver.cpp:397]     Test net output #0: loss = 1.34389 (* 1 = 1.34389 loss)
I0426 15:58:23.840358  7834 solver.cpp:218] Iteration 31000 (3.2729 iter/s, 30.5539s/100 iters), loss = 0.838693
I0426 15:58:23.840385  7834 solver.cpp:237]     Train net output #0: loss = 0.838693 (* 1 = 0.838693 loss)
I0426 15:58:23.840390  7834 sgd_solver.cpp:105] Iteration 31000, lr = 0.0001
I0426 15:58:51.701179  7834 solver.cpp:218] Iteration 31100 (3.58928 iter/s, 27.8608s/100 iters), loss = 0.919151
I0426 15:58:51.701207  7834 solver.cpp:237]     Train net output #0: loss = 0.919151 (* 1 = 0.919151 loss)
I0426 15:58:51.701212  7834 sgd_solver.cpp:105] Iteration 31100, lr = 0.0001
I0426 15:59:19.576198  7834 solver.cpp:218] Iteration 31200 (3.58745 iter/s, 27.875s/100 iters), loss = 0.705364
I0426 15:59:19.576299  7834 solver.cpp:237]     Train net output #0: loss = 0.705364 (* 1 = 0.705364 loss)
I0426 15:59:19.576305  7834 sgd_solver.cpp:105] Iteration 31200, lr = 0.0001
I0426 15:59:47.459606  7834 solver.cpp:218] Iteration 31300 (3.58638 iter/s, 27.8833s/100 iters), loss = 1.0488
I0426 15:59:47.459636  7834 solver.cpp:237]     Train net output #0: loss = 1.0488 (* 1 = 1.0488 loss)
I0426 15:59:47.459642  7834 sgd_solver.cpp:105] Iteration 31300, lr = 0.0001
I0426 16:00:15.323068  7834 solver.cpp:218] Iteration 31400 (3.58894 iter/s, 27.8634s/100 iters), loss = 0.782756
I0426 16:00:15.323204  7834 solver.cpp:237]     Train net output #0: loss = 0.782756 (* 1 = 0.782756 loss)
I0426 16:00:15.323211  7834 sgd_solver.cpp:105] Iteration 31400, lr = 0.0001
I0426 16:00:43.231865  7834 solver.cpp:218] Iteration 31500 (3.58312 iter/s, 27.9086s/100 iters), loss = 1.06406
I0426 16:00:43.231894  7834 solver.cpp:237]     Train net output #0: loss = 1.06406 (* 1 = 1.06406 loss)
I0426 16:00:43.231899  7834 sgd_solver.cpp:105] Iteration 31500, lr = 0.0001
I0426 16:01:11.091378  7834 solver.cpp:218] Iteration 31600 (3.58944 iter/s, 27.8595s/100 iters), loss = 0.580171
I0426 16:01:11.091513  7834 solver.cpp:237]     Train net output #0: loss = 0.580171 (* 1 = 0.580171 loss)
I0426 16:01:11.091529  7834 sgd_solver.cpp:105] Iteration 31600, lr = 0.0001
I0426 16:01:38.949720  7834 solver.cpp:218] Iteration 31700 (3.58961 iter/s, 27.8582s/100 iters), loss = 0.762843
I0426 16:01:38.949749  7834 solver.cpp:237]     Train net output #0: loss = 0.762843 (* 1 = 0.762843 loss)
I0426 16:01:38.949754  7834 sgd_solver.cpp:105] Iteration 31700, lr = 0.0001
I0426 16:02:06.809365  7834 solver.cpp:218] Iteration 31800 (3.58943 iter/s, 27.8596s/100 iters), loss = 1.04593
I0426 16:02:06.809474  7834 solver.cpp:237]     Train net output #0: loss = 1.04593 (* 1 = 1.04593 loss)
I0426 16:02:06.809481  7834 sgd_solver.cpp:105] Iteration 31800, lr = 0.0001
I0426 16:02:34.668572  7834 solver.cpp:218] Iteration 31900 (3.58949 iter/s, 27.8591s/100 iters), loss = 0.928505
I0426 16:02:34.668603  7834 solver.cpp:237]     Train net output #0: loss = 0.928505 (* 1 = 0.928505 loss)
I0426 16:02:34.668608  7834 sgd_solver.cpp:105] Iteration 31900, lr = 0.0001
I0426 16:02:46.653535  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:03:02.231429  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_32000.caffemodel
I0426 16:03:02.284420  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_32000.solverstate
I0426 16:03:02.299016  7834 solver.cpp:330] Iteration 32000, Testing net (#0)
I0426 16:03:04.938736  7834 solver.cpp:397]     Test net output #0: loss = 1.39526 (* 1 = 1.39526 loss)
I0426 16:03:05.214752  7834 solver.cpp:218] Iteration 32000 (3.27374 iter/s, 30.5461s/100 iters), loss = 0.821126
I0426 16:03:05.214781  7834 solver.cpp:237]     Train net output #0: loss = 0.821126 (* 1 = 0.821126 loss)
I0426 16:03:05.214787  7834 sgd_solver.cpp:105] Iteration 32000, lr = 0.0001
I0426 16:03:33.108762  7834 solver.cpp:218] Iteration 32100 (3.58501 iter/s, 27.894s/100 iters), loss = 0.799316
I0426 16:03:33.108870  7834 solver.cpp:237]     Train net output #0: loss = 0.799316 (* 1 = 0.799316 loss)
I0426 16:03:33.108877  7834 sgd_solver.cpp:105] Iteration 32100, lr = 0.0001
I0426 16:04:00.970547  7834 solver.cpp:218] Iteration 32200 (3.58916 iter/s, 27.8617s/100 iters), loss = 0.649192
I0426 16:04:00.970577  7834 solver.cpp:237]     Train net output #0: loss = 0.649192 (* 1 = 0.649192 loss)
I0426 16:04:00.970582  7834 sgd_solver.cpp:105] Iteration 32200, lr = 0.0001
I0426 16:04:28.834460  7834 solver.cpp:218] Iteration 32300 (3.58888 iter/s, 27.8639s/100 iters), loss = 0.80191
I0426 16:04:28.834538  7834 solver.cpp:237]     Train net output #0: loss = 0.80191 (* 1 = 0.80191 loss)
I0426 16:04:28.834554  7834 sgd_solver.cpp:105] Iteration 32300, lr = 0.0001
I0426 16:04:56.690918  7834 solver.cpp:218] Iteration 32400 (3.58984 iter/s, 27.8564s/100 iters), loss = 0.840113
I0426 16:04:56.690948  7834 solver.cpp:237]     Train net output #0: loss = 0.840113 (* 1 = 0.840113 loss)
I0426 16:04:56.690954  7834 sgd_solver.cpp:105] Iteration 32400, lr = 0.0001
I0426 16:05:24.552563  7834 solver.cpp:218] Iteration 32500 (3.58917 iter/s, 27.8616s/100 iters), loss = 1.25578
I0426 16:05:24.552631  7834 solver.cpp:237]     Train net output #0: loss = 1.25578 (* 1 = 1.25578 loss)
I0426 16:05:24.552649  7834 sgd_solver.cpp:105] Iteration 32500, lr = 0.0001
I0426 16:05:52.413364  7834 solver.cpp:218] Iteration 32600 (3.58928 iter/s, 27.8607s/100 iters), loss = 0.719937
I0426 16:05:52.413393  7834 solver.cpp:237]     Train net output #0: loss = 0.719937 (* 1 = 0.719937 loss)
I0426 16:05:52.413398  7834 sgd_solver.cpp:105] Iteration 32600, lr = 0.0001
I0426 16:06:20.275372  7834 solver.cpp:218] Iteration 32700 (3.58912 iter/s, 27.862s/100 iters), loss = 0.659541
I0426 16:06:20.275564  7834 solver.cpp:237]     Train net output #0: loss = 0.659541 (* 1 = 0.659541 loss)
I0426 16:06:20.275573  7834 sgd_solver.cpp:105] Iteration 32700, lr = 0.0001
I0426 16:06:48.175348  7834 solver.cpp:218] Iteration 32800 (3.58426 iter/s, 27.8998s/100 iters), loss = 0.802921
I0426 16:06:48.175375  7834 solver.cpp:237]     Train net output #0: loss = 0.802921 (* 1 = 0.802921 loss)
I0426 16:06:48.175381  7834 sgd_solver.cpp:105] Iteration 32800, lr = 0.0001
I0426 16:07:16.061260  7834 solver.cpp:218] Iteration 32900 (3.58605 iter/s, 27.8859s/100 iters), loss = 0.762608
I0426 16:07:16.061398  7834 solver.cpp:237]     Train net output #0: loss = 0.762608 (* 1 = 0.762608 loss)
I0426 16:07:16.061405  7834 sgd_solver.cpp:105] Iteration 32900, lr = 0.0001
I0426 16:07:43.630553  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_33000.caffemodel
I0426 16:07:43.683609  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_33000.solverstate
I0426 16:07:43.698207  7834 solver.cpp:330] Iteration 33000, Testing net (#0)
I0426 16:07:46.337361  7834 solver.cpp:397]     Test net output #0: loss = 1.50562 (* 1 = 1.50562 loss)
I0426 16:07:46.613324  7834 solver.cpp:218] Iteration 33000 (3.27312 iter/s, 30.5519s/100 iters), loss = 0.982228
I0426 16:07:46.613351  7834 solver.cpp:237]     Train net output #0: loss = 0.982228 (* 1 = 0.982228 loss)
I0426 16:07:46.613358  7834 sgd_solver.cpp:105] Iteration 33000, lr = 0.0001
I0426 16:08:14.473687  7834 solver.cpp:218] Iteration 33100 (3.58933 iter/s, 27.8603s/100 iters), loss = 0.739678
I0426 16:08:14.473717  7834 solver.cpp:237]     Train net output #0: loss = 0.739678 (* 1 = 0.739678 loss)
I0426 16:08:14.473723  7834 sgd_solver.cpp:105] Iteration 33100, lr = 0.0001
I0426 16:08:42.334312  7834 solver.cpp:218] Iteration 33200 (3.5893 iter/s, 27.8606s/100 iters), loss = 0.96274
I0426 16:08:42.334414  7834 solver.cpp:237]     Train net output #0: loss = 0.96274 (* 1 = 0.96274 loss)
I0426 16:08:42.334431  7834 sgd_solver.cpp:105] Iteration 33200, lr = 0.0001
I0426 16:09:10.197168  7834 solver.cpp:218] Iteration 33300 (3.58902 iter/s, 27.8627s/100 iters), loss = 0.929265
I0426 16:09:10.197197  7834 solver.cpp:237]     Train net output #0: loss = 0.929265 (* 1 = 0.929265 loss)
I0426 16:09:10.197203  7834 sgd_solver.cpp:105] Iteration 33300, lr = 0.0001
I0426 16:09:38.051053  7834 solver.cpp:218] Iteration 33400 (3.59017 iter/s, 27.8538s/100 iters), loss = 0.761412
I0426 16:09:38.051177  7834 solver.cpp:237]     Train net output #0: loss = 0.761412 (* 1 = 0.761412 loss)
I0426 16:09:38.051196  7834 sgd_solver.cpp:105] Iteration 33400, lr = 0.0001
I0426 16:10:05.913933  7834 solver.cpp:218] Iteration 33500 (3.58902 iter/s, 27.8627s/100 iters), loss = 0.86553
I0426 16:10:05.913961  7834 solver.cpp:237]     Train net output #0: loss = 0.86553 (* 1 = 0.86553 loss)
I0426 16:10:05.913967  7834 sgd_solver.cpp:105] Iteration 33500, lr = 0.0001
I0426 16:10:33.821863  7834 solver.cpp:218] Iteration 33600 (3.58322 iter/s, 27.9079s/100 iters), loss = 0.876205
I0426 16:10:33.822006  7834 solver.cpp:237]     Train net output #0: loss = 0.876205 (* 1 = 0.876205 loss)
I0426 16:10:33.822015  7834 sgd_solver.cpp:105] Iteration 33600, lr = 0.0001
I0426 16:11:02.114430  7834 solver.cpp:218] Iteration 33700 (3.53452 iter/s, 28.2924s/100 iters), loss = 1.00732
I0426 16:11:02.114472  7834 solver.cpp:237]     Train net output #0: loss = 1.00732 (* 1 = 1.00732 loss)
I0426 16:11:02.114478  7834 sgd_solver.cpp:105] Iteration 33700, lr = 0.0001
I0426 16:11:30.407464  7834 solver.cpp:218] Iteration 33800 (3.53445 iter/s, 28.293s/100 iters), loss = 0.889124
I0426 16:11:30.407572  7834 solver.cpp:237]     Train net output #0: loss = 0.889124 (* 1 = 0.889124 loss)
I0426 16:11:30.407578  7834 sgd_solver.cpp:105] Iteration 33800, lr = 0.0001
I0426 16:11:58.649008  7834 solver.cpp:218] Iteration 33900 (3.5409 iter/s, 28.2414s/100 iters), loss = 0.897716
I0426 16:11:58.649044  7834 solver.cpp:237]     Train net output #0: loss = 0.897716 (* 1 = 0.897716 loss)
I0426 16:11:58.649051  7834 sgd_solver.cpp:105] Iteration 33900, lr = 0.0001
I0426 16:12:26.229648  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_34000.caffemodel
I0426 16:12:26.283926  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_34000.solverstate
I0426 16:12:26.298913  7834 solver.cpp:330] Iteration 34000, Testing net (#0)
I0426 16:12:28.942163  7834 solver.cpp:397]     Test net output #0: loss = 1.24911 (* 1 = 1.24911 loss)
I0426 16:12:29.221637  7834 solver.cpp:218] Iteration 34000 (3.27091 iter/s, 30.5726s/100 iters), loss = 1.01096
I0426 16:12:29.221665  7834 solver.cpp:237]     Train net output #0: loss = 1.01096 (* 1 = 1.01096 loss)
I0426 16:12:29.221670  7834 sgd_solver.cpp:105] Iteration 34000, lr = 0.0001
I0426 16:12:57.096137  7834 solver.cpp:218] Iteration 34100 (3.58751 iter/s, 27.8745s/100 iters), loss = 1.01615
I0426 16:12:57.096243  7834 solver.cpp:237]     Train net output #0: loss = 1.01615 (* 1 = 1.01615 loss)
I0426 16:12:57.096251  7834 sgd_solver.cpp:105] Iteration 34100, lr = 0.0001
I0426 16:13:24.960600  7834 solver.cpp:218] Iteration 34200 (3.58882 iter/s, 27.8643s/100 iters), loss = 0.921686
I0426 16:13:24.960630  7834 solver.cpp:237]     Train net output #0: loss = 0.921686 (* 1 = 0.921686 loss)
I0426 16:13:24.960635  7834 sgd_solver.cpp:105] Iteration 34200, lr = 0.0001
I0426 16:13:52.828676  7834 solver.cpp:218] Iteration 34300 (3.58834 iter/s, 27.868s/100 iters), loss = 0.755617
I0426 16:13:52.828791  7834 solver.cpp:237]     Train net output #0: loss = 0.755617 (* 1 = 0.755617 loss)
I0426 16:13:52.828809  7834 sgd_solver.cpp:105] Iteration 34300, lr = 0.0001
I0426 16:14:20.694649  7834 solver.cpp:218] Iteration 34400 (3.58862 iter/s, 27.8658s/100 iters), loss = 0.767591
I0426 16:14:20.694679  7834 solver.cpp:237]     Train net output #0: loss = 0.767591 (* 1 = 0.767591 loss)
I0426 16:14:20.694684  7834 sgd_solver.cpp:105] Iteration 34400, lr = 0.0001
I0426 16:14:48.559592  7834 solver.cpp:218] Iteration 34500 (3.58874 iter/s, 27.8649s/100 iters), loss = 0.679921
I0426 16:14:48.559672  7834 solver.cpp:237]     Train net output #0: loss = 0.679921 (* 1 = 0.679921 loss)
I0426 16:14:48.559689  7834 sgd_solver.cpp:105] Iteration 34500, lr = 0.0001
I0426 16:15:16.425588  7834 solver.cpp:218] Iteration 34600 (3.58862 iter/s, 27.8659s/100 iters), loss = 1.13026
I0426 16:15:16.425617  7834 solver.cpp:237]     Train net output #0: loss = 1.13026 (* 1 = 1.13026 loss)
I0426 16:15:16.425622  7834 sgd_solver.cpp:105] Iteration 34600, lr = 0.0001
I0426 16:15:17.827985  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:15:44.289973  7834 solver.cpp:218] Iteration 34700 (3.58882 iter/s, 27.8643s/100 iters), loss = 1.06835
I0426 16:15:44.290071  7834 solver.cpp:237]     Train net output #0: loss = 1.06835 (* 1 = 1.06835 loss)
I0426 16:15:44.290076  7834 sgd_solver.cpp:105] Iteration 34700, lr = 0.0001
I0426 16:16:12.155050  7834 solver.cpp:218] Iteration 34800 (3.58874 iter/s, 27.865s/100 iters), loss = 0.708007
I0426 16:16:12.155078  7834 solver.cpp:237]     Train net output #0: loss = 0.708007 (* 1 = 0.708007 loss)
I0426 16:16:12.155083  7834 sgd_solver.cpp:105] Iteration 34800, lr = 0.0001
I0426 16:16:40.020032  7834 solver.cpp:218] Iteration 34900 (3.58874 iter/s, 27.8649s/100 iters), loss = 0.742549
I0426 16:16:40.020123  7834 solver.cpp:237]     Train net output #0: loss = 0.742549 (* 1 = 0.742549 loss)
I0426 16:16:40.020129  7834 sgd_solver.cpp:105] Iteration 34900, lr = 0.0001
I0426 16:17:07.591156  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_35000.caffemodel
I0426 16:17:07.644985  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_35000.solverstate
I0426 16:17:07.659651  7834 solver.cpp:330] Iteration 35000, Testing net (#0)
I0426 16:17:10.302285  7834 solver.cpp:397]     Test net output #0: loss = 1.24347 (* 1 = 1.24347 loss)
I0426 16:17:10.581548  7834 solver.cpp:218] Iteration 35000 (3.2721 iter/s, 30.5614s/100 iters), loss = 0.833032
I0426 16:17:10.581578  7834 solver.cpp:237]     Train net output #0: loss = 0.833032 (* 1 = 0.833032 loss)
I0426 16:17:10.581583  7834 sgd_solver.cpp:105] Iteration 35000, lr = 0.0001
I0426 16:17:38.448225  7834 solver.cpp:218] Iteration 35100 (3.58852 iter/s, 27.8666s/100 iters), loss = 1.12522
I0426 16:17:38.448253  7834 solver.cpp:237]     Train net output #0: loss = 1.12522 (* 1 = 1.12522 loss)
I0426 16:17:38.448259  7834 sgd_solver.cpp:105] Iteration 35100, lr = 0.0001
I0426 16:18:06.313792  7834 solver.cpp:218] Iteration 35200 (3.58866 iter/s, 27.8655s/100 iters), loss = 0.653887
I0426 16:18:06.313887  7834 solver.cpp:237]     Train net output #0: loss = 0.653887 (* 1 = 0.653887 loss)
I0426 16:18:06.313894  7834 sgd_solver.cpp:105] Iteration 35200, lr = 0.0001
I0426 16:18:34.177686  7834 solver.cpp:218] Iteration 35300 (3.58889 iter/s, 27.8638s/100 iters), loss = 0.758596
I0426 16:18:34.177713  7834 solver.cpp:237]     Train net output #0: loss = 0.758596 (* 1 = 0.758596 loss)
I0426 16:18:34.177719  7834 sgd_solver.cpp:105] Iteration 35300, lr = 0.0001
I0426 16:19:02.040832  7834 solver.cpp:218] Iteration 35400 (3.58898 iter/s, 27.8631s/100 iters), loss = 1.15211
I0426 16:19:02.040923  7834 solver.cpp:237]     Train net output #0: loss = 1.15211 (* 1 = 1.15211 loss)
I0426 16:19:02.040930  7834 sgd_solver.cpp:105] Iteration 35400, lr = 0.0001
I0426 16:19:29.908835  7834 solver.cpp:218] Iteration 35500 (3.58836 iter/s, 27.8679s/100 iters), loss = 0.808102
I0426 16:19:29.908865  7834 solver.cpp:237]     Train net output #0: loss = 0.808102 (* 1 = 0.808102 loss)
I0426 16:19:29.908871  7834 sgd_solver.cpp:105] Iteration 35500, lr = 0.0001
I0426 16:19:57.774391  7834 solver.cpp:218] Iteration 35600 (3.58867 iter/s, 27.8655s/100 iters), loss = 0.971255
I0426 16:19:57.774497  7834 solver.cpp:237]     Train net output #0: loss = 0.971255 (* 1 = 0.971255 loss)
I0426 16:19:57.774502  7834 sgd_solver.cpp:105] Iteration 35600, lr = 0.0001
I0426 16:20:25.638901  7834 solver.cpp:218] Iteration 35700 (3.58881 iter/s, 27.8644s/100 iters), loss = 0.703801
I0426 16:20:25.638942  7834 solver.cpp:237]     Train net output #0: loss = 0.703801 (* 1 = 0.703801 loss)
I0426 16:20:25.638948  7834 sgd_solver.cpp:105] Iteration 35700, lr = 0.0001
I0426 16:20:53.503636  7834 solver.cpp:218] Iteration 35800 (3.58877 iter/s, 27.8647s/100 iters), loss = 0.646678
I0426 16:20:53.503741  7834 solver.cpp:237]     Train net output #0: loss = 0.646678 (* 1 = 0.646678 loss)
I0426 16:20:53.503747  7834 sgd_solver.cpp:105] Iteration 35800, lr = 0.0001
I0426 16:21:21.365188  7834 solver.cpp:218] Iteration 35900 (3.58919 iter/s, 27.8614s/100 iters), loss = 0.844854
I0426 16:21:21.365217  7834 solver.cpp:237]     Train net output #0: loss = 0.844854 (* 1 = 0.844854 loss)
I0426 16:21:21.365221  7834 sgd_solver.cpp:105] Iteration 35900, lr = 0.0001
I0426 16:21:48.933012  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_36000.caffemodel
I0426 16:21:48.986999  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_36000.solverstate
I0426 16:21:49.001622  7834 solver.cpp:330] Iteration 36000, Testing net (#0)
I0426 16:21:51.643733  7834 solver.cpp:397]     Test net output #0: loss = 1.51917 (* 1 = 1.51917 loss)
I0426 16:21:51.923014  7834 solver.cpp:218] Iteration 36000 (3.27249 iter/s, 30.5578s/100 iters), loss = 0.961833
I0426 16:21:51.923044  7834 solver.cpp:237]     Train net output #0: loss = 0.961833 (* 1 = 0.961833 loss)
I0426 16:21:51.923049  7834 sgd_solver.cpp:105] Iteration 36000, lr = 0.0001
I0426 16:22:19.786015  7834 solver.cpp:218] Iteration 36100 (3.58899 iter/s, 27.863s/100 iters), loss = 0.742355
I0426 16:22:19.786116  7834 solver.cpp:237]     Train net output #0: loss = 0.742355 (* 1 = 0.742355 loss)
I0426 16:22:19.786124  7834 sgd_solver.cpp:105] Iteration 36100, lr = 0.0001
I0426 16:22:47.649253  7834 solver.cpp:218] Iteration 36200 (3.58897 iter/s, 27.8631s/100 iters), loss = 0.950763
I0426 16:22:47.649282  7834 solver.cpp:237]     Train net output #0: loss = 0.950763 (* 1 = 0.950763 loss)
I0426 16:22:47.649288  7834 sgd_solver.cpp:105] Iteration 36200, lr = 0.0001
I0426 16:23:15.516057  7834 solver.cpp:218] Iteration 36300 (3.5885 iter/s, 27.8668s/100 iters), loss = 0.8524
I0426 16:23:15.516192  7834 solver.cpp:237]     Train net output #0: loss = 0.8524 (* 1 = 0.8524 loss)
I0426 16:23:15.516198  7834 sgd_solver.cpp:105] Iteration 36300, lr = 0.0001
I0426 16:23:43.384202  7834 solver.cpp:218] Iteration 36400 (3.58834 iter/s, 27.868s/100 iters), loss = 0.994623
I0426 16:23:43.384232  7834 solver.cpp:237]     Train net output #0: loss = 0.994623 (* 1 = 0.994623 loss)
I0426 16:23:43.384238  7834 sgd_solver.cpp:105] Iteration 36400, lr = 0.0001
I0426 16:24:11.243760  7834 solver.cpp:218] Iteration 36500 (3.58944 iter/s, 27.8595s/100 iters), loss = 0.596633
I0426 16:24:11.243842  7834 solver.cpp:237]     Train net output #0: loss = 0.596633 (* 1 = 0.596633 loss)
I0426 16:24:11.243858  7834 sgd_solver.cpp:105] Iteration 36500, lr = 0.0001
I0426 16:24:39.109818  7834 solver.cpp:218] Iteration 36600 (3.58861 iter/s, 27.866s/100 iters), loss = 0.910685
I0426 16:24:39.109848  7834 solver.cpp:237]     Train net output #0: loss = 0.910685 (* 1 = 0.910685 loss)
I0426 16:24:39.109853  7834 sgd_solver.cpp:105] Iteration 36600, lr = 0.0001
I0426 16:25:06.976120  7834 solver.cpp:218] Iteration 36700 (3.58857 iter/s, 27.8663s/100 iters), loss = 0.768931
I0426 16:25:06.976179  7834 solver.cpp:237]     Train net output #0: loss = 0.768931 (* 1 = 0.768931 loss)
I0426 16:25:06.976186  7834 sgd_solver.cpp:105] Iteration 36700, lr = 0.0001
I0426 16:25:34.841109  7834 solver.cpp:218] Iteration 36800 (3.58874 iter/s, 27.8649s/100 iters), loss = 0.788891
I0426 16:25:34.841140  7834 solver.cpp:237]     Train net output #0: loss = 0.788891 (* 1 = 0.788891 loss)
I0426 16:25:34.841146  7834 sgd_solver.cpp:105] Iteration 36800, lr = 0.0001
I0426 16:26:02.716418  7834 solver.cpp:218] Iteration 36900 (3.58741 iter/s, 27.8753s/100 iters), loss = 0.753585
I0426 16:26:02.716563  7834 solver.cpp:237]     Train net output #0: loss = 0.753585 (* 1 = 0.753585 loss)
I0426 16:26:02.716572  7834 sgd_solver.cpp:105] Iteration 36900, lr = 0.0001
I0426 16:26:30.285749  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_37000.caffemodel
I0426 16:26:30.339453  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_37000.solverstate
I0426 16:26:30.354079  7834 solver.cpp:330] Iteration 37000, Testing net (#0)
I0426 16:26:33.001368  7834 solver.cpp:397]     Test net output #0: loss = 1.27592 (* 1 = 1.27592 loss)
I0426 16:26:33.283614  7834 solver.cpp:218] Iteration 37000 (3.2715 iter/s, 30.567s/100 iters), loss = 0.726192
I0426 16:26:33.283644  7834 solver.cpp:237]     Train net output #0: loss = 0.726192 (* 1 = 0.726192 loss)
I0426 16:26:33.283651  7834 sgd_solver.cpp:105] Iteration 37000, lr = 0.0001
I0426 16:27:01.242372  7834 solver.cpp:218] Iteration 37100 (3.5767 iter/s, 27.9587s/100 iters), loss = 0.758939
I0426 16:27:01.242399  7834 solver.cpp:237]     Train net output #0: loss = 0.758939 (* 1 = 0.758939 loss)
I0426 16:27:01.242405  7834 sgd_solver.cpp:105] Iteration 37100, lr = 0.0001
I0426 16:27:29.124001  7834 solver.cpp:218] Iteration 37200 (3.58659 iter/s, 27.8816s/100 iters), loss = 0.820869
I0426 16:27:29.124150  7834 solver.cpp:237]     Train net output #0: loss = 0.820869 (* 1 = 0.820869 loss)
I0426 16:27:29.124156  7834 sgd_solver.cpp:105] Iteration 37200, lr = 0.0001
I0426 16:27:48.113451  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:27:57.051301  7834 solver.cpp:218] Iteration 37300 (3.58074 iter/s, 27.9272s/100 iters), loss = 0.851241
I0426 16:27:57.051331  7834 solver.cpp:237]     Train net output #0: loss = 0.851241 (* 1 = 0.851241 loss)
I0426 16:27:57.051337  7834 sgd_solver.cpp:105] Iteration 37300, lr = 0.0001
I0426 16:28:24.920550  7834 solver.cpp:218] Iteration 37400 (3.58819 iter/s, 27.8692s/100 iters), loss = 0.976946
I0426 16:28:24.920684  7834 solver.cpp:237]     Train net output #0: loss = 0.976946 (* 1 = 0.976946 loss)
I0426 16:28:24.920701  7834 sgd_solver.cpp:105] Iteration 37400, lr = 0.0001
I0426 16:28:52.787900  7834 solver.cpp:218] Iteration 37500 (3.58844 iter/s, 27.8672s/100 iters), loss = 1.02664
I0426 16:28:52.787930  7834 solver.cpp:237]     Train net output #0: loss = 1.02664 (* 1 = 1.02664 loss)
I0426 16:28:52.787935  7834 sgd_solver.cpp:105] Iteration 37500, lr = 0.0001
I0426 16:29:20.663822  7834 solver.cpp:218] Iteration 37600 (3.58733 iter/s, 27.8759s/100 iters), loss = 0.747635
I0426 16:29:20.663902  7834 solver.cpp:237]     Train net output #0: loss = 0.747635 (* 1 = 0.747635 loss)
I0426 16:29:20.663918  7834 sgd_solver.cpp:105] Iteration 37600, lr = 0.0001
I0426 16:29:48.534643  7834 solver.cpp:218] Iteration 37700 (3.58799 iter/s, 27.8707s/100 iters), loss = 1.16373
I0426 16:29:48.534672  7834 solver.cpp:237]     Train net output #0: loss = 1.16373 (* 1 = 1.16373 loss)
I0426 16:29:48.534677  7834 sgd_solver.cpp:105] Iteration 37700, lr = 0.0001
I0426 16:30:16.443600  7834 solver.cpp:218] Iteration 37800 (3.58308 iter/s, 27.9089s/100 iters), loss = 0.847792
I0426 16:30:16.443656  7834 solver.cpp:237]     Train net output #0: loss = 0.847792 (* 1 = 0.847792 loss)
I0426 16:30:16.443662  7834 sgd_solver.cpp:105] Iteration 37800, lr = 0.0001
I0426 16:30:44.727537  7834 solver.cpp:218] Iteration 37900 (3.53558 iter/s, 28.2839s/100 iters), loss = 0.772729
I0426 16:30:44.727591  7834 solver.cpp:237]     Train net output #0: loss = 0.772729 (* 1 = 0.772729 loss)
I0426 16:30:44.727608  7834 sgd_solver.cpp:105] Iteration 37900, lr = 0.0001
I0426 16:31:12.595021  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_38000.caffemodel
I0426 16:31:12.649597  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_38000.solverstate
I0426 16:31:12.665122  7834 solver.cpp:330] Iteration 38000, Testing net (#0)
I0426 16:31:15.309291  7834 solver.cpp:397]     Test net output #0: loss = 1.24567 (* 1 = 1.24567 loss)
I0426 16:31:15.589097  7834 solver.cpp:218] Iteration 38000 (3.24028 iter/s, 30.8615s/100 iters), loss = 0.939948
I0426 16:31:15.589125  7834 solver.cpp:237]     Train net output #0: loss = 0.939948 (* 1 = 0.939948 loss)
I0426 16:31:15.589131  7834 sgd_solver.cpp:105] Iteration 38000, lr = 0.0001
I0426 16:31:43.456542  7834 solver.cpp:218] Iteration 38100 (3.58842 iter/s, 27.8674s/100 iters), loss = 0.823165
I0426 16:31:43.456622  7834 solver.cpp:237]     Train net output #0: loss = 0.823165 (* 1 = 0.823165 loss)
I0426 16:31:43.456637  7834 sgd_solver.cpp:105] Iteration 38100, lr = 0.0001
I0426 16:32:11.326841  7834 solver.cpp:218] Iteration 38200 (3.58806 iter/s, 27.8702s/100 iters), loss = 0.608736
I0426 16:32:11.326870  7834 solver.cpp:237]     Train net output #0: loss = 0.608736 (* 1 = 0.608736 loss)
I0426 16:32:11.326875  7834 sgd_solver.cpp:105] Iteration 38200, lr = 0.0001
I0426 16:32:39.206660  7834 solver.cpp:218] Iteration 38300 (3.58683 iter/s, 27.8798s/100 iters), loss = 0.751078
I0426 16:32:39.206804  7834 solver.cpp:237]     Train net output #0: loss = 0.751078 (* 1 = 0.751078 loss)
I0426 16:32:39.206810  7834 sgd_solver.cpp:105] Iteration 38300, lr = 0.0001
I0426 16:33:07.114339  7834 solver.cpp:218] Iteration 38400 (3.58326 iter/s, 27.9075s/100 iters), loss = 0.786853
I0426 16:33:07.114370  7834 solver.cpp:237]     Train net output #0: loss = 0.786853 (* 1 = 0.786853 loss)
I0426 16:33:07.114375  7834 sgd_solver.cpp:105] Iteration 38400, lr = 0.0001
I0426 16:33:34.992808  7834 solver.cpp:218] Iteration 38500 (3.587 iter/s, 27.8784s/100 iters), loss = 0.757649
I0426 16:33:34.992923  7834 solver.cpp:237]     Train net output #0: loss = 0.757649 (* 1 = 0.757649 loss)
I0426 16:33:34.992929  7834 sgd_solver.cpp:105] Iteration 38500, lr = 0.0001
I0426 16:34:02.870784  7834 solver.cpp:218] Iteration 38600 (3.58707 iter/s, 27.8779s/100 iters), loss = 0.809692
I0426 16:34:02.870812  7834 solver.cpp:237]     Train net output #0: loss = 0.809692 (* 1 = 0.809692 loss)
I0426 16:34:02.870818  7834 sgd_solver.cpp:105] Iteration 38600, lr = 0.0001
I0426 16:34:30.748507  7834 solver.cpp:218] Iteration 38700 (3.5871 iter/s, 27.8777s/100 iters), loss = 0.640799
I0426 16:34:30.748553  7834 solver.cpp:237]     Train net output #0: loss = 0.640799 (* 1 = 0.640799 loss)
I0426 16:34:30.748559  7834 sgd_solver.cpp:105] Iteration 38700, lr = 0.0001
I0426 16:34:58.624574  7834 solver.cpp:218] Iteration 38800 (3.58731 iter/s, 27.876s/100 iters), loss = 0.761296
I0426 16:34:58.624603  7834 solver.cpp:237]     Train net output #0: loss = 0.761296 (* 1 = 0.761296 loss)
I0426 16:34:58.624609  7834 sgd_solver.cpp:105] Iteration 38800, lr = 0.0001
I0426 16:35:26.498415  7834 solver.cpp:218] Iteration 38900 (3.5876 iter/s, 27.8738s/100 iters), loss = 0.863555
I0426 16:35:26.498493  7834 solver.cpp:237]     Train net output #0: loss = 0.863555 (* 1 = 0.863555 loss)
I0426 16:35:26.498509  7834 sgd_solver.cpp:105] Iteration 38900, lr = 0.0001
I0426 16:35:54.084985  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_39000.caffemodel
I0426 16:35:54.139171  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_39000.solverstate
I0426 16:35:54.154335  7834 solver.cpp:330] Iteration 39000, Testing net (#0)
I0426 16:35:56.797864  7834 solver.cpp:397]     Test net output #0: loss = 1.19346 (* 1 = 1.19346 loss)
I0426 16:35:57.077306  7834 solver.cpp:218] Iteration 39000 (3.27024 iter/s, 30.5788s/100 iters), loss = 0.776862
I0426 16:35:57.077332  7834 solver.cpp:237]     Train net output #0: loss = 0.776862 (* 1 = 0.776862 loss)
I0426 16:35:57.077338  7834 sgd_solver.cpp:105] Iteration 39000, lr = 0.0001
I0426 16:36:24.951617  7834 solver.cpp:218] Iteration 39100 (3.58754 iter/s, 27.8743s/100 iters), loss = 0.814419
I0426 16:36:24.951644  7834 solver.cpp:237]     Train net output #0: loss = 0.814419 (* 1 = 0.814419 loss)
I0426 16:36:24.951650  7834 sgd_solver.cpp:105] Iteration 39100, lr = 0.0001
I0426 16:36:52.825269  7834 solver.cpp:218] Iteration 39200 (3.58762 iter/s, 27.8736s/100 iters), loss = 0.721233
I0426 16:36:52.825348  7834 solver.cpp:237]     Train net output #0: loss = 0.721233 (* 1 = 0.721233 loss)
I0426 16:36:52.825364  7834 sgd_solver.cpp:105] Iteration 39200, lr = 0.0001
I0426 16:37:20.700997  7834 solver.cpp:218] Iteration 39300 (3.58736 iter/s, 27.8757s/100 iters), loss = 0.789128
I0426 16:37:20.701026  7834 solver.cpp:237]     Train net output #0: loss = 0.789128 (* 1 = 0.789128 loss)
I0426 16:37:20.701032  7834 sgd_solver.cpp:105] Iteration 39300, lr = 0.0001
I0426 16:37:48.575289  7834 solver.cpp:218] Iteration 39400 (3.58754 iter/s, 27.8743s/100 iters), loss = 0.963294
I0426 16:37:48.575389  7834 solver.cpp:237]     Train net output #0: loss = 0.963294 (* 1 = 0.963294 loss)
I0426 16:37:48.575395  7834 sgd_solver.cpp:105] Iteration 39400, lr = 0.0001
I0426 16:38:16.450351  7834 solver.cpp:218] Iteration 39500 (3.58745 iter/s, 27.875s/100 iters), loss = 0.705811
I0426 16:38:16.450381  7834 solver.cpp:237]     Train net output #0: loss = 0.705811 (* 1 = 0.705811 loss)
I0426 16:38:16.450387  7834 sgd_solver.cpp:105] Iteration 39500, lr = 0.0001
I0426 16:38:44.329309  7834 solver.cpp:218] Iteration 39600 (3.58694 iter/s, 27.8789s/100 iters), loss = 0.77127
I0426 16:38:44.329411  7834 solver.cpp:237]     Train net output #0: loss = 0.77127 (* 1 = 0.77127 loss)
I0426 16:38:44.329427  7834 sgd_solver.cpp:105] Iteration 39600, lr = 0.0001
I0426 16:39:12.210613  7834 solver.cpp:218] Iteration 39700 (3.58665 iter/s, 27.8812s/100 iters), loss = 1.09024
I0426 16:39:12.210642  7834 solver.cpp:237]     Train net output #0: loss = 1.09024 (* 1 = 1.09024 loss)
I0426 16:39:12.210647  7834 sgd_solver.cpp:105] Iteration 39700, lr = 0.0001
I0426 16:39:40.085881  7834 solver.cpp:218] Iteration 39800 (3.58741 iter/s, 27.8752s/100 iters), loss = 0.722756
I0426 16:39:40.085964  7834 solver.cpp:237]     Train net output #0: loss = 0.722756 (* 1 = 0.722756 loss)
I0426 16:39:40.085980  7834 sgd_solver.cpp:105] Iteration 39800, lr = 0.0001
I0426 16:40:07.965873  7834 solver.cpp:218] Iteration 39900 (3.58681 iter/s, 27.8799s/100 iters), loss = 0.693207
I0426 16:40:07.965903  7834 solver.cpp:237]     Train net output #0: loss = 0.693207 (* 1 = 0.693207 loss)
I0426 16:40:07.965909  7834 sgd_solver.cpp:105] Iteration 39900, lr = 0.0001
I0426 16:40:16.340658  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:40:35.550966  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_40000.caffemodel
I0426 16:40:35.605428  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_40000.solverstate
I0426 16:40:35.620641  7834 solver.cpp:330] Iteration 40000, Testing net (#0)
I0426 16:40:38.264720  7834 solver.cpp:397]     Test net output #0: loss = 1.29922 (* 1 = 1.29922 loss)
I0426 16:40:38.543817  7834 solver.cpp:218] Iteration 40000 (3.27033 iter/s, 30.5779s/100 iters), loss = 0.919459
I0426 16:40:38.543845  7834 solver.cpp:237]     Train net output #0: loss = 0.919459 (* 1 = 0.919459 loss)
I0426 16:40:38.543851  7834 sgd_solver.cpp:105] Iteration 40000, lr = 1e-05
I0426 16:41:06.426169  7834 solver.cpp:218] Iteration 40100 (3.5865 iter/s, 27.8823s/100 iters), loss = 0.75523
I0426 16:41:06.426303  7834 solver.cpp:237]     Train net output #0: loss = 0.75523 (* 1 = 0.75523 loss)
I0426 16:41:06.426311  7834 sgd_solver.cpp:105] Iteration 40100, lr = 1e-05
I0426 16:41:34.307554  7834 solver.cpp:218] Iteration 40200 (3.58664 iter/s, 27.8813s/100 iters), loss = 0.696457
I0426 16:41:34.307582  7834 solver.cpp:237]     Train net output #0: loss = 0.696457 (* 1 = 0.696457 loss)
I0426 16:41:34.307588  7834 sgd_solver.cpp:105] Iteration 40200, lr = 1e-05
I0426 16:42:02.187654  7834 solver.cpp:218] Iteration 40300 (3.58679 iter/s, 27.8801s/100 iters), loss = 0.901901
I0426 16:42:02.187786  7834 solver.cpp:237]     Train net output #0: loss = 0.901901 (* 1 = 0.901901 loss)
I0426 16:42:02.187793  7834 sgd_solver.cpp:105] Iteration 40300, lr = 1e-05
I0426 16:42:30.069152  7834 solver.cpp:218] Iteration 40400 (3.58662 iter/s, 27.8814s/100 iters), loss = 0.853141
I0426 16:42:30.069182  7834 solver.cpp:237]     Train net output #0: loss = 0.853141 (* 1 = 0.853141 loss)
I0426 16:42:30.069188  7834 sgd_solver.cpp:105] Iteration 40400, lr = 1e-05
I0426 16:42:57.950738  7834 solver.cpp:218] Iteration 40500 (3.5866 iter/s, 27.8816s/100 iters), loss = 0.584281
I0426 16:42:57.950873  7834 solver.cpp:237]     Train net output #0: loss = 0.584281 (* 1 = 0.584281 loss)
I0426 16:42:57.950881  7834 sgd_solver.cpp:105] Iteration 40500, lr = 1e-05
I0426 16:43:25.833576  7834 solver.cpp:218] Iteration 40600 (3.58645 iter/s, 27.8827s/100 iters), loss = 0.783692
I0426 16:43:25.833606  7834 solver.cpp:237]     Train net output #0: loss = 0.783692 (* 1 = 0.783692 loss)
I0426 16:43:25.833612  7834 sgd_solver.cpp:105] Iteration 40600, lr = 1e-05
I0426 16:43:53.712080  7834 solver.cpp:218] Iteration 40700 (3.587 iter/s, 27.8785s/100 iters), loss = 0.964343
I0426 16:43:53.712185  7834 solver.cpp:237]     Train net output #0: loss = 0.964343 (* 1 = 0.964343 loss)
I0426 16:43:53.712191  7834 sgd_solver.cpp:105] Iteration 40700, lr = 1e-05
I0426 16:44:21.591145  7834 solver.cpp:218] Iteration 40800 (3.58693 iter/s, 27.879s/100 iters), loss = 0.880154
I0426 16:44:21.591184  7834 solver.cpp:237]     Train net output #0: loss = 0.880154 (* 1 = 0.880154 loss)
I0426 16:44:21.591192  7834 sgd_solver.cpp:105] Iteration 40800, lr = 1e-05
I0426 16:44:49.472312  7834 solver.cpp:218] Iteration 40900 (3.58666 iter/s, 27.8811s/100 iters), loss = 0.676082
I0426 16:44:49.472481  7834 solver.cpp:237]     Train net output #0: loss = 0.676082 (* 1 = 0.676082 loss)
I0426 16:44:49.472488  7834 sgd_solver.cpp:105] Iteration 40900, lr = 1e-05
I0426 16:45:17.059099  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_41000.caffemodel
I0426 16:45:17.112939  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_41000.solverstate
I0426 16:45:17.127882  7834 solver.cpp:330] Iteration 41000, Testing net (#0)
I0426 16:45:19.774013  7834 solver.cpp:397]     Test net output #0: loss = 1.30248 (* 1 = 1.30248 loss)
I0426 16:45:20.053238  7834 solver.cpp:218] Iteration 41000 (3.27003 iter/s, 30.5808s/100 iters), loss = 0.713841
I0426 16:45:20.053267  7834 solver.cpp:237]     Train net output #0: loss = 0.713841 (* 1 = 0.713841 loss)
I0426 16:45:20.053273  7834 sgd_solver.cpp:105] Iteration 41000, lr = 1e-05
I0426 16:45:47.927292  7834 solver.cpp:218] Iteration 41100 (3.58757 iter/s, 27.874s/100 iters), loss = 0.744785
I0426 16:45:47.927322  7834 solver.cpp:237]     Train net output #0: loss = 0.744785 (* 1 = 0.744785 loss)
I0426 16:45:47.927327  7834 sgd_solver.cpp:105] Iteration 41100, lr = 1e-05
I0426 16:46:15.802881  7834 solver.cpp:218] Iteration 41200 (3.58737 iter/s, 27.8756s/100 iters), loss = 0.665241
I0426 16:46:15.802937  7834 solver.cpp:237]     Train net output #0: loss = 0.665241 (* 1 = 0.665241 loss)
I0426 16:46:15.802943  7834 sgd_solver.cpp:105] Iteration 41200, lr = 1e-05
I0426 16:46:43.679699  7834 solver.cpp:218] Iteration 41300 (3.58722 iter/s, 27.8768s/100 iters), loss = 0.77176
I0426 16:46:43.679728  7834 solver.cpp:237]     Train net output #0: loss = 0.77176 (* 1 = 0.77176 loss)
I0426 16:46:43.679733  7834 sgd_solver.cpp:105] Iteration 41300, lr = 1e-05
I0426 16:47:11.561333  7834 solver.cpp:218] Iteration 41400 (3.58659 iter/s, 27.8816s/100 iters), loss = 0.595416
I0426 16:47:11.561403  7834 solver.cpp:237]     Train net output #0: loss = 0.595416 (* 1 = 0.595416 loss)
I0426 16:47:11.561409  7834 sgd_solver.cpp:105] Iteration 41400, lr = 1e-05
I0426 16:47:39.435271  7834 solver.cpp:218] Iteration 41500 (3.58759 iter/s, 27.8739s/100 iters), loss = 0.656426
I0426 16:47:39.435300  7834 solver.cpp:237]     Train net output #0: loss = 0.656426 (* 1 = 0.656426 loss)
I0426 16:47:39.435307  7834 sgd_solver.cpp:105] Iteration 41500, lr = 1e-05
I0426 16:48:07.315414  7834 solver.cpp:218] Iteration 41600 (3.58679 iter/s, 27.8801s/100 iters), loss = 0.369246
I0426 16:48:07.315558  7834 solver.cpp:237]     Train net output #0: loss = 0.369246 (* 1 = 0.369246 loss)
I0426 16:48:07.315567  7834 sgd_solver.cpp:105] Iteration 41600, lr = 1e-05
I0426 16:48:35.193826  7834 solver.cpp:218] Iteration 41700 (3.58702 iter/s, 27.8783s/100 iters), loss = 0.642306
I0426 16:48:35.193856  7834 solver.cpp:237]     Train net output #0: loss = 0.642306 (* 1 = 0.642306 loss)
I0426 16:48:35.193861  7834 sgd_solver.cpp:105] Iteration 41700, lr = 1e-05
I0426 16:49:03.073688  7834 solver.cpp:218] Iteration 41800 (3.58682 iter/s, 27.8798s/100 iters), loss = 0.725243
I0426 16:49:03.073778  7834 solver.cpp:237]     Train net output #0: loss = 0.725243 (* 1 = 0.725243 loss)
I0426 16:49:03.073786  7834 sgd_solver.cpp:105] Iteration 41800, lr = 1e-05
I0426 16:49:30.950479  7834 solver.cpp:218] Iteration 41900 (3.58722 iter/s, 27.8767s/100 iters), loss = 0.655226
I0426 16:49:30.950507  7834 solver.cpp:237]     Train net output #0: loss = 0.655226 (* 1 = 0.655226 loss)
I0426 16:49:30.950513  7834 sgd_solver.cpp:105] Iteration 41900, lr = 1e-05
I0426 16:49:58.531785  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_42000.caffemodel
I0426 16:49:58.585623  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_42000.solverstate
I0426 16:49:58.600517  7834 solver.cpp:330] Iteration 42000, Testing net (#0)
I0426 16:50:01.245847  7834 solver.cpp:397]     Test net output #0: loss = 1.28988 (* 1 = 1.28988 loss)
I0426 16:50:01.525415  7834 solver.cpp:218] Iteration 42000 (3.27066 iter/s, 30.5749s/100 iters), loss = 0.7093
I0426 16:50:01.525442  7834 solver.cpp:237]     Train net output #0: loss = 0.7093 (* 1 = 0.7093 loss)
I0426 16:50:01.525449  7834 sgd_solver.cpp:105] Iteration 42000, lr = 1e-05
I0426 16:50:29.401065  7834 solver.cpp:218] Iteration 42100 (3.58736 iter/s, 27.8756s/100 iters), loss = 0.763329
I0426 16:50:29.401146  7834 solver.cpp:237]     Train net output #0: loss = 0.763329 (* 1 = 0.763329 loss)
I0426 16:50:29.401162  7834 sgd_solver.cpp:105] Iteration 42100, lr = 1e-05
I0426 16:50:57.276410  7834 solver.cpp:218] Iteration 42200 (3.58741 iter/s, 27.8753s/100 iters), loss = 0.534965
I0426 16:50:57.276439  7834 solver.cpp:237]     Train net output #0: loss = 0.534965 (* 1 = 0.534965 loss)
I0426 16:50:57.276444  7834 sgd_solver.cpp:105] Iteration 42200, lr = 1e-05
I0426 16:51:25.156262  7834 solver.cpp:218] Iteration 42300 (3.58682 iter/s, 27.8798s/100 iters), loss = 0.646527
I0426 16:51:25.156409  7834 solver.cpp:237]     Train net output #0: loss = 0.646527 (* 1 = 0.646527 loss)
I0426 16:51:25.156415  7834 sgd_solver.cpp:105] Iteration 42300, lr = 1e-05
I0426 16:51:53.037119  7834 solver.cpp:218] Iteration 42400 (3.58671 iter/s, 27.8807s/100 iters), loss = 0.703116
I0426 16:51:53.037149  7834 solver.cpp:237]     Train net output #0: loss = 0.703116 (* 1 = 0.703116 loss)
I0426 16:51:53.037154  7834 sgd_solver.cpp:105] Iteration 42400, lr = 1e-05
I0426 16:52:20.919119  7834 solver.cpp:218] Iteration 42500 (3.58655 iter/s, 27.882s/100 iters), loss = 0.882331
I0426 16:52:20.919219  7834 solver.cpp:237]     Train net output #0: loss = 0.882331 (* 1 = 0.882331 loss)
I0426 16:52:20.919225  7834 sgd_solver.cpp:105] Iteration 42500, lr = 1e-05
I0426 16:52:46.576586  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 16:52:48.802925  7834 solver.cpp:218] Iteration 42600 (3.58632 iter/s, 27.8837s/100 iters), loss = 0.530349
I0426 16:52:48.802955  7834 solver.cpp:237]     Train net output #0: loss = 0.530349 (* 1 = 0.530349 loss)
I0426 16:52:48.802961  7834 sgd_solver.cpp:105] Iteration 42600, lr = 1e-05
I0426 16:53:16.676909  7834 solver.cpp:218] Iteration 42700 (3.58758 iter/s, 27.874s/100 iters), loss = 0.761805
I0426 16:53:16.677004  7834 solver.cpp:237]     Train net output #0: loss = 0.761805 (* 1 = 0.761805 loss)
I0426 16:53:16.677011  7834 sgd_solver.cpp:105] Iteration 42700, lr = 1e-05
I0426 16:53:44.555178  7834 solver.cpp:218] Iteration 42800 (3.58703 iter/s, 27.8782s/100 iters), loss = 0.974127
I0426 16:53:44.555207  7834 solver.cpp:237]     Train net output #0: loss = 0.974127 (* 1 = 0.974127 loss)
I0426 16:53:44.555212  7834 sgd_solver.cpp:105] Iteration 42800, lr = 1e-05
I0426 16:54:12.432304  7834 solver.cpp:218] Iteration 42900 (3.58717 iter/s, 27.8771s/100 iters), loss = 0.778358
I0426 16:54:12.432425  7834 solver.cpp:237]     Train net output #0: loss = 0.778358 (* 1 = 0.778358 loss)
I0426 16:54:12.432441  7834 sgd_solver.cpp:105] Iteration 42900, lr = 1e-05
I0426 16:54:40.018352  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_43000.caffemodel
I0426 16:54:40.072451  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_43000.solverstate
I0426 16:54:40.087400  7834 solver.cpp:330] Iteration 43000, Testing net (#0)
I0426 16:54:42.731902  7834 solver.cpp:397]     Test net output #0: loss = 1.21026 (* 1 = 1.21026 loss)
I0426 16:54:43.011390  7834 solver.cpp:218] Iteration 43000 (3.27022 iter/s, 30.579s/100 iters), loss = 0.59247
I0426 16:54:43.011420  7834 solver.cpp:237]     Train net output #0: loss = 0.59247 (* 1 = 0.59247 loss)
I0426 16:54:43.011425  7834 sgd_solver.cpp:105] Iteration 43000, lr = 1e-05
I0426 16:55:10.882262  7834 solver.cpp:218] Iteration 43100 (3.58798 iter/s, 27.8708s/100 iters), loss = 0.671397
I0426 16:55:10.882292  7834 solver.cpp:237]     Train net output #0: loss = 0.671397 (* 1 = 0.671397 loss)
I0426 16:55:10.882298  7834 sgd_solver.cpp:105] Iteration 43100, lr = 1e-05
I0426 16:55:38.754421  7834 solver.cpp:218] Iteration 43200 (3.58781 iter/s, 27.8721s/100 iters), loss = 0.752676
I0426 16:55:38.754520  7834 solver.cpp:237]     Train net output #0: loss = 0.752676 (* 1 = 0.752676 loss)
I0426 16:55:38.754528  7834 sgd_solver.cpp:105] Iteration 43200, lr = 1e-05
I0426 16:56:06.625180  7834 solver.cpp:218] Iteration 43300 (3.588 iter/s, 27.8707s/100 iters), loss = 0.746631
I0426 16:56:06.625208  7834 solver.cpp:237]     Train net output #0: loss = 0.746631 (* 1 = 0.746631 loss)
I0426 16:56:06.625214  7834 sgd_solver.cpp:105] Iteration 43300, lr = 1e-05
I0426 16:56:34.502588  7834 solver.cpp:218] Iteration 43400 (3.58714 iter/s, 27.8774s/100 iters), loss = 0.897008
I0426 16:56:34.502683  7834 solver.cpp:237]     Train net output #0: loss = 0.897008 (* 1 = 0.897008 loss)
I0426 16:56:34.502701  7834 sgd_solver.cpp:105] Iteration 43400, lr = 1e-05
I0426 16:57:02.375706  7834 solver.cpp:218] Iteration 43500 (3.5877 iter/s, 27.873s/100 iters), loss = 0.696973
I0426 16:57:02.375735  7834 solver.cpp:237]     Train net output #0: loss = 0.696973 (* 1 = 0.696973 loss)
I0426 16:57:02.375741  7834 sgd_solver.cpp:105] Iteration 43500, lr = 1e-05
I0426 16:57:30.251202  7834 solver.cpp:218] Iteration 43600 (3.58738 iter/s, 27.8755s/100 iters), loss = 0.615714
I0426 16:57:30.251296  7834 solver.cpp:237]     Train net output #0: loss = 0.615714 (* 1 = 0.615714 loss)
I0426 16:57:30.251302  7834 sgd_solver.cpp:105] Iteration 43600, lr = 1e-05
I0426 16:57:58.124758  7834 solver.cpp:218] Iteration 43700 (3.58764 iter/s, 27.8735s/100 iters), loss = 0.697338
I0426 16:57:58.124797  7834 solver.cpp:237]     Train net output #0: loss = 0.697338 (* 1 = 0.697338 loss)
I0426 16:57:58.124804  7834 sgd_solver.cpp:105] Iteration 43700, lr = 1e-05
I0426 16:58:25.996129  7834 solver.cpp:218] Iteration 43800 (3.58791 iter/s, 27.8713s/100 iters), loss = 0.934867
I0426 16:58:25.996208  7834 solver.cpp:237]     Train net output #0: loss = 0.934867 (* 1 = 0.934867 loss)
I0426 16:58:25.996224  7834 sgd_solver.cpp:105] Iteration 43800, lr = 1e-05
I0426 16:58:53.869990  7834 solver.cpp:218] Iteration 43900 (3.5876 iter/s, 27.8738s/100 iters), loss = 0.762178
I0426 16:58:53.870018  7834 solver.cpp:237]     Train net output #0: loss = 0.762178 (* 1 = 0.762178 loss)
I0426 16:58:53.870024  7834 sgd_solver.cpp:105] Iteration 43900, lr = 1e-05
I0426 16:59:21.443717  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_44000.caffemodel
I0426 16:59:21.497455  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_44000.solverstate
I0426 16:59:21.512198  7834 solver.cpp:330] Iteration 44000, Testing net (#0)
I0426 16:59:24.155449  7834 solver.cpp:397]     Test net output #0: loss = 1.34931 (* 1 = 1.34931 loss)
I0426 16:59:24.434902  7834 solver.cpp:218] Iteration 44000 (3.27173 iter/s, 30.5649s/100 iters), loss = 0.72405
I0426 16:59:24.434928  7834 solver.cpp:237]     Train net output #0: loss = 0.72405 (* 1 = 0.72405 loss)
I0426 16:59:24.434934  7834 sgd_solver.cpp:105] Iteration 44000, lr = 1e-05
I0426 16:59:52.307922  7834 solver.cpp:218] Iteration 44100 (3.5877 iter/s, 27.873s/100 iters), loss = 0.780422
I0426 16:59:52.307989  7834 solver.cpp:237]     Train net output #0: loss = 0.780422 (* 1 = 0.780422 loss)
I0426 16:59:52.307996  7834 sgd_solver.cpp:105] Iteration 44100, lr = 1e-05
I0426 17:00:20.184067  7834 solver.cpp:218] Iteration 44200 (3.5873 iter/s, 27.8761s/100 iters), loss = 0.608195
I0426 17:00:20.184096  7834 solver.cpp:237]     Train net output #0: loss = 0.608195 (* 1 = 0.608195 loss)
I0426 17:00:20.184101  7834 sgd_solver.cpp:105] Iteration 44200, lr = 1e-05
I0426 17:00:48.058527  7834 solver.cpp:218] Iteration 44300 (3.58752 iter/s, 27.8744s/100 iters), loss = 0.588468
I0426 17:00:48.058658  7834 solver.cpp:237]     Train net output #0: loss = 0.588468 (* 1 = 0.588468 loss)
I0426 17:00:48.058665  7834 sgd_solver.cpp:105] Iteration 44300, lr = 1e-05
I0426 17:01:15.941192  7834 solver.cpp:218] Iteration 44400 (3.58647 iter/s, 27.8826s/100 iters), loss = 0.709526
I0426 17:01:15.941221  7834 solver.cpp:237]     Train net output #0: loss = 0.709526 (* 1 = 0.709526 loss)
I0426 17:01:15.941227  7834 sgd_solver.cpp:105] Iteration 44400, lr = 1e-05
I0426 17:01:43.820475  7834 solver.cpp:218] Iteration 44500 (3.58689 iter/s, 27.8793s/100 iters), loss = 0.623917
I0426 17:01:43.820554  7834 solver.cpp:237]     Train net output #0: loss = 0.623917 (* 1 = 0.623917 loss)
I0426 17:01:43.820569  7834 sgd_solver.cpp:105] Iteration 44500, lr = 1e-05
I0426 17:02:11.695813  7834 solver.cpp:218] Iteration 44600 (3.58741 iter/s, 27.8753s/100 iters), loss = 0.675713
I0426 17:02:11.695853  7834 solver.cpp:237]     Train net output #0: loss = 0.675713 (* 1 = 0.675713 loss)
I0426 17:02:11.695859  7834 sgd_solver.cpp:105] Iteration 44600, lr = 1e-05
I0426 17:02:39.572274  7834 solver.cpp:218] Iteration 44700 (3.58726 iter/s, 27.8764s/100 iters), loss = 0.599786
I0426 17:02:39.572355  7834 solver.cpp:237]     Train net output #0: loss = 0.599786 (* 1 = 0.599786 loss)
I0426 17:02:39.572369  7834 sgd_solver.cpp:105] Iteration 44700, lr = 1e-05
I0426 17:03:07.448160  7834 solver.cpp:218] Iteration 44800 (3.58734 iter/s, 27.8758s/100 iters), loss = 0.583316
I0426 17:03:07.448190  7834 solver.cpp:237]     Train net output #0: loss = 0.583316 (* 1 = 0.583316 loss)
I0426 17:03:07.448196  7834 sgd_solver.cpp:105] Iteration 44800, lr = 1e-05
I0426 17:03:35.321530  7834 solver.cpp:218] Iteration 44900 (3.58766 iter/s, 27.8734s/100 iters), loss = 0.828643
I0426 17:03:35.321610  7834 solver.cpp:237]     Train net output #0: loss = 0.828643 (* 1 = 0.828643 loss)
I0426 17:03:35.321626  7834 sgd_solver.cpp:105] Iteration 44900, lr = 1e-05
I0426 17:04:02.902127  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_45000.caffemodel
I0426 17:04:02.957113  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_45000.solverstate
I0426 17:04:02.972914  7834 solver.cpp:330] Iteration 45000, Testing net (#0)
I0426 17:04:05.617812  7834 solver.cpp:397]     Test net output #0: loss = 1.33212 (* 1 = 1.33212 loss)
I0426 17:04:05.897438  7834 solver.cpp:218] Iteration 45000 (3.27056 iter/s, 30.5758s/100 iters), loss = 0.596227
I0426 17:04:05.897465  7834 solver.cpp:237]     Train net output #0: loss = 0.596227 (* 1 = 0.596227 loss)
I0426 17:04:05.897471  7834 sgd_solver.cpp:105] Iteration 45000, lr = 1e-05
I0426 17:04:33.771049  7834 solver.cpp:218] Iteration 45100 (3.58762 iter/s, 27.8736s/100 iters), loss = 0.840214
I0426 17:04:33.771085  7834 solver.cpp:237]     Train net output #0: loss = 0.840214 (* 1 = 0.840214 loss)
I0426 17:04:33.771091  7834 sgd_solver.cpp:105] Iteration 45100, lr = 1e-05
I0426 17:05:01.647613  7834 solver.cpp:218] Iteration 45200 (3.58725 iter/s, 27.8765s/100 iters), loss = 0.679586
I0426 17:05:01.647753  7834 solver.cpp:237]     Train net output #0: loss = 0.679586 (* 1 = 0.679586 loss)
I0426 17:05:01.647758  7834 sgd_solver.cpp:105] Iteration 45200, lr = 1e-05
I0426 17:05:16.987746  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 17:05:29.535945  7834 solver.cpp:218] Iteration 45300 (3.58575 iter/s, 27.8882s/100 iters), loss = 1.07039
I0426 17:05:29.535974  7834 solver.cpp:237]     Train net output #0: loss = 1.07039 (* 1 = 1.07039 loss)
I0426 17:05:29.535979  7834 sgd_solver.cpp:105] Iteration 45300, lr = 1e-05
I0426 17:05:57.411288  7834 solver.cpp:218] Iteration 45400 (3.5874 iter/s, 27.8753s/100 iters), loss = 0.599787
I0426 17:05:57.411409  7834 solver.cpp:237]     Train net output #0: loss = 0.599787 (* 1 = 0.599787 loss)
I0426 17:05:57.411415  7834 sgd_solver.cpp:105] Iteration 45400, lr = 1e-05
I0426 17:06:25.286546  7834 solver.cpp:218] Iteration 45500 (3.58742 iter/s, 27.8752s/100 iters), loss = 0.720366
I0426 17:06:25.286576  7834 solver.cpp:237]     Train net output #0: loss = 0.720366 (* 1 = 0.720366 loss)
I0426 17:06:25.286581  7834 sgd_solver.cpp:105] Iteration 45500, lr = 1e-05
I0426 17:06:53.161375  7834 solver.cpp:218] Iteration 45600 (3.58747 iter/s, 27.8748s/100 iters), loss = 0.615745
I0426 17:06:53.161478  7834 solver.cpp:237]     Train net output #0: loss = 0.615745 (* 1 = 0.615745 loss)
I0426 17:06:53.161484  7834 sgd_solver.cpp:105] Iteration 45600, lr = 1e-05
I0426 17:07:21.036330  7834 solver.cpp:218] Iteration 45700 (3.58746 iter/s, 27.8749s/100 iters), loss = 0.554721
I0426 17:07:21.036360  7834 solver.cpp:237]     Train net output #0: loss = 0.554721 (* 1 = 0.554721 loss)
I0426 17:07:21.036365  7834 sgd_solver.cpp:105] Iteration 45700, lr = 1e-05
I0426 17:07:48.918413  7834 solver.cpp:218] Iteration 45800 (3.58653 iter/s, 27.8821s/100 iters), loss = 0.665616
I0426 17:07:48.918509  7834 solver.cpp:237]     Train net output #0: loss = 0.665616 (* 1 = 0.665616 loss)
I0426 17:07:48.918515  7834 sgd_solver.cpp:105] Iteration 45800, lr = 1e-05
I0426 17:08:16.795346  7834 solver.cpp:218] Iteration 45900 (3.58721 iter/s, 27.8769s/100 iters), loss = 0.704784
I0426 17:08:16.795373  7834 solver.cpp:237]     Train net output #0: loss = 0.704784 (* 1 = 0.704784 loss)
I0426 17:08:16.795378  7834 sgd_solver.cpp:105] Iteration 45900, lr = 1e-05
I0426 17:08:44.379139  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_46000.caffemodel
I0426 17:08:44.433135  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_46000.solverstate
I0426 17:08:44.448055  7834 solver.cpp:330] Iteration 46000, Testing net (#0)
I0426 17:08:47.092900  7834 solver.cpp:397]     Test net output #0: loss = 1.24886 (* 1 = 1.24886 loss)
I0426 17:08:47.372016  7834 solver.cpp:218] Iteration 46000 (3.27047 iter/s, 30.5767s/100 iters), loss = 0.693576
I0426 17:08:47.372045  7834 solver.cpp:237]     Train net output #0: loss = 0.693576 (* 1 = 0.693576 loss)
I0426 17:08:47.372051  7834 sgd_solver.cpp:105] Iteration 46000, lr = 1e-05
I0426 17:09:15.253525  7834 solver.cpp:218] Iteration 46100 (3.58661 iter/s, 27.8815s/100 iters), loss = 0.773488
I0426 17:09:15.253659  7834 solver.cpp:237]     Train net output #0: loss = 0.773488 (* 1 = 0.773488 loss)
I0426 17:09:15.253665  7834 sgd_solver.cpp:105] Iteration 46100, lr = 1e-05
I0426 17:09:43.131721  7834 solver.cpp:218] Iteration 46200 (3.58705 iter/s, 27.8781s/100 iters), loss = 0.86513
I0426 17:09:43.131749  7834 solver.cpp:237]     Train net output #0: loss = 0.86513 (* 1 = 0.86513 loss)
I0426 17:09:43.131755  7834 sgd_solver.cpp:105] Iteration 46200, lr = 1e-05
I0426 17:10:11.012003  7834 solver.cpp:218] Iteration 46300 (3.58677 iter/s, 27.8803s/100 iters), loss = 0.805645
I0426 17:10:11.012051  7834 solver.cpp:237]     Train net output #0: loss = 0.805645 (* 1 = 0.805645 loss)
I0426 17:10:11.012058  7834 sgd_solver.cpp:105] Iteration 46300, lr = 1e-05
I0426 17:10:38.889538  7834 solver.cpp:218] Iteration 46400 (3.58712 iter/s, 27.8775s/100 iters), loss = 0.617292
I0426 17:10:38.889567  7834 solver.cpp:237]     Train net output #0: loss = 0.617292 (* 1 = 0.617292 loss)
I0426 17:10:38.889572  7834 sgd_solver.cpp:105] Iteration 46400, lr = 1e-05
I0426 17:11:06.769034  7834 solver.cpp:218] Iteration 46500 (3.58687 iter/s, 27.8795s/100 iters), loss = 0.555227
I0426 17:11:06.769171  7834 solver.cpp:237]     Train net output #0: loss = 0.555227 (* 1 = 0.555227 loss)
I0426 17:11:06.769179  7834 sgd_solver.cpp:105] Iteration 46500, lr = 1e-05
I0426 17:11:34.646966  7834 solver.cpp:218] Iteration 46600 (3.58708 iter/s, 27.8778s/100 iters), loss = 0.625913
I0426 17:11:34.646994  7834 solver.cpp:237]     Train net output #0: loss = 0.625913 (* 1 = 0.625913 loss)
I0426 17:11:34.647001  7834 sgd_solver.cpp:105] Iteration 46600, lr = 1e-05
I0426 17:12:02.526571  7834 solver.cpp:218] Iteration 46700 (3.58685 iter/s, 27.8796s/100 iters), loss = 0.738033
I0426 17:12:02.526715  7834 solver.cpp:237]     Train net output #0: loss = 0.738033 (* 1 = 0.738033 loss)
I0426 17:12:02.526722  7834 sgd_solver.cpp:105] Iteration 46700, lr = 1e-05
I0426 17:12:30.401851  7834 solver.cpp:218] Iteration 46800 (3.58742 iter/s, 27.8752s/100 iters), loss = 0.716307
I0426 17:12:30.401880  7834 solver.cpp:237]     Train net output #0: loss = 0.716307 (* 1 = 0.716307 loss)
I0426 17:12:30.401885  7834 sgd_solver.cpp:105] Iteration 46800, lr = 1e-05
I0426 17:12:58.282301  7834 solver.cpp:218] Iteration 46900 (3.58674 iter/s, 27.8804s/100 iters), loss = 0.691058
I0426 17:12:58.282418  7834 solver.cpp:237]     Train net output #0: loss = 0.691058 (* 1 = 0.691058 loss)
I0426 17:12:58.282423  7834 sgd_solver.cpp:105] Iteration 46900, lr = 1e-05
I0426 17:13:25.866771  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_47000.caffemodel
I0426 17:13:25.920742  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_47000.solverstate
I0426 17:13:25.936473  7834 solver.cpp:330] Iteration 47000, Testing net (#0)
I0426 17:13:28.580265  7834 solver.cpp:397]     Test net output #0: loss = 1.2847 (* 1 = 1.2847 loss)
I0426 17:13:28.859704  7834 solver.cpp:218] Iteration 47000 (3.2704 iter/s, 30.5773s/100 iters), loss = 0.5799
I0426 17:13:28.859732  7834 solver.cpp:237]     Train net output #0: loss = 0.5799 (* 1 = 0.5799 loss)
I0426 17:13:28.859738  7834 sgd_solver.cpp:105] Iteration 47000, lr = 1e-05
I0426 17:13:56.731468  7834 solver.cpp:218] Iteration 47100 (3.58786 iter/s, 27.8717s/100 iters), loss = 0.751166
I0426 17:13:56.731498  7834 solver.cpp:237]     Train net output #0: loss = 0.751166 (* 1 = 0.751166 loss)
I0426 17:13:56.731503  7834 sgd_solver.cpp:105] Iteration 47100, lr = 1e-05
I0426 17:14:24.608189  7834 solver.cpp:218] Iteration 47200 (3.58722 iter/s, 27.8767s/100 iters), loss = 0.749814
I0426 17:14:24.608283  7834 solver.cpp:237]     Train net output #0: loss = 0.749814 (* 1 = 0.749814 loss)
I0426 17:14:24.608290  7834 sgd_solver.cpp:105] Iteration 47200, lr = 1e-05
I0426 17:14:52.488746  7834 solver.cpp:218] Iteration 47300 (3.58674 iter/s, 27.8805s/100 iters), loss = 0.625286
I0426 17:14:52.488775  7834 solver.cpp:237]     Train net output #0: loss = 0.625286 (* 1 = 0.625286 loss)
I0426 17:14:52.488781  7834 sgd_solver.cpp:105] Iteration 47300, lr = 1e-05
I0426 17:15:20.361759  7834 solver.cpp:218] Iteration 47400 (3.5877 iter/s, 27.873s/100 iters), loss = 0.723157
I0426 17:15:20.361853  7834 solver.cpp:237]     Train net output #0: loss = 0.723157 (* 1 = 0.723157 loss)
I0426 17:15:20.361860  7834 sgd_solver.cpp:105] Iteration 47400, lr = 1e-05
I0426 17:15:48.236042  7834 solver.cpp:218] Iteration 47500 (3.58755 iter/s, 27.8742s/100 iters), loss = 0.698117
I0426 17:15:48.236070  7834 solver.cpp:237]     Train net output #0: loss = 0.698117 (* 1 = 0.698117 loss)
I0426 17:15:48.236076  7834 sgd_solver.cpp:105] Iteration 47500, lr = 1e-05
I0426 17:16:16.105396  7834 solver.cpp:218] Iteration 47600 (3.58817 iter/s, 27.8693s/100 iters), loss = 0.429298
I0426 17:16:16.105473  7834 solver.cpp:237]     Train net output #0: loss = 0.429298 (* 1 = 0.429298 loss)
I0426 17:16:16.105489  7834 sgd_solver.cpp:105] Iteration 47600, lr = 1e-05
I0426 17:16:43.980321  7834 solver.cpp:218] Iteration 47700 (3.58746 iter/s, 27.8749s/100 iters), loss = 0.526931
I0426 17:16:43.980350  7834 solver.cpp:237]     Train net output #0: loss = 0.526931 (* 1 = 0.526931 loss)
I0426 17:16:43.980356  7834 sgd_solver.cpp:105] Iteration 47700, lr = 1e-05
I0426 17:17:11.862735  7834 solver.cpp:218] Iteration 47800 (3.58649 iter/s, 27.8824s/100 iters), loss = 0.670947
I0426 17:17:11.862829  7834 solver.cpp:237]     Train net output #0: loss = 0.670947 (* 1 = 0.670947 loss)
I0426 17:17:11.862835  7834 sgd_solver.cpp:105] Iteration 47800, lr = 1e-05
I0426 17:17:39.735849  7834 solver.cpp:218] Iteration 47900 (3.5877 iter/s, 27.873s/100 iters), loss = 0.670046
I0426 17:17:39.735878  7834 solver.cpp:237]     Train net output #0: loss = 0.670046 (* 1 = 0.670046 loss)
I0426 17:17:39.735901  7834 sgd_solver.cpp:105] Iteration 47900, lr = 1e-05
I0426 17:17:44.484966  7840 data_layer.cpp:73] Restarting data prefetching from start.
I0426 17:18:07.326419  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_48000.caffemodel
I0426 17:18:07.380820  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_48000.solverstate
I0426 17:18:07.395969  7834 solver.cpp:330] Iteration 48000, Testing net (#0)
I0426 17:18:10.041852  7834 solver.cpp:397]     Test net output #0: loss = 1.25252 (* 1 = 1.25252 loss)
I0426 17:18:10.320993  7834 solver.cpp:218] Iteration 48000 (3.26956 iter/s, 30.5851s/100 iters), loss = 0.653863
I0426 17:18:10.321022  7834 solver.cpp:237]     Train net output #0: loss = 0.653863 (* 1 = 0.653863 loss)
I0426 17:18:10.321028  7834 sgd_solver.cpp:105] Iteration 48000, lr = 1e-05
I0426 17:18:38.190184  7834 solver.cpp:218] Iteration 48100 (3.58819 iter/s, 27.8692s/100 iters), loss = 0.970682
I0426 17:18:38.190322  7834 solver.cpp:237]     Train net output #0: loss = 0.970682 (* 1 = 0.970682 loss)
I0426 17:18:38.190330  7834 sgd_solver.cpp:105] Iteration 48100, lr = 1e-05
I0426 17:19:06.062093  7834 solver.cpp:218] Iteration 48200 (3.58786 iter/s, 27.8718s/100 iters), loss = 0.759829
I0426 17:19:06.062121  7834 solver.cpp:237]     Train net output #0: loss = 0.759829 (* 1 = 0.759829 loss)
I0426 17:19:06.062127  7834 sgd_solver.cpp:105] Iteration 48200, lr = 1e-05
I0426 17:19:33.933671  7834 solver.cpp:218] Iteration 48300 (3.58789 iter/s, 27.8716s/100 iters), loss = 0.700184
I0426 17:19:33.933725  7834 solver.cpp:237]     Train net output #0: loss = 0.700184 (* 1 = 0.700184 loss)
I0426 17:19:33.933732  7834 sgd_solver.cpp:105] Iteration 48300, lr = 1e-05
I0426 17:20:01.814585  7834 solver.cpp:218] Iteration 48400 (3.58669 iter/s, 27.8809s/100 iters), loss = 0.769661
I0426 17:20:01.814615  7834 solver.cpp:237]     Train net output #0: loss = 0.769661 (* 1 = 0.769661 loss)
I0426 17:20:01.814621  7834 sgd_solver.cpp:105] Iteration 48400, lr = 1e-05
I0426 17:20:29.692560  7834 solver.cpp:218] Iteration 48500 (3.58706 iter/s, 27.878s/100 iters), loss = 0.772355
I0426 17:20:29.692708  7834 solver.cpp:237]     Train net output #0: loss = 0.772355 (* 1 = 0.772355 loss)
I0426 17:20:29.692715  7834 sgd_solver.cpp:105] Iteration 48500, lr = 1e-05
I0426 17:20:57.565088  7834 solver.cpp:218] Iteration 48600 (3.58778 iter/s, 27.8724s/100 iters), loss = 0.578629
I0426 17:20:57.565116  7834 solver.cpp:237]     Train net output #0: loss = 0.578629 (* 1 = 0.578629 loss)
I0426 17:20:57.565121  7834 sgd_solver.cpp:105] Iteration 48600, lr = 1e-05
I0426 17:21:25.441761  7834 solver.cpp:218] Iteration 48700 (3.58723 iter/s, 27.8767s/100 iters), loss = 0.62676
I0426 17:21:25.441879  7834 solver.cpp:237]     Train net output #0: loss = 0.62676 (* 1 = 0.62676 loss)
I0426 17:21:25.441885  7834 sgd_solver.cpp:105] Iteration 48700, lr = 1e-05
I0426 17:21:53.319880  7834 solver.cpp:218] Iteration 48800 (3.58706 iter/s, 27.878s/100 iters), loss = 0.615125
I0426 17:21:53.319910  7834 solver.cpp:237]     Train net output #0: loss = 0.615125 (* 1 = 0.615125 loss)
I0426 17:21:53.319914  7834 sgd_solver.cpp:105] Iteration 48800, lr = 1e-05
I0426 17:22:21.202723  7834 solver.cpp:218] Iteration 48900 (3.58644 iter/s, 27.8828s/100 iters), loss = 0.789642
I0426 17:22:21.202910  7834 solver.cpp:237]     Train net output #0: loss = 0.789642 (* 1 = 0.789642 loss)
I0426 17:22:21.202919  7834 sgd_solver.cpp:105] Iteration 48900, lr = 1e-05
I0426 17:22:48.788803  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_49000.caffemodel
I0426 17:22:48.843061  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_49000.solverstate
I0426 17:22:48.858732  7834 solver.cpp:330] Iteration 49000, Testing net (#0)
I0426 17:22:49.903195  7841 data_layer.cpp:73] Restarting data prefetching from start.
I0426 17:22:51.507355  7834 solver.cpp:397]     Test net output #0: loss = 1.26041 (* 1 = 1.26041 loss)
I0426 17:22:51.786386  7834 solver.cpp:218] Iteration 49000 (3.26974 iter/s, 30.5835s/100 iters), loss = 0.679233
I0426 17:22:51.786414  7834 solver.cpp:237]     Train net output #0: loss = 0.679233 (* 1 = 0.679233 loss)
I0426 17:22:51.786420  7834 sgd_solver.cpp:105] Iteration 49000, lr = 1e-05
I0426 17:23:19.663216  7834 solver.cpp:218] Iteration 49100 (3.58721 iter/s, 27.8768s/100 iters), loss = 0.603047
I0426 17:23:19.663246  7834 solver.cpp:237]     Train net output #0: loss = 0.603047 (* 1 = 0.603047 loss)
I0426 17:23:19.663251  7834 sgd_solver.cpp:105] Iteration 49100, lr = 1e-05
I0426 17:23:47.540946  7834 solver.cpp:218] Iteration 49200 (3.5871 iter/s, 27.8777s/100 iters), loss = 0.670416
I0426 17:23:47.541029  7834 solver.cpp:237]     Train net output #0: loss = 0.670416 (* 1 = 0.670416 loss)
I0426 17:23:47.541045  7834 sgd_solver.cpp:105] Iteration 49200, lr = 1e-05
I0426 17:24:15.415050  7834 solver.cpp:218] Iteration 49300 (3.58757 iter/s, 27.874s/100 iters), loss = 0.737075
I0426 17:24:15.415081  7834 solver.cpp:237]     Train net output #0: loss = 0.737075 (* 1 = 0.737075 loss)
I0426 17:24:15.415086  7834 sgd_solver.cpp:105] Iteration 49300, lr = 1e-05
I0426 17:24:43.292343  7834 solver.cpp:218] Iteration 49400 (3.58715 iter/s, 27.8773s/100 iters), loss = 0.590255
I0426 17:24:43.292479  7834 solver.cpp:237]     Train net output #0: loss = 0.590255 (* 1 = 0.590255 loss)
I0426 17:24:43.292485  7834 sgd_solver.cpp:105] Iteration 49400, lr = 1e-05
I0426 17:25:11.171839  7834 solver.cpp:218] Iteration 49500 (3.58688 iter/s, 27.8794s/100 iters), loss = 0.609817
I0426 17:25:11.171869  7834 solver.cpp:237]     Train net output #0: loss = 0.609817 (* 1 = 0.609817 loss)
I0426 17:25:11.171876  7834 sgd_solver.cpp:105] Iteration 49500, lr = 1e-05
I0426 17:25:39.047886  7834 solver.cpp:218] Iteration 49600 (3.58731 iter/s, 27.876s/100 iters), loss = 0.617544
I0426 17:25:39.047977  7834 solver.cpp:237]     Train net output #0: loss = 0.617544 (* 1 = 0.617544 loss)
I0426 17:25:39.047984  7834 sgd_solver.cpp:105] Iteration 49600, lr = 1e-05
I0426 17:26:06.924850  7834 solver.cpp:218] Iteration 49700 (3.5872 iter/s, 27.8769s/100 iters), loss = 0.5649
I0426 17:26:06.924880  7834 solver.cpp:237]     Train net output #0: loss = 0.5649 (* 1 = 0.5649 loss)
I0426 17:26:06.924885  7834 sgd_solver.cpp:105] Iteration 49700, lr = 1e-05
I0426 17:26:34.799567  7834 solver.cpp:218] Iteration 49800 (3.58748 iter/s, 27.8747s/100 iters), loss = 0.829089
I0426 17:26:34.799645  7834 solver.cpp:237]     Train net output #0: loss = 0.829089 (* 1 = 0.829089 loss)
I0426 17:26:34.799661  7834 sgd_solver.cpp:105] Iteration 49800, lr = 1e-05
I0426 17:27:02.679457  7834 solver.cpp:218] Iteration 49900 (3.58682 iter/s, 27.8798s/100 iters), loss = 0.629558
I0426 17:27:02.679487  7834 solver.cpp:237]     Train net output #0: loss = 0.629558 (* 1 = 0.629558 loss)
I0426 17:27:02.679493  7834 sgd_solver.cpp:105] Iteration 49900, lr = 1e-05
I0426 17:27:30.261646  7834 solver.cpp:447] Snapshotting to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_50000.caffemodel
I0426 17:27:30.315701  7834 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/lein/yan/caffe/finetunning_thesis/argu_par_ic/1fold_2013_parIC/snapshot/_iter_50000.solverstate
I0426 17:27:30.432133  7834 solver.cpp:310] Iteration 50000, loss = 0.560326
I0426 17:27:30.432153  7834 solver.cpp:330] Iteration 50000, Testing net (#0)
I0426 17:27:33.077553  7834 solver.cpp:397]     Test net output #0: loss = 1.37006 (* 1 = 1.37006 loss)
I0426 17:27:33.077569  7834 solver.cpp:315] Optimization Done.
I0426 17:27:33.077571  7834 caffe.cpp:259] Optimization Done.
